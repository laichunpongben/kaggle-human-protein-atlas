*** 2019-01-03 14:46:31,568 - code.resnet_fastai - DEBUG ***
Start a new training task
******

*** 2019-01-03 14:46:31,568 - code.resnet_fastai - INFO ***
Device ID: 0
Image size: 256
Network architecture: resnet
Loss function: focal
Sampler: random
Encoder depth: 50
Dropout: 0.5
Threshold: 0.1
Stage 1 #epoch: 3
Stage 2 #epoch: 30
Learning rate #1: 0
Batch size: 64
Dataset: official_hpav18
Dataset directory: data/hpav18
Output directory: output
******

*** 2019-01-03 14:46:31,568 - code.resnet_fastai - INFO ***
official_hpav18 stats: ([0.08035214900985806, 0.052662718446443796, 0.054821162479790554, 0.08270705238092081], [0.1441818831316468, 0.10766732147991964, 0.15509390386065397, 0.1447311870215956])
******

*** 2019-01-03 14:46:31,568 - code.resnet_fastai - INFO ***
official stats: ([0.08035214900985806, 0.052662718446443796, 0.054821162479790554, 0.08270705238092081], [0.1441818831316468, 0.10766732147991964, 0.15509390386065397, 0.1447311870215956])
******

*** 2019-01-03 14:46:31,568 - code.resnet_fastai - INFO ***
hpav18 stats: ([0.11810116173772936, 0.06795416990341785, 0.06612933906943513, 0.08437984839655913], [0.17499094128737935, 0.12197690061419421, 0.17568283970650891, 0.11266782268834614])
******

*** 2019-01-03 14:46:31,630 - code.resnet_fastai - DEBUG ***
# Test ids: 11702
******

*** 2019-01-03 14:46:31,752 - code.resnet_fastai - DEBUG ***
official train size: (31072, 2)
******

*** 2019-01-03 14:46:31,798 - code.resnet_fastai - DEBUG ***
hpav18 train size: (71437, 2)
******

*** 2019-01-03 14:46:31,799 - code.resnet_fastai - DEBUG ***
empty size (0, 2)
******

*** 2019-01-03 14:46:32,945 - code.resnet_fastai - DEBUG ***
hpav18 rare size: (7404, 2)
******

*** 2019-01-03 14:46:32,947 - code.resnet_fastai - DEBUG ***
concat size: (38476, 2)
******

*** 2019-01-03 14:46:34,292 - code.resnet_fastai - DEBUG ***
oversample train size: (45767, 2)
******

*** 2019-01-03 14:46:43,665 - code.resnet_fastai - DEBUG ***
Start of fold 5
******

*** 2019-01-03 14:46:43,665 - code.resnet_fastai - DEBUG ***
Size of valid set: 9141
******

*** 2019-01-03 14:46:43,973 - code.resnet_fastai - DEBUG ***
LabelList
y: MultiCategoryList (36626 items)
[MultiCategory 16;0, MultiCategory 7;1;2;0, MultiCategory 5, MultiCategory 18, MultiCategory 25;2]...
Path: data/hpav18
x: ImageItemList (36626 items)
[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...
Path: data/hpav18
******

*** 2019-01-03 14:46:44,103 - code.resnet_fastai - DEBUG ***
LabelList
y: MultiCategoryList (9141 items)
[MultiCategory 1, MultiCategory 0, MultiCategory 7, MultiCategory 23, MultiCategory 6;2]...
Path: data/hpav18
x: ImageItemList (9141 items)
[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...
Path: data/hpav18
******

*** 2019-01-03 14:46:46,087 - code.resnet_fastai - DEBUG ***
Databunch created
******

*** 2019-01-03 14:46:46,087 - code.resnet_fastai - INFO ***
Initialising model.
******

*** 2019-01-03 14:46:46,943 - code.resnet_fastai - INFO ***
Complete initialising model.
******

*** 2019-01-03 14:46:46,943 - code.resnet_fastai - INFO ***
No pretrained model.
******

*** 2019-01-03 14:46:46,943 - code.resnet_fastai - DEBUG ***
Start finding LR
******

epoch     train_loss  valid_loss  fbeta   
1         1.407515                
*** 2019-01-03 14:53:56,159 - code.resnet_fastai - DEBUG ***
[(0.01, tensor(10.7904)), (0.010013872557113347, tensor(12.2580)), (0.010027764359010777, tensor(11.0332)), (0.010041675432389732, tensor(10.2406)), (0.010055605803984681, tensor(9.5265)), (0.01006955550056719, tensor(8.8587)), (0.010083524548945951, tensor(8.2697)), (0.010097512975966859, tensor(7.6229)), (0.010111520808513042, tensor(7.0489)), (0.01012554807350493, tensor(6.5881)), (0.010139594797900291, tensor(6.1692)), (0.010153661008694297, tensor(5.8172)), (0.010167746732919562, tensor(5.5348)), (0.010181851997646207, tensor(5.2839)), (0.010195976829981905, tensor(5.0841)), (0.010210121257071934, tensor(4.9334)), (0.010224285306099224, tensor(4.7875)), (0.010238469004284424, tensor(4.6507)), (0.010252672378885939, tensor(4.5605)), (0.01026689545719999, tensor(4.4329)), (0.010281138266560666, tensor(4.3285)), (0.010295400834339972, tensor(4.2420)), (0.010309683187947886, tensor(4.1547)), (0.01032398535483242, tensor(4.0623)), (0.010338307362479645, tensor(3.9773)), (0.010352649238413777, tensor(3.8906)), (0.010367011010197207, tensor(3.8035)), (0.010381392705430573, tensor(3.7351)), (0.010395794351752788, tensor(3.6593)), (0.010410215976841115, tensor(3.6075)), (0.010424657608411214, tensor(3.5415)), (0.01043911927421719, tensor(3.4763)), (0.010453601002051649, tensor(3.4140)), (0.010468102819745757, tensor(3.3576)), (0.010482624755169288, tensor(3.2976)), (0.010497166836230674, tensor(3.2533)), (0.010511729090877065, tensor(3.2086)), (0.010526311547094385, tensor(3.1615)), (0.01054091423290738, tensor(3.1163)), (0.010555537176379668, tensor(3.0747)), (0.010570180405613803, tensor(3.0299)), (0.010584843948751328, tensor(2.9883)), (0.010599527833972817, tensor(2.9484)), (0.010614232089497947, tensor(2.9181)), (0.010628956743585532, tensor(2.8809)), (0.010643701824533598, tensor(2.8545)), (0.010658467360679425, tensor(2.8199)), (0.010673253380399601, tensor(2.7897)), (0.01068805991211008, tensor(2.7665)), (0.01070288698426624, tensor(2.7349)), (0.010717734625362931, tensor(2.7125)), (0.010732602863934536, tensor(2.6858)), (0.010747491728555013, tensor(2.6557)), (0.010762401247837972, tensor(2.6351)), (0.01077733145043671, tensor(2.6159)), (0.010792282365044273, tensor(2.5919)), (0.010807254020393516, tensor(2.5667)), (0.01082224644525715, tensor(2.5466)), (0.0108372596684478, tensor(2.5302)), (0.010852293718818072, tensor(2.5125)), (0.01086734862526058, tensor(2.4904)), (0.010882424416708036, tensor(2.4672)), (0.010897521122133283, tensor(2.4466)), (0.01091263877054935, tensor(2.4317)), (0.010927777391009526, tensor(2.4101)), (0.010942937012607394, tensor(2.3918)), (0.010958117664476909, tensor(2.3779)), (0.01097331937579243, tensor(2.3593)), (0.010988542175768796, tensor(2.3467)), (0.011003786093661372, tensor(2.3311)), (0.011019051158766106, tensor(2.3117)), (0.011034337400419592, tensor(2.2968)), (0.011049644847999116, tensor(2.2787)), (0.011064973530922721, tensor(2.2602)), (0.011080323478649259, tensor(2.2425)), (0.01109569472067845, tensor(2.2236)), (0.011111087286550936, tensor(2.2081)), (0.01112650120584834, tensor(2.1943)), (0.011141936508193324, tensor(2.1827)), (0.01115739322324964, tensor(2.1669)), (0.011172871380722201, tensor(2.1544)), (0.011188371010357112, tensor(2.1413)), (0.01120389214194176, tensor(2.1281)), (0.011219434805304844, tensor(2.1186)), (0.011234999030316451, tensor(2.1088)), (0.011250584846888094, tensor(2.1008)), (0.011266192284972793, tensor(2.0895)), (0.011281821374565116, tensor(2.0784)), (0.011297472145701235, tensor(2.0675)), (0.011313144628459003, tensor(2.0574)), (0.011328838852957986, tensor(2.0493)), (0.01134455484935954, tensor(2.0395)), (0.011360292647866864, tensor(2.0346)), (0.01137605227872505, tensor(2.0217)), (0.01139183377222115, tensor(2.0136)), (0.011407637158684236, tensor(2.0049)), (0.011423462468485452, tensor(1.9965)), (0.011439309732038074, tensor(1.9894)), (0.01145517897979757, tensor(1.9800)), (0.011471070242261653, tensor(1.9726)), (0.011486983549970351, tensor(1.9660)), (0.011502918933506053, tensor(1.9577)), (0.011518876423493576, tensor(1.9488)), (0.011534856050600225, tensor(1.9408)), (0.011550857845535842, tensor(1.9321)), (0.011566881839052873, tensor(1.9198)), (0.011582928061946432, tensor(1.9118)), (0.011598996545054346, tensor(1.9044)), (0.011615087319257221, tensor(1.9007)), (0.011631200415478509, tensor(1.8943)), (0.011647335864684558, tensor(1.8855)), (0.011663493697884672, tensor(1.8820)), (0.01167967394613118, tensor(1.8797)), (0.011695876640519473, tensor(1.8707)), (0.011712101812188099, tensor(1.8667)), (0.011728349492318789, tensor(1.8587)), (0.011744619712136535, tensor(1.8558)), (0.011760912502909648, tensor(1.8514)), (0.011777227895949816, tensor(1.8441)), (0.01179356592261216, tensor(1.8382)), (0.011809926614295304, tensor(1.8315)), (0.011826310002441427, tensor(1.8258)), (0.011842716118536328, tensor(1.8203)), (0.011859144994109479, tensor(1.8117)), (0.011875596660734103, tensor(1.8083)), (0.01189207115002721, tensor(1.8045)), (0.011908568493649683, tensor(1.7961)), (0.011925088723306316, tensor(1.7870)), (0.011941631870745895, tensor(1.7813)), (0.011958197967761241, tensor(1.7703)), (0.011974787046189286, tensor(1.7649)), (0.011991399137911127, tensor(1.7597)), (0.012008034274852086, tensor(1.7526)), (0.012024692488981777, tensor(1.7480)), (0.012041373812314158, tensor(1.7427)), (0.012058078276907604, tensor(1.7373)), (0.012074805914864964, tensor(1.7296)), (0.012091556758333614, tensor(1.7284)), (0.012108330839505538, tensor(1.7259)), (0.012125128190617371, tensor(1.7190)), (0.01214194884395047, tensor(1.7151)), (0.012158792831830972, tensor(1.7091)), (0.012175660186629862, tensor(1.7040)), (0.012192550940763032, tensor(1.7030)), (0.012209465126691344, tensor(1.6984)), (0.012226402776920685, tensor(1.6917)), (0.012243363924002045, tensor(1.6876)), (0.012260348600531563, tensor(1.6844)), (0.012277356839150605, tensor(1.6843)), (0.012294388672545807, tensor(1.6790)), (0.012311444133449163, tensor(1.6713)), (0.012328523254638067, tensor(1.6685)), (0.012345626068935384, tensor(1.6655)), (0.012362752609209516, tensor(1.6618)), (0.012379902908374457, tensor(1.6580)), (0.012397076999389868, tensor(1.6566)), (0.012414274915261123, tensor(1.6520)), (0.012431496689039397, tensor(1.6486)), (0.012448742353821703, tensor(1.6424)), (0.012466011942750974, tensor(1.6350)), (0.01248330548901612, tensor(1.6312)), (0.012500623025852092, tensor(1.6268)), (0.012517964586539945, tensor(1.6252)), (0.012535330204406905, tensor(1.6238)), (0.012552719912826433, tensor(1.6181)), (0.012570133745218284, tensor(1.6164)), (0.012587571735048578, tensor(1.6117)), (0.012605033915829856, tensor(1.6068)), (0.012622520321121156, tensor(1.6026)), (0.012640030984528068, tensor(1.5987)), (0.012657565939702799, tensor(1.5933)), (0.012675125220344245, tensor(1.5916)), (0.012692708860198049, tensor(1.5921)), (0.012710316893056664, tensor(1.5887)), (0.01272794935275943, tensor(1.5858)), (0.012745606273192623, tensor(1.5827)), (0.01276328768828953, tensor(1.5781)), (0.012780993632030516, tensor(1.5766)), (0.012798724138443079, tensor(1.5800)), (0.01281647924160193, tensor(1.5766)), (0.012834258975629042, tensor(1.5709)), (0.01285206337469373, tensor(1.5674)), (0.012869892473012708, tensor(1.5660)), (0.012887746304850156, tensor(1.5637)), (0.01290562490451779, tensor(1.5614)), (0.012923528306374924, tensor(1.5596)), (0.012941456544828533, tensor(1.5610)), (0.012959409654333336, tensor(1.5593)), (0.012977387669391834, tensor(1.5550)), (0.0129953906245544, tensor(1.5535)), (0.013013418554419336, tensor(1.5504)), (0.013031471493632941, tensor(1.5457)), (0.013049549476889577, tensor(1.5451)), (0.013067652538931733, tensor(1.5392)), (0.013085780714550101, tensor(1.5397)), (0.013103934038583634, tensor(1.5355)), (0.013122112545919608, tensor(1.5315)), (0.01314031627149371, tensor(1.5302)), (0.013158545250290081, tensor(1.5298)), (0.0131767995173414, tensor(1.5253)), (0.013195079107728942, tensor(1.5234)), (0.013213384056582652, tensor(1.5202)), (0.013231714399081202, tensor(1.5161)), (0.013250070170452075, tensor(1.5167)), (0.013268451405971618, tensor(1.5152)), (0.013286858140965117, tensor(1.5126)), (0.01330529041080686, tensor(1.5083)), (0.013323748250920218, tensor(1.5078)), (0.01334223169677769, tensor(1.5080)), (0.013360740783900994, tensor(1.5034)), (0.01337927554786112, tensor(1.5016)), (0.013397836024278409, tensor(1.4980)), (0.013416422248822613, tensor(1.4931)), (0.013435034257212968, tensor(1.4893)), (0.013453672085218263, tensor(1.4874)), (0.013472335768656902, tensor(1.4866)), (0.013491025343396988, tensor(1.4851)), (0.013509740845356374, tensor(1.4833)), (0.013528482310502745, tensor(1.4834)), (0.013547249774853679, tensor(1.4796)), (0.013566043274476719, tensor(1.4796)), (0.013584862845489447, tensor(1.4794)), (0.01360370852405955, tensor(1.4740)), (0.013622580346404883, tensor(1.4741)), (0.013641478348793546, tensor(1.4716)), (0.013660402567543955, tensor(1.4694)), (0.013679353039024908, tensor(1.4728)), (0.013698329799655658, tensor(1.4687)), (0.013717332885905976, tensor(1.4665)), (0.013736362334296225, tensor(1.4680)), (0.013755418181397439, tensor(1.4693)), (0.013774500463831376, tensor(1.4668)), (0.013793609218270607, tensor(1.4622)), (0.013812744481438568, tensor(1.4575)), (0.013831906290109648, tensor(1.4547)), (0.013851094681109247, tensor(1.4505)), (0.01387030969131385, tensor(1.4470)), (0.013889551357651105, tensor(1.4441)), (0.01390881971709988, tensor(1.4447)), (0.01392811480669035, tensor(1.4428)), (0.013947436663504054, tensor(1.4402)), (0.013966785324673976, tensor(1.4386)), (0.013986160827384615, tensor(1.4350)), (0.014005563208872047, tensor(1.4361)), (0.01402499250642401, tensor(1.4323)), (0.014044448757379972, tensor(1.4329)), (0.014063931999131193, tensor(1.4296)), (0.014083442269120807, tensor(1.4283)), (0.014102979604843895, tensor(1.4255)), (0.01412254404384755, tensor(1.4225)), (0.014142135623730952, tensor(1.4205)), (0.014161754382145439, tensor(1.4214)), (0.014181400356794587, tensor(1.4216)), (0.014201073585434272, tensor(1.4186)), (0.014220774105872747, tensor(1.4192)), (0.014240501955970717, tensor(1.4192)), (0.014260257173641409, tensor(1.4196)), (0.01428003979685064, tensor(1.4149)), (0.014299849863616907, tensor(1.4103)), (0.014319687412011436, tensor(1.4097)), (0.014339552480158273, tensor(1.4093)), (0.014359445106234355, tensor(1.4074)), (0.014379365328469574, tensor(1.4048)), (0.014399313185146858, tensor(1.4030)), (0.014419288714602248, tensor(1.4062)), (0.014439291955224962, tensor(1.4047)), (0.014459322945457473, tensor(1.4032)), (0.01447938172379559, tensor(1.3999)), (0.014499468328788519, tensor(1.3996)), (0.014519582799038944, tensor(1.4003)), (0.014539725173203106, tensor(1.3955)), (0.014559895489990867, tensor(1.3961)), (0.014580093788165792, tensor(1.3936)), (0.014600320106545217, tensor(1.3892)), (0.014620574484000334, tensor(1.3848)), (0.014640856959456255, tensor(1.3839)), (0.014661167571892094, tensor(1.3835)), (0.014681506360341032, tensor(1.3872)), (0.01470187336389041, tensor(1.3876)), (0.014722268621681784, tensor(1.3842)), (0.014742692172911012, tensor(1.3868)), (0.01476314405682833, tensor(1.3849)), (0.014783624312738419, tensor(1.3843)), (0.014804132980000488, tensor(1.3822)), (0.01482467009802835, tensor(1.3803)), (0.014845235706290491, tensor(1.3782)), (0.01486582984431015, tensor(1.3750)), (0.014886452551665397, tensor(1.3735)), (0.014907103867989204, tensor(1.3757)), (0.01492778383296953, tensor(1.3744)), (0.014948492486349383, tensor(1.3714)), (0.014969229867926915, tensor(1.3687)), (0.014989996017555475, tensor(1.3696)), (0.015010790975143712, tensor(1.3669)), (0.015031614780655627, tensor(1.3648)), (0.01505246747411067, tensor(1.3642)), (0.01507334909558381, tensor(1.3650)), (0.015094259685205598, tensor(1.3658)), (0.015115199283162267, tensor(1.3667)), (0.015136167929695792, tensor(1.3655)), (0.01515716566510398, tensor(1.3658)), (0.01517819252974054, tensor(1.3677)), (0.015199248564015158, tensor(1.3688)), (0.01522033380839358, tensor(1.3675)), (0.015241448303397694, tensor(1.3639)), (0.015262592089605592, tensor(1.3652)), (0.015283765207651666, tensor(1.3647)), (0.015304967698226677, tensor(1.3684)), (0.015326199602077832, tensor(1.3686)), (0.015347460960008868, tensor(1.3675)), (0.015368751812880124, tensor(1.3677)), (0.015390072201608625, tensor(1.3677)), (0.015411422167168157, tensor(1.3686)), (0.015432801750589349, tensor(1.3691)), (0.015454210992959747, tensor(1.3651)), (0.015475649935423899, tensor(1.3666)), (0.015497118619183431, tensor(1.3656)), (0.015518617085497122, tensor(1.3652)), (0.01554014537568099, tensor(1.3632)), (0.015561703531108374, tensor(1.3624)), (0.015583291593209998, tensor(1.3629)), (0.01560490960347407, tensor(1.3605)), (0.015626557603446348, tensor(1.3594)), (0.015648235634730227, tensor(1.3580)), (0.015669943738986815, tensor(1.3521)), (0.015691681957935015, tensor(1.3519)), (0.015713450333351607, tensor(1.3533)), (0.01573524890707132, tensor(1.3535)), (0.015757077720986924, tensor(1.3533)), (0.015778936817049304, tensor(1.3506)), (0.015800826237267546, tensor(1.3523)), (0.015822746023709, tensor(1.3505)), (0.015844696218499384, tensor(1.3502)), (0.015866676863822857, tensor(1.3517)), (0.015888688001922096, tensor(1.3504)), (0.015910729675098375, tensor(1.3515)), (0.015932801925711657, tensor(1.3522)), (0.015954904796180662, tensor(1.3489)), (0.01597703832898296, tensor(1.3460)), (0.01599920256665505, tensor(1.3492)), (0.01602139755179244, tensor(1.3453)), (0.016043623327049727, tensor(1.3463)), (0.01606587993514068, tensor(1.3461)), (0.016088167418838315, tensor(1.3478)), (0.016110485820975004, tensor(1.3488)), (0.016132835184442525, tensor(1.3476)), (0.01615521555219216, tensor(1.3476)), (0.016177626967234782, tensor(1.3466)), (0.016200069472640917, tensor(1.3459)), (0.016222543111540855, tensor(1.3488)), (0.01624504792712471, tensor(1.3495)), (0.016267583962642516, tensor(1.3505)), (0.016290151261404307, tensor(1.3491)), (0.016312749866780194, tensor(1.3480)), (0.016335379822200454, tensor(1.3469)), (0.01635804117115562, tensor(1.3465)), (0.016380733957196553, tensor(1.3467)), (0.016403458223934526, tensor(1.3473)), (0.016426214015041317, tensor(1.3464)), (0.016449001374249286, tensor(1.3443)), (0.01647182034535146, tensor(1.3444)), (0.016494670972201628, tensor(1.3437)), (0.016517553298714398, tensor(1.3443)), (0.016540467368865313, tensor(1.3411)), (0.01656341322669091, tensor(1.3423)), (0.016586390916288832, tensor(1.3421)), (0.01660940048181788, tensor(1.3416)), (0.016632441967498128, tensor(1.3440)), (0.01665551541761098, tensor(1.3437)), (0.01667862087649928, tensor(1.3408)), (0.016701758388567387, tensor(1.3398)), (0.016724927998281257, tensor(1.3388)), (0.016748129750168532, tensor(1.3366)), (0.016771363688818625, tensor(1.3377)), (0.016794629858882807, tensor(1.3381)), (0.01681792830507429, tensor(1.3387)), (0.01684125907216832, tensor(1.3401)), (0.01686462220500225, tensor(1.3416)), (0.01688801774847564, tensor(1.3417)), (0.01691144574755033, tensor(1.3387)), (0.016934906247250543, tensor(1.3392)), (0.016958399292662955, tensor(1.3366)), (0.016981924928936794, tensor(1.3393)), (0.01700548320128392, tensor(1.3386)), (0.0170290741549789, tensor(1.3392)), (0.017052697835359135, tensor(1.3400)), (0.017076354287824898, tensor(1.3393)), (0.017100043557839454, tensor(1.3402)), (0.01712376569092914, tensor(1.3371)), (0.017147520732683434, tensor(1.3382)), (0.017171308728755077, tensor(1.3370)), (0.01719512972486013, tensor(1.3339)), (0.01721898376677808, tensor(1.3343)), (0.01724287090035192, tensor(1.3361)), (0.017266791171488237, tensor(1.3381)), (0.017290744626157303, tensor(1.3357)), (0.01731473131039317, tensor(1.3386)), (0.017338751270293735, tensor(1.3385)), (0.01736280455202086, tensor(1.3403)), (0.017386891201800436, tensor(1.3420)), (0.017411011265922482, tensor(1.3452)), (0.017435164790741246, tensor(1.3454)), (0.01745935182267526, tensor(1.3472)), (0.017483572408207464, tensor(1.3486)), (0.017507826593885282, tensor(1.3462)), (0.017532114426320702, tensor(1.3463)), (0.017556435952190388, tensor(1.3471)), (0.01758079121823574, tensor(1.3488)), (0.017605180271263017, tensor(1.3481)), (0.017629603158143402, tensor(1.3487)), (0.017654059925813096, tensor(1.3533)), (0.017678550621273423, tensor(1.3493)), (0.017703075291590903, tensor(1.3434)), (0.017727633983897345, tensor(1.3428)), (0.017752226745389958, tensor(1.3427)), (0.017776853623331403, tensor(1.3426)), (0.017801514665049926, tensor(1.3429)), (0.017826209917939425, tensor(1.3437)), (0.017850939429459534, tensor(1.3401)), (0.01787570324713574, tensor(1.3376)), (0.01790050141855945, tensor(1.3366)), (0.017925333991388098, tensor(1.3394)), (0.01795020101334523, tensor(1.3408)), (0.017975102532220594, tensor(1.3402)), (0.01800003859587024, tensor(1.3402)), (0.018025009252216603, tensor(1.3422)), (0.0180500145492486, tensor(1.3400)), (0.018075054535021718, tensor(1.3422)), (0.01810012925765811, tensor(1.3428)), (0.018125238765346687, tensor(1.3397)), (0.018150383106343218, tensor(1.3398)), (0.018175562328970402, tensor(1.3370)), (0.018200776481617983, tensor(1.3384)), (0.018226025612742832, tensor(1.3376)), (0.01825130977086904, tensor(1.3423)), (0.01827662900458801, tensor(1.3430)), (0.018301983362558567, tensor(1.3453)), (0.018327372893507027, tensor(1.3432)), (0.0183527976462273, tensor(1.3416)), (0.018378257669580997, tensor(1.3411)), (0.0184037530124975, tensor(1.3407)), (0.01842928372397408, tensor(1.3394)), (0.018454849853075966, tensor(1.3441)), (0.01848045144893647, tensor(1.3472)), (0.018506088560757045, tensor(1.3485)), (0.018531761237807417, tensor(1.3502)), (0.018557469529425656, tensor(1.3499)), (0.018583213485018266, tensor(1.3490)), (0.018608993154060307, tensor(1.3489)), (0.018634808586095463, tensor(1.3482)), (0.01866065983073615, tensor(1.3479)), (0.01868654693766361, tensor(1.3465)), (0.018712469956628, tensor(1.3462)), (0.01873842893744851, tensor(1.3428)), (0.018764423930013423, tensor(1.3461)), (0.018790454984280235, tensor(1.3442)), (0.018816522150275756, tensor(1.3412)), (0.018842625478096175, tensor(1.3408)), (0.018868765017907203, tensor(1.3413)), (0.018894940819944125, tensor(1.3405)), (0.01892115293451192, tensor(1.3376)), (0.018947401411985355, tensor(1.3367)), (0.01897368630280908, tensor(1.3372)), (0.019000007657497722, tensor(1.3358)), (0.019026365526635985, tensor(1.3340)), (0.01905275996087875, tensor(1.3363)), (0.019079191010951166, tensor(1.3376)), (0.019105658727648748, tensor(1.3377)), (0.01913216316183749, tensor(1.3367)), (0.01915870436445393, tensor(1.3371)), (0.019185282386505288, tensor(1.3389)), (0.019211897279069533, tensor(1.3370)), (0.019238549093295493, tensor(1.3367)), (0.019265237880402956, tensor(1.3357)), (0.019291963691682765, tensor(1.3393)), (0.01931872657849691, tensor(1.3404)), (0.01934552659227864, tensor(1.3381)), (0.019372363784532554, tensor(1.3377)), (0.019399238206834698, tensor(1.3406)), (0.019426149910832666, tensor(1.3417)), (0.01945309894824571, tensor(1.3410)), (0.01948008537086482, tensor(1.3438)), (0.019507109230552835, tensor(1.3441)), (0.019534170579244548, tensor(1.3419)), (0.019561269468946787, tensor(1.3409)), (0.01958840595173854, tensor(1.3404)), (0.019615580079771027, tensor(1.3396)), (0.019642791905267826, tensor(1.3369)), (0.019670041480524966, tensor(1.3380)), (0.019697328857911013, tensor(1.3384)), (0.019724654089867184, tensor(1.3383)), (0.019752017228907452, tensor(1.3385)), (0.01977941832761863, tensor(1.3387)), (0.019806857438660494, tensor(1.3420)), (0.019834334614765862, tensor(1.3431)), (0.01986184990874072, tensor(1.3465)), (0.019889403373464287, tensor(1.3472)), (0.019916995061889164, tensor(1.3485)), (0.01994462502704139, tensor(1.3486)), (0.01997229332202058, tensor(1.3488)), (0.02, tensor(1.3483)), (0.020027745114226694, tensor(1.3456)), (0.020055528718021555, tensor(1.3437)), (0.020083350864779463, tensor(1.3416)), (0.020111211607969363, tensor(1.3448)), (0.02013911100113438, tensor(1.3449)), (0.020167049097891902, tensor(1.3459)), (0.020195025951933718, tensor(1.3462)), (0.020223041617026084, tensor(1.3445)), (0.02025109614700986, tensor(1.3474)), (0.020279189595800582, tensor(1.3474)), (0.020307322017388593, tensor(1.3461)), (0.020335493465839124, tensor(1.3435)), (0.020363703995292415, tensor(1.3462)), (0.02039195365996381, tensor(1.3457)), (0.020420242514143868, tensor(1.3453)), (0.020448570612198447, tensor(1.3457)), (0.020476938008568847, tensor(1.3495)), (0.020505344757771878, tensor(1.3514)), (0.02053379091439998, tensor(1.3533)), (0.020562276533121333, tensor(1.3581)), (0.020590801668679944, tensor(1.3639)), (0.02061936637589578, tensor(1.3667)), (0.02064797070966484, tensor(1.3653)), (0.02067661472495929, tensor(1.3698)), (0.020705298476827554, tensor(1.3702)), (0.02073402202039442, tensor(1.3711)), (0.020762785410861146, tensor(1.3738)), (0.020791588703505576, tensor(1.3739)), (0.02082043195368223, tensor(1.3726)), (0.02084931521682243, tensor(1.3714)), (0.02087823854843438, tensor(1.3757)), (0.020907202004103297, tensor(1.3763)), (0.020936205639491518, tensor(1.3810)), (0.020965249510338575, tensor(1.3834)), (0.020994333672461347, tensor(1.3803)), (0.021023458181754134, tensor(1.3747)), (0.021052623094188774, tensor(1.3747)), (0.02108182846581476, tensor(1.3758)), (0.021111074352759336, tensor(1.3798)), (0.02114036081122761, tensor(1.3848)), (0.021169687897502655, tensor(1.3860)), (0.021199055667945638, tensor(1.3873)), (0.021228464178995893, tensor(1.3863)), (0.021257913487171067, tensor(1.3879)), (0.0212874036490672, tensor(1.3870)), (0.02131693472135885, tensor(1.3862)), (0.021346506760799203, tensor(1.3848)), (0.021376119824220163, tensor(1.3873)), (0.02140577396853248, tensor(1.3890)), (0.021435469250725862, tensor(1.3899)), (0.02146520572786907, tensor(1.3887)), (0.02149498345711003, tensor(1.3886)), (0.021524802495675944, tensor(1.3935)), (0.02155466290087342, tensor(1.3959)), (0.021584564730088546, tensor(1.3954)), (0.02161450804078703, tensor(1.3988)), (0.0216444928905143, tensor(1.3979)), (0.021674519336895605, tensor(1.4013)), (0.021704587437636143, tensor(1.4016)), (0.021734697250521164, tensor(1.4019)), (0.02176484883341608, tensor(1.4005)), (0.021795042244266566, tensor(1.3968)), (0.0218252775410987, tensor(1.3992)), (0.021855554782019046, tensor(1.4014)), (0.021885874025214788, tensor(1.4004)), (0.021916235328953815, tensor(1.4017)), (0.02194663875158486, tensor(1.4012)), (0.02197708435153759, tensor(1.4028)), (0.022007572187322744, tensor(1.4068)), (0.022038102317532213, tensor(1.4082)), (0.022068674800839183, tensor(1.4075)), (0.022099289695998232, tensor(1.4083)), (0.022129947061845442, tensor(1.4093)), (0.022160646957298517, tensor(1.4071)), (0.022191389441356898, tensor(1.4073)), (0.022222174573101872, tensor(1.4087)), (0.02225300241169668, tensor(1.4086)), (0.022283873016386645, tensor(1.4064)), (0.02231478644649928, tensor(1.4116)), (0.022345742761444395, tensor(1.4117)), (0.022376742020714224, tensor(1.4102)), (0.02240778428388352, tensor(1.4095)), (0.022438869610609688, tensor(1.4145)), (0.022469998060632896, tensor(1.4128)), (0.022501169693776187, tensor(1.4115)), (0.022532384569945586, tensor(1.4102)), (0.022563642749130225, tensor(1.4114)), (0.02259494429140247, tensor(1.4107)), (0.022626289256918005, tensor(1.4080)), (0.022657677705915973, tensor(1.4116)), (0.02268910969871908, tensor(1.4119)), (0.022720585295733727, tensor(1.4094)), (0.02275210455745009, tensor(1.4084)), (0.0227836675444423, tensor(1.4058)), (0.022815274317368472, tensor(1.4057)), (0.022846924936970905, tensor(1.4031)), (0.02287861946407615, tensor(1.4055)), (0.02291035795959514, tensor(1.4055)), (0.022942140484523303, tensor(1.4037)), (0.0229739670999407, tensor(1.4077)), (0.023005837867012106, tensor(1.4113)), (0.023037752846987152, tensor(1.4141)), (0.02306971210120045, tensor(1.4109)), (0.02310171569107168, tensor(1.4102)), (0.023133763678105747, tensor(1.4094)), (0.023165856123892863, tensor(1.4118)), (0.023197993090108688, tensor(1.4099)), (0.023230174638514442, tensor(1.4082)), (0.023262400830957018, tensor(1.4086)), (0.023294671729369117, tensor(1.4100)), (0.023326987395769345, tensor(1.4087)), (0.023359347892262353, tensor(1.4083)), (0.023391753281038947, tensor(1.4083)), (0.023424203624376198, tensor(1.4062)), (0.023456698984637578, tensor(1.4049)), (0.02348923942427307, tensor(1.4067)), (0.023521825005819296, tensor(1.4067)), (0.02355445579189963, tensor(1.4067)), (0.02358713184522432, tensor(1.4082)), (0.023619853228590608, tensor(1.4071)), (0.023652620004882854, tensor(1.4048)), (0.023685432237072656, tensor(1.4050)), (0.023718289988218958, tensor(1.4057)), (0.023751193321468207, tensor(1.4048)), (0.02378414230005442, tensor(1.4058)), (0.023817136987299366, tensor(1.4046)), (0.023850177446612632, tensor(1.4068)), (0.02388326374149179, tensor(1.4078)), (0.023916395935522482, tensor(1.4088)), (0.02394957409237857, tensor(1.4065)), (0.023982798275822254, tensor(1.4066)), (0.024016068549704173, tensor(1.4032)), (0.024049384977963554, tensor(1.4075)), (0.024082747624628316, tensor(1.4129)), (0.02411615655381521, tensor(1.4122)), (0.02414961182972993, tensor(1.4132)), (0.02418311351666723, tensor(1.4130)), (0.024216661679011077, tensor(1.4141)), (0.024250256381234743, tensor(1.4107)), (0.02428389768790094, tensor(1.4130)), (0.024317585663661944, tensor(1.4162)), (0.024351320373259724, tensor(1.4149)), (0.024385101881526063, tensor(1.4127)), (0.024418930253382688, tensor(1.4089)), (0.024452805553841373, tensor(1.4040)), (0.02448672784800409, tensor(1.4068)), (0.024520697201063126, tensor(1.4049)), (0.02455471367830121, tensor(1.4035)), (0.024588777345091618, tensor(1.4058)), (0.024622888266898325, tensor(1.4029)), (0.024657046509276134, tensor(1.4040)), (0.02469125213787077, tensor(1.4063)), (0.02472550521841903, tensor(1.4049)), (0.024759805816748914, tensor(1.4027)), (0.024794153998779735, tensor(1.4026)), (0.024828549830522247, tensor(1.4052)), (0.024862993378078794, tensor(1.4042)), (0.024897484707643407, tensor(1.4022)), (0.024932023885501947, tensor(1.4005)), (0.02496661097803224, tensor(1.3998)), (0.025001246051704184, tensor(1.4015)), (0.02503592917307989, tensor(1.4012)), (0.02507066040881381, tensor(1.4007)), (0.025105439825652866, tensor(1.3995)), (0.025140267490436567, tensor(1.3991)), (0.025175143470097156, tensor(1.3974)), (0.025210067831659716, tensor(1.3990)), (0.025245040642242315, tensor(1.3967)), (0.025280061969056137, tensor(1.4014)), (0.025315131879405598, tensor(1.4038)), (0.02535025044068849, tensor(1.4029)), (0.0253854177203961, tensor(1.4055)), (0.025420633786113332, tensor(1.4066)), (0.02545589870551886, tensor(1.4062)), (0.025491212546385245, tensor(1.4044)), (0.025526575376579062, tensor(1.4073)), (0.02556198726406103, tensor(1.4071)), (0.02559744827688616, tensor(1.4108)), (0.02563295848320386, tensor(1.4116)), (0.025668517951258085, tensor(1.4089)), (0.02570412674938746, tensor(1.4073)), (0.025739784946025416, tensor(1.4073)), (0.02577549260970031, tensor(1.4060)), (0.02581124980903558, tensor(1.4056)), (0.025847056612749848, tensor(1.4074)), (0.02588291308965707, tensor(1.4075)), (0.02591881930866667, tensor(1.4091)), (0.025954775338783667, tensor(1.4044)), (0.0259907812491088, tensor(1.4034)), (0.026026837108838668, tensor(1.4039)), (0.026062942987265882, tensor(1.4027)), (0.02609909895377915, tensor(1.4047)), (0.026135305077863467, tensor(1.4043)), (0.026171561429100203, tensor(1.4003)), (0.026207868077167264, tensor(1.4000)), (0.026244225091839216, tensor(1.4008)), (0.026280632542987417, tensor(1.4009)), (0.026317090500580162, tensor(1.4033)), (0.0263535990346828, tensor(1.4023)), (0.026390158215457885, tensor(1.4030)), (0.0264267681131653, tensor(1.4045)), (0.0264634287981624, tensor(1.4056)), (0.026500140340904147, tensor(1.4060)), (0.026536902811943232, tensor(1.4080)), (0.02657371628193023, tensor(1.4058)), (0.02661058082161372, tensor(1.4078)), (0.026647496501840437, tensor(1.4088)), (0.026684463393555378, tensor(1.4065)), (0.026721481567801988, tensor(1.4040)), (0.02675855109572224, tensor(1.4025)), (0.026795672048556818, tensor(1.4046)), (0.026832844497645225, tensor(1.4059)), (0.026870068514425936, tensor(1.4102)), (0.026907344170436522, tensor(1.4125)), (0.026944671537313804, tensor(1.4132)), (0.026982050686793976, tensor(1.4128)), (0.02701948169071275, tensor(1.4122)), (0.027056964621005486, tensor(1.4084)), (0.027094499549707357, tensor(1.4114)), (0.027132086548953438, tensor(1.4142)), (0.027169725690978894, tensor(1.4178)), (0.0272074170481191, tensor(1.4192)), (0.027245160692809762, tensor(1.4218)), (0.027282956697587093, tensor(1.4176)), (0.02732080513508791, tensor(1.4183)), (0.027358706078049817, tensor(1.4172)), (0.027396659599311316, tensor(1.4177)), (0.027434665771811945, tensor(1.4211)), (0.02747272466859245, tensor(1.4173)), (0.027510836362794874, tensor(1.4162)), (0.027549000927662753, tensor(1.4221)), (0.027587218436541213, tensor(1.4212)), (0.027625488962877136, tensor(1.4226)), (0.027663812580219296, tensor(1.4223)), (0.027702189362218493, tensor(1.4199)), (0.0277406193826277, tensor(1.4177)), (0.02777910271530221, tensor(1.4201)), (0.02781763943419976, tensor(1.4206)), (0.0278562296133807, tensor(1.4201)), (0.02789487332700811, tensor(1.4183)), (0.02793357064934795, tensor(1.4182)), (0.02797232165476923, tensor(1.4200)), (0.028011126417744094, tensor(1.4211)), (0.02804998501284802, tensor(1.4216)), (0.028088897514759945, tensor(1.4247)), (0.028127863998262385, tensor(1.4258)), (0.028166884538241614, tensor(1.4265)), (0.02820595920968779, tensor(1.4269)), (0.0282450880876951, tensor(1.4266)), (0.028284271247461905, tensor(1.4275)), (0.028323508764290878, tensor(1.4262)), (0.028362800713589174, tensor(1.4240)), (0.028402147170868544, tensor(1.4237)), (0.028441548211745493, tensor(1.4204)), (0.028481003911941433, tensor(1.4235)), (0.028520514347282817, tensor(1.4294)), (0.02856007959370128, tensor(1.4316)), (0.028599699727233814, tensor(1.4335)), (0.028639374824022873, tensor(1.4312)), (0.028679104960316545, tensor(1.4310)), (0.02871889021246871, tensor(1.4330)), (0.02875873065693915, tensor(1.4349)), (0.028798626370293717, tensor(1.4334)), (0.028838577429204496, tensor(1.4338)), (0.028878583910449923, tensor(1.4339)), (0.028918645890914946, tensor(1.4329)), (0.02895876344759118, tensor(1.4342)), (0.028998936657577037, tensor(1.4345)), (0.029039165598077888, tensor(1.4311)), (0.029079450346406212, tensor(1.4313)), (0.029119790979981734, tensor(1.4278)), (0.029160187576331584, tensor(1.4263)), (0.029200640213090434, tensor(1.4262)), (0.029241148968000667, tensor(1.4303)), (0.02928171391891251, tensor(1.4276)), (0.029322335143784187, tensor(1.4262)), (0.029363012720682063, tensor(1.4305)), (0.02940374672778082, tensor(1.4333)), (0.02944453724336357, tensor(1.4310)), (0.029485384345822024, tensor(1.4284)), (0.02952628811365666, tensor(1.4306)), (0.029567248625476838, tensor(1.4359)), (0.029608265960000983, tensor(1.4353)), (0.029649340196056705, tensor(1.4380)), (0.029690471412580983, tensor(1.4375)), (0.0297316596886203, tensor(1.4397)), (0.029772905103330794, tensor(1.4408)), (0.029814207735978412, tensor(1.4410)), (0.02985556766593906, tensor(1.4400)), (0.02989698497269877, tensor(1.4391)), (0.02993845973585383, tensor(1.4413)), (0.029979992035110953, tensor(1.4418)), (0.030021581950287424, tensor(1.4400)), (0.030063229561311258, tensor(1.4449)), (0.03010493494822135, tensor(1.4454)), (0.03014669819116762, tensor(1.4467)), (0.030188519370411195, tensor(1.4485)), (0.030230398566324534, tensor(1.4460)), (0.030272335859391583, tensor(1.4459)), (0.030314331330207965, tensor(1.4436)), (0.030356385059481083, tensor(1.4467)), (0.030398497128030316, tensor(1.4478)), (0.030440667616787164, tensor(1.4484)), (0.030482896606795387, tensor(1.4473)), (0.030525184179211188, tensor(1.4467)), (0.030567530415303336, tensor(1.4463)), (0.030609935396453354, tensor(1.4491)), (0.030652399204155665, tensor(1.4529)), (0.03069492192001774, tensor(1.4585)), (0.03073750362576025, tensor(1.4600)), (0.03078014440321725, tensor(1.4655)), (0.030822844334336318, tensor(1.4691)), (0.030865603501178694, tensor(1.4741)), (0.03090842198591949, tensor(1.4770)), (0.030951299870847798, tensor(1.4798)), (0.030994237238366855, tensor(1.4825)), (0.03103723417099424, tensor(1.4838)), (0.03108029075136198, tensor(1.4874)), (0.03112340706221674, tensor(1.4922)), (0.03116658318641999, tensor(1.4958)), (0.03120981920694814, tensor(1.5018)), (0.031253115206892695, tensor(1.5064)), (0.03129647126946045, tensor(1.5115)), (0.03133988747797363, tensor(1.5141)), (0.03138336391587003, tensor(1.5159)), (0.03142690066670321, tensor(1.5153)), (0.031470497814142635, tensor(1.5159)), (0.03151415544197385, tensor(1.5171)), (0.03155787363409861, tensor(1.5171)), (0.031601652474535086, tensor(1.5197)), (0.03164549204741799, tensor(1.5216)), (0.03168939243699876, tensor(1.5218)), (0.03173335372764571, tensor(1.5166)), (0.031777376003844185, tensor(1.5135)), (0.03182145935019674, tensor(1.5142)), (0.031865603851423306, tensor(1.5197)), (0.03190980959236132, tensor(1.5163)), (0.031954076657965916, tensor(1.5136)), (0.0319984051333101, tensor(1.5154)), (0.03204279510358488, tensor(1.5145)), (0.03208724665409945, tensor(1.5135)), (0.03213175987028136, tensor(1.5141)), (0.03217633483767663, tensor(1.5178)), (0.03222097164195001, tensor(1.5206)), (0.03226567036888505, tensor(1.5196)), (0.03231043110438432, tensor(1.5191)), (0.032355253934469565, tensor(1.5202)), (0.032400138945281834, tensor(1.5208)), (0.03244508622308171, tensor(1.5179)), (0.03249009585424942, tensor(1.5129)), (0.03253516792528503, tensor(1.5124)), (0.032580302522808614, tensor(1.5123)), (0.03262549973356039, tensor(1.5092)), (0.03267075964440091, tensor(1.5105)), (0.03271608234231124, tensor(1.5094)), (0.032761467914393105, tensor(1.5118)), (0.03280691644786905, tensor(1.5132)), (0.032852428030082634, tensor(1.5157)), (0.03289800274849857, tensor(1.5139)), (0.03294364069070292, tensor(1.5147)), (0.032989341944403255, tensor(1.5199)), (0.033035106597428796, tensor(1.5162)), (0.033080934737730626, tensor(1.5125)), (0.03312682645338182, tensor(1.5100)), (0.033172781832577665, tensor(1.5097)), (0.03321880096363576, tensor(1.5050)), (0.033264883934996256, tensor(1.5039)), (0.03331103083522196, tensor(1.5020)), (0.03335724175299856, tensor(1.5026)), (0.033403516777134774, tensor(1.5050)), (0.033449855996562514, tensor(1.5037)), (0.033496259500337064, tensor(1.5021)), (0.03354272737763725, tensor(1.5037)), (0.033589259717765614, tensor(1.5055)), (0.03363585661014858, tensor(1.5050)), (0.03368251814433664, tensor(1.5051)), (0.0337292444100045, tensor(1.5028)), (0.03377603549695128, tensor(1.5024)), (0.03382289149510066, tensor(1.5086)), (0.033869812494501085, tensor(1.5123)), (0.03391679858532591, tensor(1.5166)), (0.03396384985787359, tensor(1.5166)), (0.03401096640256784, tensor(1.5161)), (0.0340581483099578, tensor(1.5149)), (0.03410539567071827, tensor(1.5163)), (0.034152708575649796, tensor(1.5145)), (0.03420008711567891, tensor(1.5147)), (0.03424753138185828, tensor(1.5145)), (0.03429504146536687, tensor(1.5162)), (0.034342617457510154, tensor(1.5163)), (0.03439025944972026, tensor(1.5177)), (0.03443796753355616, tensor(1.5163)), (0.03448574180070384, tensor(1.5134)), (0.034533582342976474, tensor(1.5100)), (0.03458148925231461, tensor(1.5099)), (0.03462946262078634, tensor(1.5072)), (0.03467750254058747, tensor(1.5037)), (0.03472560910404172, tensor(1.5008)), (0.03477378240360087, tensor(1.5037)), (0.034822022531844965, tensor(1.5030)), (0.03487032958148249, tensor(1.5036)), (0.03491870364535052, tensor(1.5018)), (0.03496714481641493, tensor(1.5026)), (0.035015653187770564, tensor(1.5039)), (0.035064228852641405, tensor(1.5011)), (0.035112871904380775, tensor(1.4985)), (0.03516158243647148, tensor(1.4997)), (0.03521036054252604, tensor(1.4975)), (0.03525920631628681, tensor(1.4956)), (0.03530811985162619, tensor(1.4963)), (0.035357101242546846, tensor(1.4933)), (0.035406150583181806, tensor(1.4921)), (0.03545526796779469, tensor(1.4940)), (0.035504453490779915, tensor(1.4916)), (0.03555370724666281, tensor(1.4974)), (0.03560302933009986, tensor(1.4987)), (0.03565241983587885, tensor(1.4984)), (0.035701878858919074, tensor(1.4998)), (0.03575140649427148, tensor(1.4998)), (0.0358010028371189, tensor(1.5015)), (0.035850667982776196, tensor(1.5005)), (0.03590040202669046, tensor(1.5009)), (0.035950205064441194, tensor(1.5005)), (0.03600007719174048, tensor(1.4984)), (0.036050018504433214, tensor(1.5020)), (0.0361000290984972, tensor(1.5024)), (0.036150109070043436, tensor(1.5031)), (0.03620025851531622, tensor(1.5045)), (0.03625047753069338, tensor(1.5087)), (0.036300766212686436, tensor(1.5125)), (0.036351124657940805, tensor(1.5157)), (0.03640155296323597, tensor(1.5130)), (0.036452051225485664, tensor(1.5135)), (0.03650261954173808, tensor(1.5091)), (0.036553258009176026, tensor(1.5090)), (0.03660396672511714, tensor(1.5128)), (0.036654745787014054, tensor(1.5119)), (0.0367055952924546, tensor(1.5109)), (0.036756515339161994, tensor(1.5104)), (0.036807506024995, tensor(1.5144)), (0.03685856744794815, tensor(1.5170)), (0.03690969970615193, tensor(1.5153)), (0.03696090289787293, tensor(1.5126)), (0.03701217712151409, tensor(1.5170)), (0.037063522475614834, tensor(1.5142)), (0.037114939058851305, tensor(1.5141)), (0.037166426970036526, tensor(1.5151)), (0.037217986308120614, tensor(1.5131)), (0.037269617172190926, tensor(1.5134)), (0.0373213196614723, tensor(1.5153)), (0.03737309387532722, tensor(1.5118)), (0.037424939913256, tensor(1.5098)), (0.03747685787489702, tensor(1.5068)), (0.037528847860026845, tensor(1.5093)), (0.03758090996856047, tensor(1.5114)), (0.037633044300551505, tensor(1.5097)), (0.037685250956192344, tensor(1.5119)), (0.037737530035814405, tensor(1.5122)), (0.037789881639888244, tensor(1.5159)), (0.03784230586902384, tensor(1.5155)), (0.03789480282397071, tensor(1.5181)), (0.03794737260561816, tensor(1.5212)), (0.03800001531499544, tensor(1.5198)), (0.03805273105327196, tensor(1.5187)), (0.038105519921757494, tensor(1.5185)), (0.038158382021902325, tensor(1.5237)), (0.038211317455297496, tensor(1.5250)), (0.03826432632367497, tensor(1.5265)), (0.03831740872890786, tensor(1.5257)), (0.038370564773010575, tensor(1.5255)), (0.03842379455813907, tensor(1.5234)), (0.03847709818659099, tensor(1.5240)), (0.03853047576080591, tensor(1.5223)), (0.03858392738336553, tensor(1.5239)), (0.03863745315699382, tensor(1.5213)), (0.03869105318455728, tensor(1.5208)), (0.03874472756906511, tensor(1.5253)), (0.038798476413669396, tensor(1.5285)), (0.03885229982166533, tensor(1.5289)), (0.03890619789649142, tensor(1.5297)), (0.03896017074172964, tensor(1.5287)), (0.03901421846110567, tensor(1.5282)), (0.039068341158489096, tensor(1.5279)), (0.039122538937893574, tensor(1.5282)), (0.03917681190347708, tensor(1.5268)), (0.039231160159542054, tensor(1.5278)), (0.03928558381053565, tensor(1.5274)), (0.03934008296104993, tensor(1.5273)), (0.039394657715822026, tensor(1.5290)), (0.03944930817973437, tensor(1.5268)), (0.039504034457814904, tensor(1.5255)), (0.03955883665523726, tensor(1.5267)), (0.03961371487732099, tensor(1.5235)), (0.039668669229531724, tensor(1.5263)), (0.03972369981748144, tensor(1.5243)), (0.039778806746928574, tensor(1.5230)), (0.03983399012377833, tensor(1.5201)), (0.03988925005408278, tensor(1.5231)), (0.03994458664404116, tensor(1.5237))]
******

*** 2019-01-03 14:53:56,530 - code.resnet_fastai - DEBUG ***
Best LR: 0.01719512972486013
******

*** 2019-01-03 14:53:56,567 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2019-01-03 14:53:56,570 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:56,570 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2019-01-03 14:53:56,579 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:56,579 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2019-01-03 14:53:56,665 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,687 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXGeneral:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXGeneral ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,693 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXGeneral:style=italic:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXGeneral ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,694 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXGeneral:style=normal:variant=normal:weight=bold:stretch=normal:size=10.0 to STIXGeneral ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf') with score of 0.000000.
******

*** 2019-01-03 14:53:56,711 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXNonUnicode:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXNonUnicode ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,716 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXNonUnicode:style=italic:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXNonUnicode ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,717 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXNonUnicode:style=normal:variant=normal:weight=bold:stretch=normal:size=10.0 to STIXNonUnicode ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf') with score of 0.000000.
******

*** 2019-01-03 14:53:56,730 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeOneSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeOneSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,735 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeTwoSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeTwoSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,752 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeThreeSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeThreeSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,757 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeFourSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeFourSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,765 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeFiveSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeFiveSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,771 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmsy10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmsy10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,776 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmr10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmr10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,781 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmtt10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmtt10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,786 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmmi10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmmi10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,791 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmb10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmb10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,795 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmss10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmss10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,801 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmex10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmex10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,807 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,813 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans:style=italic:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf') with score of 0.150000.
******

*** 2019-01-03 14:53:56,814 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans:style=normal:variant=normal:weight=bold:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf') with score of 0.000000.
******

*** 2019-01-03 14:53:56,821 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans Mono:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans Mono ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:56,826 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans Display:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans Display ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf') with score of 0.050000.
******

*** 2019-01-03 14:53:57,024 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:57,024 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2019-01-03 14:53:57,025 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:57,026 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2019-01-03 14:53:57,100 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2019-01-03 14:53:57,102 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:57,102 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2019-01-03 14:53:57,103 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:57,103 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2019-01-03 14:53:57,111 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:57,111 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2019-01-03 14:53:57,113 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2019-01-03 14:53:57,113 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2019-01-03 14:53:57,134 - code.resnet_fastai - INFO ***
Start model fitting: Stage 1
******

*** 2019-01-03 14:53:57,134 - code.resnet_fastai - DEBUG ***
LR: 0.012036590807402091
******

2         1.523748                
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
[0.001204 0.001204 0.012037]
epoch     train_loss  valid_loss  fbeta   
1         1.328398    1.220479    0.251262  
2         1.118220    1.038640    0.324611  
*** 2019-01-03 15:08:39,726 - code.resnet_fastai - INFO ***
Complete model fitting: Stage 1
******

*** 2019-01-03 15:08:39,857 - code.resnet_fastai - INFO ***
Stage 1 model saved.
******

*** 2019-01-03 15:08:39,860 - code.resnet_fastai - DEBUG ***
Unfreezing model
******

*** 2019-01-03 15:08:39,860 - code.resnet_fastai - DEBUG ***
Start finding LR
******

3         1.004534    0.933248    0.330777  
epoch     train_loss  valid_loss  fbeta   
1         0.969437                
*** 2019-01-03 15:15:56,526 - code.resnet_fastai - DEBUG ***
[(1e-05, tensor(1.0730)), (1.0010992159842042e-05, tensor(1.0638)), (1.002199640244188e-05, tensor(1.0373)), (1.003301274108108e-05, tensor(1.0116)), (1.00440411890558e-05, tensor(1.0021)), (1.0055081759676814e-05, tensor(0.9862)), (1.006613446626953e-05, tensor(0.9879)), (1.0077199322174e-05, tensor(0.9822)), (1.0088276340744945e-05, tensor(0.9945)), (1.009936553535176e-05, tensor(0.9863)), (1.0110466919378537e-05, tensor(0.9827)), (1.0121580506224084e-05, tensor(0.9852)), (1.0132706309301935e-05, tensor(0.9854)), (1.0143844342040364e-05, tensor(0.9863)), (1.0154994617882412e-05, tensor(0.9872)), (1.0166157150285893e-05, tensor(0.9809)), (1.017733195272342e-05, tensor(0.9837)), (1.0188519038682403e-05, tensor(0.9853)), (1.0199718421665091e-05, tensor(0.9873)), (1.0210930115188564e-05, tensor(1.0014)), (1.0222154132784772e-05, tensor(0.9979)), (1.0233390488000525e-05, tensor(1.0000)), (1.0244639194397536e-05, tensor(0.9991)), (1.0255900265552423e-05, tensor(0.9997)), (1.026717371505672e-05, tensor(1.0053)), (1.027845955651691e-05, tensor(1.0068)), (1.0289757803554428e-05, tensor(1.0062)), (1.0301068469805684e-05, tensor(1.0121)), (1.0312391568922076e-05, tensor(1.0134)), (1.0323727114570006e-05, tensor(1.0123)), (1.0335075120430903e-05, tensor(1.0051)), (1.0346435600201228e-05, tensor(1.0081)), (1.0357808567592507e-05, tensor(1.0048)), (1.0369194036331331e-05, tensor(1.0089)), (1.0380592020159379e-05, tensor(1.0029)), (1.039200253283344e-05, tensor(1.0002)), (1.040342558812542e-05, tensor(0.9983)), (1.0414861199822364e-05, tensor(0.9965)), (1.0426309381726475e-05, tensor(1.0007)), (1.0437770147655127e-05, tensor(0.9960)), (1.0449243511440876e-05, tensor(0.9954)), (1.0460729486931493e-05, tensor(0.9945)), (1.0472228087989962e-05, tensor(0.9911)), (1.0483739328494511e-05, tensor(0.9912)), (1.0495263222338622e-05, tensor(0.9929)), (1.0506799783431045e-05, tensor(0.9997)), (1.0518349025695825e-05, tensor(0.9983)), (1.0529910963072307e-05, tensor(0.9981)), (1.054148560951516e-05, tensor(0.9995)), (1.0553072978994396e-05, tensor(1.0002)), (1.056467308549538e-05, tensor(1.0016)), (1.0576285943018848e-05, tensor(0.9999)), (1.0587911565580927e-05, tensor(0.9984)), (1.0599549967213151e-05, tensor(0.9997)), (1.0611201161962481e-05, tensor(1.0013)), (1.0622865163891314e-05, tensor(0.9983)), (1.0634541987077509e-05, tensor(0.9994)), (1.0646231645614394e-05, tensor(0.9934)), (1.0657934153610792e-05, tensor(0.9956)), (1.0669649525191035e-05, tensor(1.0000)), (1.0681377774494981e-05, tensor(0.9986)), (1.0693118915678027e-05, tensor(1.0013)), (1.0704872962911135e-05, tensor(1.0035)), (1.071663993038084e-05, tensor(1.0026)), (1.0728419832289274e-05, tensor(1.0008)), (1.0740212682854178e-05, tensor(1.0012)), (1.0752018496308922e-05, tensor(1.0042)), (1.0763837286902524e-05, tensor(1.0056)), (1.0775669068899658e-05, tensor(1.0054)), (1.0787513856580688e-05, tensor(1.0028)), (1.0799371664241663e-05, tensor(1.0011)), (1.0811242506194357e-05, tensor(0.9991)), (1.0823126396766273e-05, tensor(0.9969)), (1.0835023350300657e-05, tensor(0.9959)), (1.0846933381156532e-05, tensor(0.9966)), (1.0858856503708696e-05, tensor(0.9965)), (1.0870792732347753e-05, tensor(0.9963)), (1.0882742081480117e-05, tensor(0.9950)), (1.0894704565528051e-05, tensor(0.9933)), (1.090668019892966e-05, tensor(0.9930)), (1.0918668996138925e-05, tensor(0.9923)), (1.0930670971625713e-05, tensor(0.9922)), (1.09426861398758e-05, tensor(0.9958)), (1.095471451539088e-05, tensor(0.9980)), (1.096675611268859e-05, tensor(0.9973)), (1.0978810946302525e-05, tensor(0.9962)), (1.0990879030782256e-05, tensor(0.9940)), (1.1002960380693344e-05, tensor(0.9922)), (1.1015055010617366e-05, tensor(0.9921)), (1.1027162935151922e-05, tensor(0.9938)), (1.1039284168910664e-05, tensor(0.9944)), (1.1051418726523301e-05, tensor(0.9915)), (1.106356662263563e-05, tensor(0.9887)), (1.1075727871909536e-05, tensor(0.9868)), (1.1087902489023035e-05, tensor(0.9876)), (1.1100090488670263e-05, tensor(0.9893)), (1.111229188556152e-05, tensor(0.9872)), (1.1124506694423272e-05, tensor(0.9885)), (1.1136734929998167e-05, tensor(0.9869)), (1.1148976607045063e-05, tensor(0.9808)), (1.1161231740339045e-05, tensor(0.9793)), (1.117350034467143e-05, tensor(0.9819)), (1.1185782434849803e-05, tensor(0.9823)), (1.1198078025698021e-05, tensor(0.9843)), (1.1210387132056231e-05, tensor(0.9836)), (1.1222709768780901e-05, tensor(0.9855)), (1.123504595074483e-05, tensor(0.9851)), (1.1247395692837155e-05, tensor(0.9861)), (1.1259759009963389e-05, tensor(0.9838)), (1.1272135917045429e-05, tensor(0.9864)), (1.1284526429021566e-05, tensor(0.9879)), (1.1296930560846517e-05, tensor(0.9885)), (1.1309348327491443e-05, tensor(0.9874)), (1.1321779743943952e-05, tensor(0.9864)), (1.1334224825208135e-05, tensor(0.9838)), (1.1346683586304566e-05, tensor(0.9842)), (1.1359156042270338e-05, tensor(0.9849)), (1.1371642208159068e-05, tensor(0.9858)), (1.1384142099040926e-05, tensor(0.9866)), (1.1396655730002644e-05, tensor(0.9865)), (1.1409183116147534e-05, tensor(0.9853)), (1.1421724272595514e-05, tensor(0.9875)), (1.1434279214483122e-05, tensor(0.9859)), (1.1446847956963533e-05, tensor(0.9842)), (1.1459430515206582e-05, tensor(0.9844)), (1.1472026904398773e-05, tensor(0.9837)), (1.1484637139743307e-05, tensor(0.9863)), (1.1497261236460095e-05, tensor(0.9855)), (1.1509899209785782e-05, tensor(0.9841)), (1.1522551074973756e-05, tensor(0.9827)), (1.1535216847294175e-05, tensor(0.9820)), (1.154789654203398e-05, tensor(0.9832)), (1.156059017449692e-05, tensor(0.9836)), (1.157329776000356e-05, tensor(0.9829)), (1.1586019313891307e-05, tensor(0.9851)), (1.1598754851514433e-05, tensor(0.9854)), (1.1611504388244082e-05, tensor(0.9869)), (1.1624267939468297e-05, tensor(0.9861)), (1.163704552059203e-05, tensor(0.9864)), (1.1649837147037175e-05, tensor(0.9864)), (1.1662642834242573e-05, tensor(0.9865)), (1.1675462597664033e-05, tensor(0.9846)), (1.1688296452774364e-05, tensor(0.9834)), (1.1701144415063369e-05, tensor(0.9829)), (1.1714006500037887e-05, tensor(0.9878)), (1.1726882723221798e-05, tensor(0.9886)), (1.1739773100156049e-05, tensor(0.9879)), (1.175267764639867e-05, tensor(0.9871)), (1.1765596377524789e-05, tensor(0.9855)), (1.1778529309126658e-05, tensor(0.9851)), (1.1791476456813666e-05, tensor(0.9852)), (1.1804437836212362e-05, tensor(0.9841)), (1.181741346296647e-05, tensor(0.9836)), (1.183040335273691e-05, tensor(0.9835)), (1.1843407521201819e-05, tensor(0.9848)), (1.1856425984056568e-05, tensor(0.9863)), (1.1869458757013774e-05, tensor(0.9856)), (1.1882505855803335e-05, tensor(0.9848)), (1.1895567296172432e-05, tensor(0.9884)), (1.190864309388556e-05, tensor(0.9848)), (1.192173326472454e-05, tensor(0.9867)), (1.1934837824488541e-05, tensor(0.9876)), (1.1947956788994103e-05, tensor(0.9837)), (1.1961090174075144e-05, tensor(0.9810)), (1.1974237995582993e-05, tensor(0.9839)), (1.1987400269386403e-05, tensor(0.9828)), (1.2000577011371563e-05, tensor(0.9816)), (1.2013768237442137e-05, tensor(0.9840)), (1.2026973963519256e-05, tensor(0.9856)), (1.204019420554156e-05, tensor(0.9849)), (1.2053428979465214e-05, tensor(0.9819)), (1.206667830126391e-05, tensor(0.9823)), (1.2079942186928909e-05, tensor(0.9841)), (1.209322065246904e-05, tensor(0.9832)), (1.2106513713910741e-05, tensor(0.9844)), (1.2119821387298056e-05, tensor(0.9848)), (1.2133143688692672e-05, tensor(0.9850)), (1.214648063417393e-05, tensor(0.9860)), (1.2159832239838839e-05, tensor(0.9851)), (1.2173198521802108e-05, tensor(0.9842)), (1.2186579496196163e-05, tensor(0.9853)), (1.2199975179171155e-05, tensor(0.9860)), (1.2213385586894992e-05, tensor(0.9867)), (1.2226810735553354e-05, tensor(0.9878)), (1.224025064134971e-05, tensor(0.9868)), (1.2253705320505347e-05, tensor(0.9874)), (1.2267174789259373e-05, tensor(0.9880)), (1.2280659063868751e-05, tensor(0.9885)), (1.2294158160608318e-05, tensor(0.9874)), (1.230767209577079e-05, tensor(0.9888)), (1.2321200885666804e-05, tensor(0.9910)), (1.233474454662492e-05, tensor(0.9913)), (1.2348303094991643e-05, tensor(0.9952)), (1.2361876547131453e-05, tensor(0.9956)), (1.2375464919426819e-05, tensor(0.9930)), (1.2389068228278207e-05, tensor(0.9933)), (1.2402686490104125e-05, tensor(0.9941)), (1.2416319721341122e-05, tensor(0.9927)), (1.2429967938443805e-05, tensor(0.9938)), (1.2443631157884889e-05, tensor(0.9928)), (1.2457309396155175e-05, tensor(0.9930)), (1.2471002669763604e-05, tensor(0.9948)), (1.2484710995237258e-05, tensor(0.9987)), (1.2498434389121391e-05, tensor(1.0024)), (1.251217286797944e-05, tensor(1.0019)), (1.2525926448393046e-05, tensor(1.0010)), (1.2539695146962086e-05, tensor(1.0014)), (1.2553478980304672e-05, tensor(1.0017)), (1.2567277965057191e-05, tensor(1.0013)), (1.2581092117874318e-05, tensor(1.0007)), (1.259492145542903e-05, tensor(0.9973)), (1.260876599441263e-05, tensor(0.9959)), (1.2622625751534778e-05, tensor(0.9947)), (1.2636500743523492e-05, tensor(0.9948)), (1.265039098712518e-05, tensor(0.9947)), (1.2664296499104658e-05, tensor(0.9929)), (1.2678217296245172e-05, tensor(0.9923)), (1.2692153395348417e-05, tensor(0.9893)), (1.2706104813234555e-05, tensor(0.9893)), (1.2720071566742233e-05, tensor(0.9901)), (1.2734053672728617e-05, tensor(0.9939)), (1.274805114806939e-05, tensor(0.9970)), (1.27620640096588e-05, tensor(0.9965)), (1.2776092274409653e-05, tensor(0.9949)), (1.279013595925335e-05, tensor(0.9956)), (1.2804195081139905e-05, tensor(0.9965)), (1.281826965703796e-05, tensor(0.9968)), (1.2832359703934814e-05, tensor(0.9947)), (1.2846465238836436e-05, tensor(0.9960)), (1.2860586278767486e-05, tensor(0.9997)), (1.2874722840771343e-05, tensor(0.9971)), (1.2888874941910117e-05, tensor(0.9979)), (1.290304259926467e-05, tensor(0.9969)), (1.2917225829934648e-05, tensor(0.9951)), (1.2931424651038485e-05, tensor(0.9954)), (1.2945639079713437e-05, tensor(0.9939)), (1.2959869133115595e-05, tensor(0.9931)), (1.2974114828419908e-05, tensor(0.9919)), (1.2988376182820207e-05, tensor(0.9931)), (1.3002653213529216e-05, tensor(0.9951)), (1.3016945937778591e-05, tensor(0.9990)), (1.3031254372818918e-05, tensor(0.9964)), (1.3045578535919749e-05, tensor(0.9952)), (1.3059918444369621e-05, tensor(0.9916)), (1.3074274115476073e-05, tensor(0.9946)), (1.308864556656567e-05, tensor(0.9931)), (1.310303281498402e-05, tensor(0.9929)), (1.3117435878095802e-05, tensor(0.9910)), (1.3131854773284776e-05, tensor(0.9886)), (1.3146289517953816e-05, tensor(0.9899)), (1.3160740129524924e-05, tensor(0.9901)), (1.3175206625439254e-05, tensor(0.9897)), (1.3189689023157129e-05, tensor(0.9891)), (1.3204187340158063e-05, tensor(0.9891)), (1.321870159394079e-05, tensor(0.9915)), (1.3233231802023274e-05, tensor(0.9909)), (1.3247777981942735e-05, tensor(0.9917)), (1.3262340151255672e-05, tensor(0.9903)), (1.3276918327537884e-05, tensor(0.9902)), (1.3291512528384486e-05, tensor(0.9899)), (1.3306122771409935e-05, tensor(0.9875)), (1.3320749074248049e-05, tensor(0.9867)), (1.3335391454552035e-05, tensor(0.9862)), (1.3350049929994498e-05, tensor(0.9847)), (1.336472451826747e-05, tensor(0.9826)), (1.3379415237082432e-05, tensor(0.9813)), (1.3394122104170337e-05, tensor(0.9815)), (1.340884513728162e-05, tensor(0.9835)), (1.3423584354186238e-05, tensor(0.9827)), (1.3438339772673671e-05, tensor(0.9820)), (1.345311141055296e-05, tensor(0.9810)), (1.3467899285652716e-05, tensor(0.9819)), (1.3482703415821156e-05, tensor(0.9821)), (1.349752381892611e-05, tensor(0.9821)), (1.351236051285505e-05, tensor(0.9827)), (1.3527213515515108e-05, tensor(0.9833)), (1.3542082844833102e-05, tensor(0.9842)), (1.3556968518755557e-05, tensor(0.9807)), (1.3571870555248726e-05, tensor(0.9790)), (1.3586788972298604e-05, tensor(0.9777)), (1.360172378791096e-05, tensor(0.9772)), (1.361667502011136e-05, tensor(0.9767)), (1.3631642686945179e-05, tensor(0.9752)), (1.3646626806477628e-05, tensor(0.9741)), (1.3661627396793775e-05, tensor(0.9721)), (1.367664447599857e-05, tensor(0.9723)), (1.3691678062216865e-05, tensor(0.9743)), (1.370672817359343e-05, tensor(0.9725)), (1.3721794828292982e-05, tensor(0.9726)), (1.373687804450021e-05, tensor(0.9738)), (1.3751977840419789e-05, tensor(0.9746)), (1.3767094234276397e-05, tensor(0.9761)), (1.3782227244314757e-05, tensor(0.9758)), (1.3797376888799641e-05, tensor(0.9759)), (1.3812543186015897e-05, tensor(0.9794)), (1.3827726154268475e-05, tensor(0.9774)), (1.3842925811882441e-05, tensor(0.9749)), (1.3858142177203016e-05, tensor(0.9747)), (1.3873375268595569e-05, tensor(0.9741)), (1.388862510444567e-05, tensor(0.9733)), (1.3903891703159093e-05, tensor(0.9728)), (1.391917508316185e-05, tensor(0.9753)), (1.3934475262900196e-05, tensor(0.9732)), (1.3949792260840672e-05, tensor(0.9722)), (1.3965126095470114e-05, tensor(0.9753)), (1.398047678529568e-05, tensor(0.9766)), (1.3995844348844869e-05, tensor(0.9753)), (1.4011228804665552e-05, tensor(0.9753)), (1.402663017132598e-05, tensor(0.9774)), (1.4042048467414822e-05, tensor(0.9774)), (1.4057483711541171e-05, tensor(0.9791)), (1.4072935922334586e-05, tensor(0.9815)), (1.4088405118445094e-05, tensor(0.9787)), (1.4103891318543233e-05, tensor(0.9784)), (1.4119394541320053e-05, tensor(0.9785)), (1.4134914805487154e-05, tensor(0.9818)), (1.4150452129776708e-05, tensor(0.9820)), (1.4166006532941475e-05, tensor(0.9833)), (1.4181578033754822e-05, tensor(0.9814)), (1.419716665101076e-05, tensor(0.9801)), (1.4212772403523962e-05, tensor(0.9783)), (1.422839531012977e-05, tensor(0.9788)), (1.4244035389684238e-05, tensor(0.9781)), (1.4259692661064146e-05, tensor(0.9761)), (1.4275367143167027e-05, tensor(0.9744)), (1.4291058854911177e-05, tensor(0.9768)), (1.4306767815235696e-05, tensor(0.9761)), (1.4322494043100498e-05, tensor(0.9759)), (1.4338237557486343e-05, tensor(0.9751)), (1.4353998377394847e-05, tensor(0.9758)), (1.4369776521848517e-05, tensor(0.9764)), (1.4385572009890773e-05, tensor(0.9755)), (1.4401384860585966e-05, tensor(0.9772)), (1.4417215093019394e-05, tensor(0.9734)), (1.4433062726297349e-05, tensor(0.9730)), (1.4448927779547115e-05, tensor(0.9719)), (1.4464810271917002e-05, tensor(0.9725)), (1.4480710222576373e-05, tensor(0.9725)), (1.4496627650715655e-05, tensor(0.9713)), (1.4512562575546379e-05, tensor(0.9711)), (1.4528515016301179e-05, tensor(0.9721)), (1.4544484992233846e-05, tensor(0.9716)), (1.4560472522619327e-05, tensor(0.9697)), (1.4576477626753753e-05, tensor(0.9706)), (1.4592500323954472e-05, tensor(0.9697)), (1.4608540633560067e-05, tensor(0.9695)), (1.462459857493037e-05, tensor(0.9688)), (1.4640674167446502e-05, tensor(0.9666)), (1.4656767430510883e-05, tensor(0.9673)), (1.467287838354726e-05, tensor(0.9673)), (1.4689007046000738e-05, tensor(0.9686)), (1.4705153437337789e-05, tensor(0.9697)), (1.4721317577046283e-05, tensor(0.9678)), (1.4737499484635516e-05, tensor(0.9683)), (1.4753699179636228e-05, tensor(0.9670)), (1.4769916681600622e-05, tensor(0.9673)), (1.4786152010102399e-05, tensor(0.9667)), (1.4802405184736774e-05, tensor(0.9682)), (1.48186762251205e-05, tensor(0.9696)), (1.4834965150891898e-05, tensor(0.9697)), (1.485127198171087e-05, tensor(0.9671)), (1.4867596737258926e-05, tensor(0.9684)), (1.4883939437239224e-05, tensor(0.9688)), (1.4900300101376561e-05, tensor(0.9698)), (1.4916678749417432e-05, tensor(0.9692)), (1.4933075401130029e-05, tensor(0.9694)), (1.4949490076304274e-05, tensor(0.9677)), (1.4965922794751848e-05, tensor(0.9674)), (1.4982373576306205e-05, tensor(0.9678)), (1.4998842440822596e-05, tensor(0.9678)), (1.5015329408178106e-05, tensor(0.9695)), (1.5031834498271665e-05, tensor(0.9717)), (1.5048357731024074e-05, tensor(0.9705)), (1.5064899126378037e-05, tensor(0.9715)), (1.5081458704298173e-05, tensor(0.9704)), (1.509803648477105e-05, tensor(0.9694)), (1.5114632487805207e-05, tensor(0.9703)), (1.5131246733431173e-05, tensor(0.9703)), (1.5147879241701496e-05, tensor(0.9673)), (1.5164530032690768e-05, tensor(0.9650)), (1.5181199126495643e-05, tensor(0.9638)), (1.5197886543234873e-05, tensor(0.9628)), (1.5214592303049316e-05, tensor(0.9627)), (1.5231316426101974e-05, tensor(0.9631)), (1.5248058932578016e-05, tensor(0.9653)), (1.526481984268479e-05, tensor(0.9664)), (1.5281599176651865e-05, tensor(0.9698)), (1.529839695473104e-05, tensor(0.9713)), (1.531521319719638e-05, tensor(0.9731)), (1.533204792434423e-05, tensor(0.9717)), (1.534890115649325e-05, tensor(0.9706)), (1.536577291398444e-05, tensor(0.9694)), (1.5382663217181138e-05, tensor(0.9679)), (1.539957208646909e-05, tensor(0.9673)), (1.5416499542256443e-05, tensor(0.9694)), (1.5433445604973764e-05, tensor(0.9709)), (1.5450410295074096e-05, tensor(0.9685)), (1.546739363303295e-05, tensor(0.9681)), (1.5484395639348356e-05, tensor(0.9694)), (1.5501416334540867e-05, tensor(0.9686)), (1.55184557391536e-05, tensor(0.9713)), (1.553551387375224e-05, tensor(0.9734)), (1.5552590758925092e-05, tensor(0.9748)), (1.5569686415283086e-05, tensor(0.9735)), (1.558680086345981e-05, tensor(0.9730)), (1.560393412411153e-05, tensor(0.9737)), (1.562108621791722e-05, tensor(0.9767)), (1.5638257165578585e-05, tensor(0.9738)), (1.565544698782008e-05, tensor(0.9731)), (1.5672655705388954e-05, tensor(0.9743)), (1.5689883339055244e-05, tensor(0.9729)), (1.570712990961183e-05, tensor(0.9741)), (1.5724395437874446e-05, tensor(0.9728)), (1.5741679944681702e-05, tensor(0.9726)), (1.575898345089512e-05, tensor(0.9721)), (1.577630597739915e-05, tensor(0.9739)), (1.57936475451012e-05, tensor(0.9766)), (1.5811008174931664e-05, tensor(0.9744)), (1.5828387887843927e-05, tensor(0.9745)), (1.5845786704814426e-05, tensor(0.9765)), (1.5863204646842648e-05, tensor(0.9790)), (1.588064173495116e-05, tensor(0.9819)), (1.5898097990185633e-05, tensor(0.9798)), (1.591557343361489e-05, tensor(0.9831)), (1.5933068086330893e-05, tensor(0.9828)), (1.5950581969448796e-05, tensor(0.9841)), (1.5968115104106975e-05, tensor(0.9837)), (1.5985667511467016e-05, tensor(0.9825)), (1.600323921271379e-05, tensor(0.9816)), (1.6020830229055452e-05, tensor(0.9803)), (1.6038440581723446e-05, tensor(0.9802)), (1.6056070291972584e-05, tensor(0.9793)), (1.6073719381081024e-05, tensor(0.9822)), (1.609138787035032e-05, tensor(0.9818)), (1.6109075781105435e-05, tensor(0.9804)), (1.6126783134694783e-05, tensor(0.9828)), (1.6144509952490232e-05, tensor(0.9799)), (1.6162256255887148e-05, tensor(0.9774)), (1.6180022066304422e-05, tensor(0.9778)), (1.6197807405184477e-05, tensor(0.9768)), (1.6215612293993315e-05, tensor(0.9773)), (1.623343675422053e-05, tensor(0.9777)), (1.6251280807379334e-05, tensor(0.9759)), (1.6269144475006594e-05, tensor(0.9759)), (1.6287027778662845e-05, tensor(0.9763)), (1.630493073993233e-05, tensor(0.9746)), (1.6322853380423e-05, tensor(0.9778)), (1.634079572176658e-05, tensor(0.9802)), (1.6358757785618558e-05, tensor(0.9789)), (1.6376739593658235e-05, tensor(0.9782)), (1.639474116758873e-05, tensor(0.9790)), (1.6412762529137033e-05, tensor(0.9785)), (1.6430803700054005e-05, tensor(0.9782)), (1.6448864702114425e-05, tensor(0.9782)), (1.6466945557116998e-05, tensor(0.9823)), (1.64850462868844e-05, tensor(0.9816)), (1.6503166913263285e-05, tensor(0.9814)), (1.6521307458124332e-05, tensor(0.9812)), (1.6539467943362253e-05, tensor(0.9815)), (1.6557648390895826e-05, tensor(0.9798)), (1.657584882266793e-05, tensor(0.9765)), (1.6594069260645556e-05, tensor(0.9758)), (1.6612309726819848e-05, tensor(0.9744)), (1.6630570243206118e-05, tensor(0.9748)), (1.6648850831843877e-05, tensor(0.9749)), (1.666715151479687e-05, tensor(0.9751)), (1.6685472314153083e-05, tensor(0.9753)), (1.6703813252024794e-05, tensor(0.9761)), (1.6722174350548583e-05, tensor(0.9777)), (1.674055563188535e-05, tensor(0.9811)), (1.6758957118220377e-05, tensor(0.9828)), (1.6777378831763314e-05, tensor(0.9801)), (1.6795820794748233e-05, tensor(0.9796)), (1.681428302943365e-05, tensor(0.9772)), (1.683276555810253e-05, tensor(0.9774)), (1.6851268403062357e-05, tensor(0.9769)), (1.6869791586645117e-05, tensor(0.9780)), (1.688833513120735e-05, tensor(0.9763)), (1.6906899059130167e-05, tensor(0.9744)), (1.6925483392819287e-05, tensor(0.9725)), (1.6944088154705055e-05, tensor(0.9717)), (1.696271336724247e-05, tensor(0.9711)), (1.698135905291121e-05, tensor(0.9697)), (1.7000025234215684e-05, tensor(0.9703)), (1.7018711933685004e-05, tensor(0.9711)), (1.7037419173873075e-05, tensor(0.9706)), (1.7056146977358582e-05, tensor(0.9700)), (1.7074895366745027e-05, tensor(0.9683)), (1.7093664364660766e-05, tensor(0.9727)), (1.711245399375902e-05, tensor(0.9727)), (1.7131264276717917e-05, tensor(0.9729)), (1.7150095236240508e-05, tensor(0.9689)), (1.7168946895054806e-05, tensor(0.9700)), (1.71878192759138e-05, tensor(0.9699)), (1.7206712401595497e-05, tensor(0.9725)), (1.722562629490293e-05, tensor(0.9727)), (1.7244560978664213e-05, tensor(0.9725)), (1.7263516475732543e-05, tensor(0.9719)), (1.7282492808986237e-05, tensor(0.9763)), (1.7301490001328767e-05, tensor(0.9778)), (1.7320508075688774e-05, tensor(0.9762)), (1.7339547055020107e-05, tensor(0.9754)), (1.7358606962301842e-05, tensor(0.9734)), (1.737768782053832e-05, tensor(0.9728)), (1.7396789652759164e-05, tensor(0.9723)), (1.741591248201931e-05, tensor(0.9731)), (1.7435056331399047e-05, tensor(0.9723)), (1.745422122400402e-05, tensor(0.9724)), (1.747340718296528e-05, tensor(0.9721)), (1.74926142314393e-05, tensor(0.9728)), (1.7511842392608013e-05, tensor(0.9748)), (1.753109168967883e-05, tensor(0.9758)), (1.755036214588467e-05, tensor(0.9766)), (1.7569653784483996e-05, tensor(0.9755)), (1.7588966628760835e-05, tensor(0.9731)), (1.7608300702024802e-05, tensor(0.9742)), (1.7627656027611136e-05, tensor(0.9721)), (1.764703262888074e-05, tensor(0.9709)), (1.7666430529220174e-05, tensor(0.9715)), (1.7685849752041723e-05, tensor(0.9744)), (1.77052903207834e-05, tensor(0.9735)), (1.772475225890898e-05, tensor(0.9729)), (1.7744235589908027e-05, tensor(0.9729)), (1.7763740337295936e-05, tensor(0.9723)), (1.7783266524613942e-05, tensor(0.9721)), (1.780281417542916e-05, tensor(0.9695)), (1.7822383313334605e-05, tensor(0.9710)), (1.7841973961949235e-05, tensor(0.9708)), (1.7861586144917963e-05, tensor(0.9713)), (1.7881219885911695e-05, tensor(0.9698)), (1.7900875208627354e-05, tensor(0.9691)), (1.792055213678792e-05, tensor(0.9668)), (1.794025069414244e-05, tensor(0.9652)), (1.795997090446607e-05, tensor(0.9659)), (1.79797127915601e-05, tensor(0.9649)), (1.799947637925198e-05, tensor(0.9645)), (1.8019261691395355e-05, tensor(0.9652)), (1.8039068751870094e-05, tensor(0.9628)), (1.8058897584582305e-05, tensor(0.9617)), (1.807874821346438e-05, tensor(0.9629)), (1.809862066247502e-05, tensor(0.9619)), (1.811851495559926e-05, tensor(0.9612)), (1.8138431116848497e-05, tensor(0.9634)), (1.8158369170260518e-05, tensor(0.9639)), (1.8178329139899547e-05, tensor(0.9631)), (1.819831104985625e-05, tensor(0.9639)), (1.8218314924247766e-05, tensor(0.9639)), (1.8238340787217765e-05, tensor(0.9608)), (1.8258388662936433e-05, tensor(0.9610)), (1.8278458575600544e-05, tensor(0.9642)), (1.8298550549433455e-05, tensor(0.9639)), (1.831866460868516e-05, tensor(0.9624)), (1.83388007776323e-05, tensor(0.9638)), (1.8358959080578206e-05, tensor(0.9660)), (1.8379139541852928e-05, tensor(0.9673)), (1.839934218581325e-05, tensor(0.9691)), (1.8419567036842733e-05, tensor(0.9684)), (1.8439814119351747e-05, tensor(0.9676)), (1.8460083457777492e-05, tensor(0.9658)), (1.848037507658402e-05, tensor(0.9654)), (1.850068900026229e-05, tensor(0.9641)), (1.8521025253330166e-05, tensor(0.9637)), (1.8541383860332474e-05, tensor(0.9613)), (1.856176484584101e-05, tensor(0.9639)), (1.8582168234454595e-05, tensor(0.9656)), (1.8602594050799077e-05, tensor(0.9666)), (1.8623042319527376e-05, tensor(0.9651)), (1.8643513065319506e-05, tensor(0.9697)), (1.8664006312882627e-05, tensor(0.9689)), (1.8684522086951033e-05, tensor(0.9705)), (1.870506041228622e-05, tensor(0.9692)), (1.8725621313676907e-05, tensor(0.9694)), (1.8746204815939053e-05, tensor(0.9706)), (1.8766810943915897e-05, tensor(0.9691)), (1.8787439722477985e-05, tensor(0.9685)), (1.8808091176523204e-05, tensor(0.9701)), (1.8828765330976802e-05, tensor(0.9682)), (1.884946221079144e-05, tensor(0.9662)), (1.8870181840947194e-05, tensor(0.9687)), (1.88909242464516e-05, tensor(0.9710)), (1.8911689452339687e-05, tensor(0.9682)), (1.8932477483674003e-05, tensor(0.9645)), (1.8953288365544638e-05, tensor(0.9659)), (1.8974122123069275e-05, tensor(0.9668)), (1.8994978781393193e-05, tensor(0.9657)), (1.9015858365689318e-05, tensor(0.9651)), (1.9036760901158245e-05, tensor(0.9667)), (1.9057686413028268e-05, tensor(0.9648)), (1.9078634926555416e-05, tensor(0.9629)), (1.909960646702348e-05, tensor(0.9617)), (1.912060105974404e-05, tensor(0.9623)), (1.91416187300565e-05, tensor(0.9617)), (1.9162659503328116e-05, tensor(0.9618)), (1.9183723404954035e-05, tensor(0.9610)), (1.920481046035731e-05, tensor(0.9644)), (1.9225920694988944e-05, tensor(0.9624)), (1.9247054134327914e-05, tensor(0.9621)), (1.926821080388121e-05, tensor(0.9604)), (1.928939072918385e-05, tensor(0.9592)), (1.9310593935798926e-05, tensor(0.9591)), (1.9331820449317627e-05, tensor(0.9590)), (1.935307029535928e-05, tensor(0.9575)), (1.9374343499571365e-05, tensor(0.9579)), (1.9395640087629554e-05, tensor(0.9551)), (1.9416960085237747e-05, tensor(0.9539)), (1.943830351812809e-05, tensor(0.9521)), (1.9459670412061028e-05, tensor(0.9561)), (1.9481060792825305e-05, tensor(0.9590)), (1.950247468623803e-05, tensor(0.9604)), (1.9523912118144678e-05, tensor(0.9586)), (1.954537311441914e-05, tensor(0.9595)), (1.956685770096374e-05, tensor(0.9595)), (1.9588365903709285e-05, tensor(0.9585)), (1.960989774861508e-05, tensor(0.9555)), (1.9631453261668967e-05, tensor(0.9543)), (1.9653032468887347e-05, tensor(0.9537)), (1.967463539631523e-05, tensor(0.9531)), (1.9696262070026246e-05, tensor(0.9509)), (1.971791251612269e-05, tensor(0.9520)), (1.9739586760735548e-05, tensor(0.9520)), (1.9761284830024535e-05, tensor(0.9536)), (1.9783006750178108e-05, tensor(0.9509)), (1.9804752547413517e-05, tensor(0.9481)), (1.982652224797684e-05, tensor(0.9502)), (1.9848315878142996e-05, tensor(0.9512)), (1.9870133464215778e-05, tensor(0.9482)), (1.9891975032527915e-05, tensor(0.9472)), (1.9913840609441058e-05, tensor(0.9474)), (1.9935730221345845e-05, tensor(0.9479)), (1.995764389466193e-05, tensor(0.9500)), (1.9979581655837993e-05, tensor(0.9498)), (2.00015435313518e-05, tensor(0.9510)), (2.0023529547710218e-05, tensor(0.9514)), (2.004553973144924e-05, tensor(0.9491)), (2.0067574109134045e-05, tensor(0.9479)), (2.0089632707359006e-05, tensor(0.9471)), (2.0111715552747725e-05, tensor(0.9449)), (2.013382267195307e-05, tensor(0.9459)), (2.0155954091657214e-05, tensor(0.9473)), (2.017810983857164e-05, tensor(0.9461)), (2.0200289939437225e-05, tensor(0.9443)), (2.0222494421024213e-05, tensor(0.9433)), (2.024472331013228e-05, tensor(0.9420)), (2.0266976633590567e-05, tensor(0.9402)), (2.02892544182577e-05, tensor(0.9416)), (2.031155669102183e-05, tensor(0.9413)), (2.0333883478800666e-05, tensor(0.9401)), (2.035623480854151e-05, tensor(0.9389)), (2.0378610707221268e-05, tensor(0.9387)), (2.0401011201846518e-05, tensor(0.9384)), (2.0423436319453516e-05, tensor(0.9400)), (2.044588608710823e-05, tensor(0.9390)), (2.0468360531906394e-05, tensor(0.9380)), (2.0490859680973515e-05, tensor(0.9397)), (2.051338356146493e-05, tensor(0.9418)), (2.0535932200565796e-05, tensor(0.9408)), (2.055850562549119e-05, tensor(0.9405)), (2.058110386348608e-05, tensor(0.9429)), (2.060372694182539e-05, tensor(0.9406)), (2.0626374887814018e-05, tensor(0.9388)), (2.0649047728786887e-05, tensor(0.9399)), (2.067174549210896e-05, tensor(0.9396)), (2.069446820517529e-05, tensor(0.9418)), (2.0717215895411017e-05, tensor(0.9444)), (2.073998859027146e-05, tensor(0.9445)), (2.0762786317242095e-05, tensor(0.9455)), (2.078560910383862e-05, tensor(0.9438)), (2.0808456977606978e-05, tensor(0.9435)), (2.0831329966123385e-05, tensor(0.9420)), (2.0854228096994377e-05, tensor(0.9461)), (2.087715139785683e-05, tensor(0.9453)), (2.0900099896378004e-05, tensor(0.9447)), (2.0923073620255562e-05, tensor(0.9460)), (2.0946072597217628e-05, tensor(0.9446)), (2.0969096855022787e-05, tensor(0.9446)), (2.099214642146015e-05, tensor(0.9458)), (2.1015221324349372e-05, tensor(0.9452)), (2.1038321591540684e-05, tensor(0.9444)), (2.1061447250914927e-05, tensor(0.9462)), (2.1084598330383604e-05, tensor(0.9460)), (2.1107774857888884e-05, tensor(0.9479)), (2.1130976861403657e-05, tensor(0.9475)), (2.115420436893156e-05, tensor(0.9475)), (2.1177457408507007e-05, tensor(0.9456)), (2.1200736008195237e-05, tensor(0.9448)), (2.122404019609234e-05, tensor(0.9459)), (2.124737000032527e-05, tensor(0.9441)), (2.1270725449051926e-05, tensor(0.9443)), (2.1294106570461138e-05, tensor(0.9443)), (2.1317513392772735e-05, tensor(0.9439)), (2.1340945944237555e-05, tensor(0.9442)), (2.1364404253137493e-05, tensor(0.9441)), (2.138788834778554e-05, tensor(0.9431)), (2.1411398256525796e-05, tensor(0.9437)), (2.1434934007733526e-05, tensor(0.9445)), (2.145849562981519e-05, tensor(0.9426)), (2.1482083151208455e-05, tensor(0.9440)), (2.1505696600382264e-05, tensor(0.9415)), (2.1529336005836846e-05, tensor(0.9434)), (2.1553001396103765e-05, tensor(0.9429)), (2.157669279974593e-05, tensor(0.9421)), (2.1600410245357674e-05, tensor(0.9438)), (2.1624153761564735e-05, tensor(0.9443)), (2.1647923377024332e-05, tensor(0.9458)), (2.1671719120425185e-05, tensor(0.9471)), (2.1695541020487533e-05, tensor(0.9477)), (2.1719389105963213e-05, tensor(0.9474)), (2.174326340563563e-05, tensor(0.9490)), (2.1767163948319866e-05, tensor(0.9471)), (2.179109076286265e-05, tensor(0.9481)), (2.181504387814243e-05, tensor(0.9459)), (2.1839023323069396e-05, tensor(0.9440)), (2.186302912658552e-05, tensor(0.9426)), (2.188706131766458e-05, tensor(0.9435)), (2.191111992531221e-05, tensor(0.9437)), (2.1935204978565926e-05, tensor(0.9466)), (2.195931650649516e-05, tensor(0.9463)), (2.1983454538201294e-05, tensor(0.9458)), (2.200761910281771e-05, tensor(0.9448)), (2.2031810229509796e-05, tensor(0.9443)), (2.205602794747503e-05, tensor(0.9446)), (2.2080272285942944e-05, tensor(0.9452)), (2.210454327417523e-05, tensor(0.9444)), (2.2128840941465733e-05, tensor(0.9449)), (2.21531653171405e-05, tensor(0.9466)), (2.2177516430557814e-05, tensor(0.9450)), (2.2201894311108237e-05, tensor(0.9482)), (2.2226298988214616e-05, tensor(0.9505)), (2.2250730491332156e-05, tensor(0.9500)), (2.2275188849948445e-05, tensor(0.9508)), (2.229967409358347e-05, tensor(0.9509)), (2.2324186251789682e-05, tensor(0.9488)), (2.2348725354151997e-05, tensor(0.9480)), (2.2373291430287865e-05, tensor(0.9519)), (2.2397884509847295e-05, tensor(0.9525)), (2.2422504622512873e-05, tensor(0.9544)), (2.2447151797999833e-05, tensor(0.9539)), (2.2471826066056046e-05, tensor(0.9516)), (2.249652745646211e-05, tensor(0.9499)), (2.252125599903134e-05, tensor(0.9514)), (2.2546011723609826e-05, tensor(0.9513)), (2.257079466007647e-05, tensor(0.9528)), (2.259560483834301e-05, tensor(0.9519)), (2.2620442288354077e-05, tensor(0.9539)), (2.26453070400872e-05, tensor(0.9509)), (2.2670199123552873e-05, tensor(0.9513)), (2.2695118568794576e-05, tensor(0.9506)), (2.2720065405888797e-05, tensor(0.9500)), (2.274503966494511e-05, tensor(0.9509)), (2.2770041376106175e-05, tensor(0.9538)), (2.2795070569547775e-05, tensor(0.9511)), (2.282012727547888e-05, tensor(0.9521)), (2.2845211524141663e-05, tensor(0.9547)), (2.2870323345811524e-05, tensor(0.9527)), (2.2895462770797154e-05, tensor(0.9506)), (2.2920629829440562e-05, tensor(0.9522)), (2.2945824552117107e-05, tensor(0.9518)), (2.297104696923554e-05, tensor(0.9535)), (2.2996297111238022e-05, tensor(0.9514)), (2.30215750086002e-05, tensor(0.9510)), (2.3046880691831205e-05, tensor(0.9503)), (2.307221419147371e-05, tensor(0.9495)), (2.3097575538103957e-05, tensor(0.9485)), (2.31229647623318e-05, tensor(0.9497)), (2.3148381894800745e-05, tensor(0.9502)), (2.3173826966187968e-05, tensor(0.9479)), (2.3199300007204384e-05, tensor(0.9472)), (2.3224801048594644e-05, tensor(0.9462)), (2.325033012113722e-05, tensor(0.9478)), (2.3275887255644392e-05, tensor(0.9512)), (2.3301472482962334e-05, tensor(0.9506)), (2.3327085833971094e-05, tensor(0.9507)), (2.3352727339584695e-05, tensor(0.9507)), (2.3378397030751126e-05, tensor(0.9508)), (2.34040949384524e-05, tensor(0.9491)), (2.342982109370457e-05, tensor(0.9485)), (2.3455575527557813e-05, tensor(0.9488)), (2.3481358271096412e-05, tensor(0.9473)), (2.3507169355438822e-05, tensor(0.9465)), (2.353300881173771e-05, tensor(0.9450)), (2.355887667117999e-05, tensor(0.9442)), (2.358477296498684e-05, tensor(0.9442)), (2.3610697724413777e-05, tensor(0.9449)), (2.3636650980750668e-05, tensor(0.9439)), (2.366263276532176e-05, tensor(0.9434)), (2.368864310948575e-05, tensor(0.9409)), (2.3714682044635803e-05, tensor(0.9399)), (2.3740749602199584e-05, tensor(0.9407)), (2.3766845813639304e-05, tensor(0.9422)), (2.3792970710451773e-05, tensor(0.9416)), (2.3819124324168402e-05, tensor(0.9415)), (2.384530668635527e-05, tensor(0.9430)), (2.387151782861316e-05, tensor(0.9422)), (2.389775778257758e-05, tensor(0.9418)), (2.3924026579918825e-05, tensor(0.9434)), (2.3950324252341997e-05, tensor(0.9422)), (2.397665083158704e-05, tensor(0.9434)), (2.4003006349428802e-05, tensor(0.9423)), (2.4029390837677045e-05, tensor(0.9434)), (2.4055804328176507e-05, tensor(0.9442)), (2.4082246852806924e-05, tensor(0.9456)), (2.4108718443483077e-05, tensor(0.9442)), (2.4135219132154827e-05, tensor(0.9439)), (2.4161748950807162e-05, tensor(0.9460)), (2.4188307931460214e-05, tensor(0.9473)), (2.4214896106169325e-05, tensor(0.9467)), (2.4241513507025066e-05, tensor(0.9442)), (2.4268160166153285e-05, tensor(0.9427)), (2.4294836115715148e-05, tensor(0.9399)), (2.4321541387907157e-05, tensor(0.9416)), (2.4348276014961227e-05, tensor(0.9382)), (2.4375040029144685e-05, tensor(0.9378)), (2.440183346276033e-05, tensor(0.9364)), (2.442865634814648e-05, tensor(0.9349)), (2.445550871767699e-05, tensor(0.9351)), (2.4482390603761304e-05, tensor(0.9338)), (2.450930203884449e-05, tensor(0.9353)), (2.4536243055407266e-05, tensor(0.9349)), (2.456321368596609e-05, tensor(0.9352)), (2.459021396307312e-05, tensor(0.9360)), (2.461724391931633e-05, tensor(0.9344)), (2.4644303587319495e-05, tensor(0.9336)), (2.467139299974225e-05, tensor(0.9320)), (2.4698512189280148e-05, tensor(0.9320)), (2.4725661188664662e-05, tensor(0.9319)), (2.4752840030663257e-05, tensor(0.9319)), (2.478004874807941e-05, tensor(0.9302)), (2.480728737375265e-05, tensor(0.9298)), (2.4834555940558627e-05, tensor(0.9263)), (2.48618544814091e-05, tensor(0.9241)), (2.4889183029252014e-05, tensor(0.9256)), (2.491654161707155e-05, tensor(0.9273)), (2.494393027788812e-05, tensor(0.9287)), (2.4971349044758447e-05, tensor(0.9291)), (2.4998797950775585e-05, tensor(0.9301)), (2.5026277029068963e-05, tensor(0.9296)), (2.5053786312804435e-05, tensor(0.9273)), (2.5081325835184306e-05, tensor(0.9258)), (2.510889562944737e-05, tensor(0.9273)), (2.513649572886897e-05, tensor(0.9264)), (2.5164126166761017e-05, tensor(0.9259)), (2.5191786976472047e-05, tensor(0.9254)), (2.521947819138725e-05, tensor(0.9270)), (2.5247199844928506e-05, tensor(0.9255)), (2.5274951970554448e-05, tensor(0.9227)), (2.530273460176047e-05, tensor(0.9248)), (2.53305477720788e-05, tensor(0.9235)), (2.5358391515078512e-05, tensor(0.9221)), (2.5386265864365595e-05, tensor(0.9219)), (2.5414170853582957e-05, tensor(0.9220)), (2.5442106516410507e-05, tensor(0.9205)), (2.547007288656517e-05, tensor(0.9211)), (2.549806999780092e-05, tensor(0.9198)), (2.552609788390886e-05, tensor(0.9218)), (2.555415657871721e-05, tensor(0.9219)), (2.5582246116091388e-05, tensor(0.9235)), (2.5610366529934036e-05, tensor(0.9207)), (2.5638517854185065e-05, tensor(0.9211)), (2.5666700122821688e-05, tensor(0.9207)), (2.5694913369858464e-05, tensor(0.9221)), (2.5723157629347354e-05, tensor(0.9221)), (2.575143293537773e-05, tensor(0.9233)), (2.5779739322076455e-05, tensor(0.9233)), (2.5808076823607894e-05, tensor(0.9268)), (2.5836445474173976e-05, tensor(0.9249)), (2.5864845308014204e-05, tensor(0.9258)), (2.589327635940574e-05, tensor(0.9240)), (2.592173866266341e-05, tensor(0.9239)), (2.595023225213977e-05, tensor(0.9222)), (2.5978757162225127e-05, tensor(0.9235)), (2.60073134273476e-05, tensor(0.9229)), (2.6035901081973143e-05, tensor(0.9258)), (2.6064520160605608e-05, tensor(0.9259)), (2.6093170697786752e-05, tensor(0.9255)), (2.6121852728096325e-05, tensor(0.9240)), (2.6150566286152074e-05, tensor(0.9239)), (2.61793114066098e-05, tensor(0.9256)), (2.62080881241634e-05, tensor(0.9250)), (2.6236896473544908e-05, tensor(0.9249)), (2.626573648952454e-05, tensor(0.9260)), (2.6294608206910714e-05, tensor(0.9271)), (2.6323511660550133e-05, tensor(0.9313)), (2.6352446885327792e-05, tensor(0.9297)), (2.6381413916167035e-05, tensor(0.9299)), (2.6410412788029588e-05, tensor(0.9311)), (2.6439443535915615e-05, tensor(0.9315)), (2.6468506194863754e-05, tensor(0.9308)), (2.6497600799951155e-05, tensor(0.9300)), (2.6526727386293514e-05, tensor(0.9307)), (2.6555885989045153e-05, tensor(0.9292)), (2.658507664339901e-05, tensor(0.9297)), (2.661429938458673e-05, tensor(0.9309)), (2.6643554247878657e-05, tensor(0.9311)), (2.6672841268583934e-05, tensor(0.9311)), (2.67021604820505e-05, tensor(0.9344)), (2.6731511923665146e-05, tensor(0.9336)), (2.6760895628853584e-05, tensor(0.9347)), (2.6790311633080434e-05, tensor(0.9358)), (2.6819759971849325e-05, tensor(0.9340)), (2.6849240680702896e-05, tensor(0.9366)), (2.6878753795222868e-05, tensor(0.9354)), (2.6908299351030062e-05, tensor(0.9369)), (2.693787738378446e-05, tensor(0.9372)), (2.6967487929185246e-05, tensor(0.9383)), (2.699713102297084e-05, tensor(0.9372)), (2.7026806700918937e-05, tensor(0.9360)), (2.7056514998846584e-05, tensor(0.9351)), (2.708625595261017e-05, tensor(0.9362)), (2.711602959810552e-05, tensor(0.9336)), (2.714583597126791e-05, tensor(0.9325)), (2.7175675108072107e-05, tensor(0.9307)), (2.720554704453244e-05, tensor(0.9289)), (2.7235451816702804e-05, tensor(0.9312)), (2.7265389460676742e-05, tensor(0.9322)), (2.7295360012587465e-05, tensor(0.9308)), (2.732536350860791e-05, tensor(0.9310)), (2.7355399984950754e-05, tensor(0.9309)), (2.738546947786851e-05, tensor(0.9322)), (2.7415572023653516e-05, tensor(0.9301)), (2.744570765863801e-05, tensor(0.9322)), (2.7475876419194176e-05, tensor(0.9300)), (2.7506078341734173e-05, tensor(0.9310)), (2.7536313462710174e-05, tensor(0.9288)), (2.756658181861444e-05, tensor(0.9292)), (2.7596883445979327e-05, tensor(0.9300)), (2.762721838137737e-05, tensor(0.9292)), (2.765758666142127e-05, tensor(0.9331)), (2.7687988322764016e-05, tensor(0.9312)), (2.7718423402098854e-05, tensor(0.9321)), (2.7748891936159377e-05, tensor(0.9345)), (2.7779393961719553e-05, tensor(0.9326)), (2.7809929515593775e-05, tensor(0.9317)), (2.7840498634636905e-05, tensor(0.9314)), (2.7871101355744308e-05, tensor(0.9318)), (2.7901737715851913e-05, tensor(0.9308)), (2.7932407751936246e-05, tensor(0.9303)), (2.7963111501014483e-05, tensor(0.9306)), (2.7993849000144474e-05, tensor(0.9310)), (2.8024620286424825e-05, tensor(0.9320)), (2.8055425396994914e-05, tensor(0.9335)), (2.8086264369034936e-05, tensor(0.9337)), (2.811713723976596e-05, tensor(0.9352)), (2.8148044046449968e-05, tensor(0.9357)), (2.817898482638991e-05, tensor(0.9392)), (2.8209959616929715e-05, tensor(0.9406)), (2.8240968455454395e-05, tensor(0.9412)), (2.8272011379390038e-05, tensor(0.9409)), (2.8303088426203862e-05, tensor(0.9411)), (2.8334199633404283e-05, tensor(0.9418)), (2.836534503854095e-05, tensor(0.9412)), (2.8396524679204777e-05, tensor(0.9420)), (2.8427738593028003e-05, tensor(0.9421)), (2.8458986817684236e-05, tensor(0.9425)), (2.8490269390888486e-05, tensor(0.9432)), (2.852158635039723e-05, tensor(0.9416)), (2.8552937734008445e-05, tensor(0.9412)), (2.858432357956165e-05, tensor(0.9409)), (2.8615743924937964e-05, tensor(0.9390)), (2.8647198808060145e-05, tensor(0.9387)), (2.8678688266892635e-05, tensor(0.9405)), (2.871021233944161e-05, tensor(0.9375)), (2.8741771063755015e-05, tensor(0.9393)), (2.8773364477922633e-05, tensor(0.9387)), (2.880499262007609e-05, tensor(0.9373)), (2.883665552838896e-05, tensor(0.9369)), (2.8868353241076752e-05, tensor(0.9358)), (2.890008579639699e-05, tensor(0.9353)), (2.8931853232649262e-05, tensor(0.9340)), (2.8963655588175235e-05, tensor(0.9350)), (2.899549290135874e-05, tensor(0.9337)), (2.9027365210625788e-05, tensor(0.9343)), (2.9059272554444635e-05, tensor(0.9340)), (2.9091214971325822e-05, tensor(0.9332)), (2.912319249982222e-05, tensor(0.9351)), (2.9155205178529072e-05, tensor(0.9355)), (2.918725304608406e-05, tensor(0.9346)), (2.9219336141167326e-05, tensor(0.9344)), (2.925145450250153e-05, tensor(0.9371)), (2.9283608168851895e-05, tensor(0.9370)), (2.9315797179026268e-05, tensor(0.9359)), (2.934802157187514e-05, tensor(0.9358)), (2.938028138629171e-05, tensor(0.9363)), (2.9412576661211935e-05, tensor(0.9369)), (2.9444907435614563e-05, tensor(0.9376)), (2.94772737485212e-05, tensor(0.9397)), (2.9509675638996334e-05, tensor(0.9388)), (2.9542113146147392e-05, tensor(0.9404)), (2.9574586309124808e-05, tensor(0.9414)), (2.960709516712202e-05, tensor(0.9376)), (2.9639639759375567e-05, tensor(0.9369)), (2.9672220125165125e-05, tensor(0.9366)), (2.9704836303813526e-05, tensor(0.9344)), (2.9737488334686843e-05, tensor(0.9334)), (2.9770176257194415e-05, tensor(0.9305)), (2.9802900110788893e-05, tensor(0.9313)), (2.983565993496631e-05, tensor(0.9322)), (2.98684557692661e-05, tensor(0.9316)), (2.9901287653271168e-05, tensor(0.9303)), (2.9934155626607926e-05, tensor(0.9302)), (2.9967059728946347e-05, tensor(0.9291))]
******

*** 2019-01-03 15:15:56,933 - code.resnet_fastai - DEBUG ***
Best LR: 2.549806999780092e-05
******

*** 2019-01-03 15:15:56,968 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2019-01-03 15:15:56,971 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:56,971 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2019-01-03 15:15:56,977 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:56,977 - matplotlib.ticker - DEBUG ***
ticklocs [2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2019-01-03 15:15:57,104 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:57,105 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2019-01-03 15:15:57,106 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:57,106 - matplotlib.ticker - DEBUG ***
ticklocs [2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2019-01-03 15:15:57,210 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2019-01-03 15:15:57,212 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:57,212 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2019-01-03 15:15:57,214 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:57,214 - matplotlib.ticker - DEBUG ***
ticklocs [2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2019-01-03 15:15:57,221 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:57,221 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2019-01-03 15:15:57,223 - matplotlib.ticker - DEBUG ***
vmin 9.57848551497451e-06 vmax 3.1458129283654e-05
******

*** 2019-01-03 15:15:57,223 - matplotlib.ticker - DEBUG ***
ticklocs [2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2019-01-03 15:15:57,246 - code.resnet_fastai - INFO ***
Start model fitting: Stage 2
******

*** 2019-01-03 15:15:57,246 - code.resnet_fastai - DEBUG ***
LR: 1.7848648998460644e-05
******

2         0.929107                
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
[1.784865e-05 2.524180e-04 3.569730e-03]
epoch     train_loss  valid_loss  fbeta   
1         0.962933    0.897114    0.361549  
2         0.923294    0.858189    0.377981  
3         0.894766    0.853238    0.374987  
4         0.879178    0.834466    0.398009  
5         0.886412    0.831974    0.388607  
6         0.875550    0.801167    0.415097  
7         0.841504    0.814870    0.425946  
8         0.825239    0.810817    0.461560  
9         0.795303    0.760426    0.444255  
10        0.739893    0.737452    0.485511  
11        0.742716    0.736318    0.497964  
12        0.697567    0.695070    0.514574  
13        0.664281    0.652473    0.534417  
14        0.626951    0.644888    0.557919  
15        0.588386    0.610429    0.558296  
16        0.571388    0.613171    0.565778  
17        0.538452    0.587483    0.604956  
18        0.509280    0.557396    0.603101  
19        0.477136    0.549873    0.619411  
20        0.444669    0.552225    0.628977  
21        0.400722    0.556572    0.661806  
22        0.385734    0.536784    0.674261  
23        0.355294    0.547249    0.687778  
24        0.331037    0.553488    0.695433  
25        0.303808    0.551670    0.704463  
26        0.278455    0.558341    0.715364  
27        0.265928    0.569731    0.720802  
*** 2019-01-03 17:34:09,232 - code.resnet_fastai - INFO ***
Complete model fitting: Stage 2
******

*** 2019-01-03 17:34:09,395 - code.resnet_fastai - INFO ***
Stage 2 model saved.
******

*** 2019-01-03 17:34:09,397 - code.resnet_fastai - INFO ***
Start predicting test set
******

28        0.257536    0.572898    0.726388  
Epoch 28: early stopping
Epoch 28: reducing lr to 1.5862100256800408e-05
*** 2019-01-03 17:35:09,765 - code.resnet_fastai - INFO ***
Complete test prediction.
******

*** 2019-01-03 17:35:09,768 - code.resnet_fastai - INFO ***
Prediction saved.
******

*** 2019-01-03 17:35:09,909 - code.resnet_fastai - INFO ***
Results written to output/resnet50-256-official_hpav18-focal-random-drop0.5-th0.1-bs64-lr0-ep3_30-5.csv. Finished! :)
******

*** 2019-01-03 17:35:09,910 - code.resnet_fastai - DEBUG ***
torch.Size([11702, 28])
******

*** 2019-01-03 17:35:09,992 - code.resnet_fastai - INFO ***
Results written to output/resnet50-256-official_hpav18-focal-random-drop0.5-th0.1-bs64-lr0-ep3_30-avg.csv. Finished! :)
******

