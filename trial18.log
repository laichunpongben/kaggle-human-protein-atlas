*** 2018-12-28 15:54:30,679 - code.resnet_fastai - DEBUG ***
Start a new training task
******

*** 2018-12-28 15:54:30,679 - code.resnet_fastai - INFO ***
Device ID: 0
Image size: 512
Network architecture: resnet
Loss function: bce
Sampler: random
Encoder depth: 50
Dropout: 0.5
Threshold: 0.1
Stage 1 #epoch: 0
Stage 2 #epoch: 25
Learning rate #1: 0
Batch size: 32
Dataset: official
Dataset directory: data/official
Output directory: output
******

*** 2018-12-28 15:54:30,679 - code.resnet_fastai - INFO ***
Offical stats: ([0.07986162506177984, 0.05217604947235713, 0.054227752481757215, 0.08201468927464939], [0.1403192215484648, 0.1041239635111223, 0.1532386688507187, 0.14099509309392533])
******

*** 2018-12-28 15:54:30,738 - code.resnet_fastai - DEBUG ***
# Test ids: 11702
******

*** 2018-12-28 15:54:31,549 - code.resnet_fastai - DEBUG ***
Start of fold 0
******

*** 2018-12-28 15:54:31,549 - code.resnet_fastai - DEBUG ***
Size of valid set: 6209
******

*** 2018-12-28 15:54:31,741 - code.resnet_fastai - DEBUG ***
LabelList
y: MultiCategoryList (24863 items)
[MultiCategory 16;0, MultiCategory 1, MultiCategory 18, MultiCategory 0, MultiCategory 25;2]...
Path: data/official
x: ImageItemList (24863 items)
[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...
Path: data/official
******

*** 2018-12-28 15:54:31,889 - code.resnet_fastai - DEBUG ***
LabelList
y: MultiCategoryList (6209 items)
[MultiCategory 7;1;2;0, MultiCategory 5, MultiCategory 21, MultiCategory 0, MultiCategory 25;4]...
Path: data/official
x: ImageItemList (6209 items)
[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...
Path: data/official
******

*** 2018-12-28 15:54:34,136 - code.resnet_fastai - DEBUG ***
Databunch created
******

*** 2018-12-28 15:54:34,137 - code.resnet_fastai - INFO ***
Initialising model.
******

*** 2018-12-28 15:54:38,517 - code.resnet_fastai - INFO ***
Complete initialising model.
******

*** 2018-12-28 15:54:38,517 - code.resnet_fastai - DEBUG ***
runname: resnet50-512-official-bce-random-drop0.5-th0.1-bs32-lr0-ep3_25
******

*** 2018-12-28 15:54:38,517 - code.resnet_fastai - INFO ***
Loading model: stage-1-resnet50-512-official-bce-random-drop0.5-th0.1-bs32-lr0-ep3_25, with suffix 0
******

*** 2018-12-28 15:54:38,676 - code.resnet_fastai - INFO ***
Finish loading model.
******

*** 2018-12-28 15:54:38,678 - code.resnet_fastai - DEBUG ***
Unfreezing model
******

*** 2018-12-28 15:54:38,678 - code.resnet_fastai - DEBUG ***
Start finding LR
******

epoch     train_loss  valid_loss  fbeta   
1         0.095844                
*** 2018-12-28 16:03:24,949 - code.resnet_fastai - DEBUG ***
[(1e-06, tensor(0.0803)), (1.0034069880166463e-06, tensor(0.0982)), (1.0068255836006383e-06, tensor(0.0909)), (1.0102558262988186e-06, tensor(0.0899)), (1.0136977557927658e-06, tensor(0.0946)), (1.017151411899253e-06, tensor(0.0988)), (1.0206168345707087e-06, tensor(0.0960)), (1.0240940638956785e-06, tensor(0.1007)), (1.0275831400992898e-06, tensor(0.1012)), (1.031084103543716e-06, tensor(0.0980)), (1.034596994728644e-06, tensor(0.0977)), (1.0381218542917426e-06, tensor(0.0971)), (1.0416587230091333e-06, tensor(0.0961)), (1.0452076417958606e-06, tensor(0.0992)), (1.0487686517063663e-06, tensor(0.0981)), (1.0523417939349644e-06, tensor(0.0977)), (1.0559271098163169e-06, tensor(0.0966)), (1.059524640825913e-06, tensor(0.0969)), (1.0631344285805485e-06, tensor(0.0968)), (1.0667565148388065e-06, tensor(0.0988)), (1.0703909415015418e-06, tensor(0.0985)), (1.0740377506123643e-06, tensor(0.0979)), (1.0776969843581265e-06, tensor(0.0984)), (1.0813686850694107e-06, tensor(0.0983)), (1.0850528952210188e-06, tensor(0.0970)), (1.0887496574324642e-06, tensor(0.0964)), (1.0924590144684642e-06, tensor(0.0964)), (1.0961810092394357e-06, tensor(0.0962)), (1.0999156848019896e-06, tensor(0.0966)), (1.1036630843594315e-06, tensor(0.0958)), (1.107423251262259e-06, tensor(0.0969)), (1.111196229008665e-06, tensor(0.0968)), (1.1149820612450402e-06, tensor(0.0963)), (1.1187807917664777e-06, tensor(0.0964)), (1.12259246451728e-06, tensor(0.0962)), (1.1264171235914682e-06, tensor(0.0955)), (1.1302548132332895e-06, tensor(0.0955)), (1.134105577837732e-06, tensor(0.0956)), (1.137969461951037e-06, tensor(0.0962)), (1.1418465102712136e-06, tensor(0.0959)), (1.1457367676485572e-06, tensor(0.0964)), (1.149640279086167e-06, tensor(0.0959)), (1.1535570897404675e-06, tensor(0.0957)), (1.1574872449217305e-06, tensor(0.0957)), (1.1614307900946e-06, tensor(0.0954)), (1.1653877708786165e-06, tensor(0.0952)), (1.1693582330487459e-06, tensor(0.0957)), (1.1733422225359098e-06, tensor(0.0954)), (1.1773397854275148e-06, tensor(0.0949)), (1.1813509679679875e-06, tensor(0.0950)), (1.185375816559308e-06, tensor(0.0956)), (1.1894143777615478e-06, tensor(0.0961)), (1.1934666982934084e-06, tensor(0.0968)), (1.1975328250327606e-06, tensor(0.0972)), (1.2016128050171876e-06, tensor(0.0971)), (1.20570668544453e-06, tensor(0.0975)), (1.2098145136734298e-06, tensor(0.0979)), (1.2139363372238803e-06, tensor(0.0976)), (1.2180722037777735e-06, tensor(0.0971)), (1.2222221611794543e-06, tensor(0.0971)), (1.2263862574362724e-06, tensor(0.0971)), (1.2305645407191376e-06, tensor(0.0973)), (1.2347570593630777e-06, tensor(0.0978)), (1.2389638618677971e-06, tensor(0.0978)), (1.2431849968982384e-06, tensor(0.0974)), (1.2474205132851455e-06, tensor(0.0968)), (1.2516704600256268e-06, tensor(0.0964)), (1.2559348862837243e-06, tensor(0.0965)), (1.2602138413909808e-06, tensor(0.0965)), (1.2645073748470118e-06, tensor(0.0963)), (1.2688155363200764e-06, tensor(0.0967)), (1.2731383756476538e-06, tensor(0.0968)), (1.2774759428370179e-06, tensor(0.0963)), (1.2818282880658175e-06, tensor(0.0964)), (1.2861954616826563e-06, tensor(0.0961)), (1.2905775142076738e-06, tensor(0.0959)), (1.2949744963331327e-06, tensor(0.0959)), (1.2993864589240022e-06, tensor(0.0964)), (1.3038134530185489e-06, tensor(0.0961)), (1.3082555298289255e-06, tensor(0.0962)), (1.312712740741764e-06, tensor(0.0970)), (1.31718513731877e-06, tensor(0.0970)), (1.3216727712973198e-06, tensor(0.0967)), (1.3261756945910575e-06, tensor(0.0961)), (1.330693959290497e-06, tensor(0.0960)), (1.3352276176636233e-06, tensor(0.0960)), (1.3397767221564984e-06, tensor(0.0958)), (1.3443413253938674e-06, tensor(0.0961)), (1.3489214801797668e-06, tensor(0.0957)), (1.353517239498136e-06, tensor(0.0957)), (1.3581286565134304e-06, tensor(0.0955)), (1.3627557845712359e-06, tensor(0.0949)), (1.3673986771988854e-06, tensor(0.0950)), (1.3720573881060803e-06, tensor(0.0948)), (1.3767319711855086e-06, tensor(0.0946)), (1.3814224805134716e-06, tensor(0.0943)), (1.386128970350507e-06, tensor(0.0945)), (1.3908514951420174e-06, tensor(0.0944)), (1.395590109518901e-06, tensor(0.0945)), (1.400344868298182e-06, tensor(0.0942)), (1.405115826483646e-06, tensor(0.0949)), (1.4099030392664759e-06, tensor(0.0952)), (1.41470656202589e-06, tensor(0.0951)), (1.4195264503297833e-06, tensor(0.0953)), (1.4243627599353694e-06, tensor(0.0955)), (1.4292155467898263e-06, tensor(0.0953)), (1.434084867030944e-06, tensor(0.0953)), (1.4389707769877723e-06, tensor(0.0952)), (1.443873333181274e-06, tensor(0.0949)), (1.4487925923249778e-06, tensor(0.0950)), (1.4537286113256351e-06, tensor(0.0949)), (1.4586814472838774e-06, tensor(0.0946)), (1.463651157494878e-06, tensor(0.0950)), (1.4686377994490137e-06, tensor(0.0946)), (1.4736414308325302e-06, tensor(0.0946)), (1.4786621095282102e-06, tensor(0.0940)), (1.4836998936160418e-06, tensor(0.0946)), (1.4887548413738912e-06, tensor(0.0945)), (1.493827011278176e-06, tensor(0.0943)), (1.4989164620045437e-06, tensor(0.0938)), (1.504023252428547e-06, tensor(0.0937)), (1.5091474416263285e-06, tensor(0.0934)), (1.5142890888753019e-06, tensor(0.0934)), (1.5194482536548382e-06, tensor(0.0935)), (1.5246249956469546e-06, tensor(0.0935)), (1.5298193747370035e-06, tensor(0.0937)), (1.5350314510143656e-06, tensor(0.0940)), (1.540261284773147e-06, tensor(0.0940)), (1.5455089365128732e-06, tensor(0.0937)), (1.5507744669391924e-06, tensor(0.0938)), (1.5560579369645754e-06, tensor(0.0936)), (1.5613594077090212e-06, tensor(0.0938)), (1.5666789405007638e-06, tensor(0.0937)), (1.5720165968769823e-06, tensor(0.0941)), (1.5773724385845113e-06, tensor(0.0945)), (1.582746527580557e-06, tensor(0.0948)), (1.5881389260334125e-06, tensor(0.0954)), (1.593549696323178e-06, tensor(0.0958)), (1.5989789010424815e-06, tensor(0.0961)), (1.6044266029972036e-06, tensor(0.0961)), (1.6098928652072036e-06, tensor(0.0963)), (1.615377750907049e-06, tensor(0.0964)), (1.6208813235467463e-06, tensor(0.0962)), (1.626403646792476e-06, tensor(0.0959)), (1.631944784527328e-06, tensor(0.0960)), (1.6375048008520409e-06, tensor(0.0960)), (1.6430837600857449e-06, tensor(0.0959)), (1.648681726766703e-06, tensor(0.0958)), (1.6542987656530612e-06, tensor(0.0958)), (1.659934941723594e-06, tensor(0.0957)), (1.6655903201784586e-06, tensor(0.0956)), (1.6712649664399489e-06, tensor(0.0954)), (1.6769589461532506e-06, tensor(0.0952)), (1.6826723251872028e-06, tensor(0.0952)), (1.688405169635058e-06, tensor(0.0954)), (1.6941575458152483e-06, tensor(0.0951)), (1.699929520272152e-06, tensor(0.0952)), (1.7057211597768626e-06, tensor(0.0955)), (1.7115325313279625e-06, tensor(0.0956)), (1.717363702152297e-06, tensor(0.0955)), (1.7232147397057534e-06, tensor(0.0954)), (1.7290857116740394e-06, tensor(0.0956)), (1.7349766859734672e-06, tensor(0.0955)), (1.7408877307517395e-06, tensor(0.0952)), (1.7468189143887375e-06, tensor(0.0950)), (1.7527703054973112e-06, tensor(0.0957)), (1.758741972924074e-06, tensor(0.0957)), (1.7647339857501992e-06, tensor(0.0962)), (1.7707464132922187e-06, tensor(0.0959)), (1.7767793251028249e-06, tensor(0.0957)), (1.7828327909716752e-06, tensor(0.0954)), (1.7889068809261997e-06, tensor(0.0960)), (1.7950016652324114e-06, tensor(0.0960)), (1.8011172143957185e-06, tensor(0.0963)), (1.80725359916174e-06, tensor(0.0962)), (1.8134108905171252e-06, tensor(0.0962)), (1.819589159690373e-06, tensor(0.0959)), (1.8257884781526579e-06, tensor(0.0958)), (1.832008917618655e-06, tensor(0.0953)), (1.8382505500473708e-06, tensor(0.0951)), (1.8445134476429758e-06, tensor(0.0950)), (1.8507976828556384e-06, tensor(0.0953)), (1.8571033283823644e-06, tensor(0.0951)), (1.8634304571678371e-06, tensor(0.0950)), (1.8697791424052619e-06, tensor(0.0949)), (1.8761494575372119e-06, tensor(0.0948)), (1.8825414762564787e-06, tensor(0.0948)), (1.8889552725069242e-06, tensor(0.0950)), (1.8953909204843364e-06, tensor(0.0954)), (1.9018484946372867e-06, tensor(0.0952)), (1.9083280696679927e-06, tensor(0.0951)), (1.9148297205331815e-06, tensor(0.0953)), (1.9213535224449563e-06, tensor(0.0950)), (1.9278995508716677e-06, tensor(0.0953)), (1.9344678815387855e-06, tensor(0.0952)), (1.941058590429775e-06, tensor(0.0956)), (1.947671753786978e-06, tensor(0.0951)), (1.9543074481124906e-06, tensor(0.0947)), (1.9609657501690525e-06, tensor(0.0949)), (1.9676467369809325e-06, tensor(0.0946)), (1.97435048583482e-06, tensor(0.0950)), (1.981077074280719e-06, tensor(0.0947)), (1.9878265801328462e-06, tensor(0.0946)), (1.99459908147053e-06, tensor(0.0943)), (2.0013946566391136e-06, tensor(0.0945)), (2.008213384250863e-06, tensor(0.0944)), (2.0150553431858745e-06, tensor(0.0943)), (2.021920612592988e-06, tensor(0.0946)), (2.028809271890703e-06, tensor(0.0948)), (2.0357214007680954e-06, tensor(0.0951)), (2.042657079185743e-06, tensor(0.0952)), (2.0496163873766464e-06, tensor(0.0952)), (2.0565994058471606e-06, tensor(0.0948)), (2.063606215377924e-06, tensor(0.0948)), (2.0706368970247935e-06, tensor(0.0949)), (2.0776915321197825e-06, tensor(0.0950)), (2.0847702022720022e-06, tensor(0.0947)), (2.0918729893686046e-06, tensor(0.0953)), (2.0989999755757293e-06, tensor(0.0958)), (2.106151243339457e-06, tensor(0.0959)), (2.1133268753867594e-06, tensor(0.0960)), (2.1205269547264587e-06, tensor(0.0957)), (2.1277515646501874e-06, tensor(0.0960)), (2.135000788733351e-06, tensor(0.0965)), (2.1422747108360962e-06, tensor(0.0962)), (2.149573415104279e-06, tensor(0.0958)), (2.156896985970441e-06, tensor(0.0958)), (2.164245508154783e-06, tensor(0.0958)), (2.171619066666147e-06, tensor(0.0951)), (2.1790177468029995e-06, tensor(0.0946)), (2.1864416341544166e-06, tensor(0.0948)), (2.1938908146010777e-06, tensor(0.0950)), (2.201365374316254e-06, tensor(0.0953)), (2.2088653997668097e-06, tensor(0.0956)), (2.2163909777142e-06, tensor(0.0957)), (2.2239421952154753e-06, tensor(0.0954)), (2.2315191396242885e-06, tensor(0.0953)), (2.2391218985919053e-06, tensor(0.0957)), (2.2467505600682184e-06, tensor(0.0958)), (2.2544052123027645e-06, tensor(0.0959)), (2.262085943845745e-06, tensor(0.0966)), (2.2697928435490517e-06, tensor(0.0964)), (2.2775260005672928e-06, tensor(0.0967)), (2.2852855043588263e-06, tensor(0.0964)), (2.293071444686792e-06, tensor(0.0964)), (2.3008839116201544e-06, tensor(0.0963)), (2.308722995534738e-06, tensor(0.0957)), (2.316588787114281e-06, tensor(0.0960)), (2.3244813773514768e-06, tensor(0.0958)), (2.3324008575490306e-06, tensor(0.0958)), (2.340347319320716e-06, tensor(0.0958)), (2.348320854592432e-06, tensor(0.0962)), (2.356321555603269e-06, tensor(0.0956)), (2.364349514906575e-06, tensor(0.0954)), (2.372404825371025e-06, tensor(0.0951)), (2.380487580181698e-06, tensor(0.0954)), (2.388597872841153e-06, tensor(0.0957)), (2.3967357971705094e-06, tensor(0.0961)), (2.4049014473105366e-06, tensor(0.0960)), (2.4130949177227397e-06, tensor(0.0961)), (2.421316303190451e-06, tensor(0.0965)), (2.429565698819931e-06, tensor(0.0964)), (2.437843200041466e-06, tensor(0.0962)), (2.4461489026104697e-06, tensor(0.0961)), (2.454482902608596e-06, tensor(0.0961)), (2.462845296444847e-06, tensor(0.0960)), (2.4712361808566884e-06, tensor(0.0959)), (2.47965565291117e-06, tensor(0.0961)), (2.4881038100060482e-06, tensor(0.0970)), (2.4965807498709107e-06, tensor(0.0972)), (2.505086570568311e-06, tensor(0.0972)), (2.5136213704948987e-06, tensor(0.0975)), (2.5221852483825608e-06, tensor(0.0973)), (2.5307783032995627e-06, tensor(0.0972)), (2.539400634651693e-06, tensor(0.0970)), (2.5480523421834156e-06, tensor(0.0968)), (2.556733525979022e-06, tensor(0.0967)), (2.5654442864637903e-06, tensor(0.0965)), (2.5741847244051464e-06, tensor(0.0966)), (2.582954940913829e-06, tensor(0.0964)), (2.5917550374450597e-06, tensor(0.0963)), (2.6005851157997177e-06, tensor(0.0962)), (2.609445278125516e-06, tensor(0.0961)), (2.618335626918184e-06, tensor(0.0961)), (2.627256265022652e-06, tensor(0.0956)), (2.636207295634243e-06, tensor(0.0952)), (2.645188822299865e-06, tensor(0.0951)), (2.6542009489192073e-06, tensor(0.0947)), (2.6632437797459466e-06, tensor(0.0950)), (2.6723174193889495e-06, tensor(0.0952)), (2.6814219728134823e-06, tensor(0.0954)), (2.69055754534243e-06, tensor(0.0957)), (2.699724242657509e-06, tensor(0.0957)), (2.708922170800493e-06, tensor(0.0957)), (2.718151436174438e-06, tensor(0.0954)), (2.7274121455449143e-06, tensor(0.0952)), (2.7367044060412417e-06, tensor(0.0953)), (2.7460283251577275e-06, tensor(0.0954)), (2.7553840107549115e-06, tensor(0.0956)), (2.7647715710608124e-06, tensor(0.0957)), (2.774191114672181e-06, tensor(0.0957)), (2.783642750555756e-06, tensor(0.0963)), (2.7931265880495238e-06, tensor(0.0964)), (2.8026427368639847e-06, tensor(0.0966)), (2.8121913070834216e-06, tensor(0.0967)), (2.8217724091671717e-06, tensor(0.0967)), (2.8313861539509077e-06, tensor(0.0969)), (2.8410326526479165e-06, tensor(0.0970)), (2.850712016850389e-06, tensor(0.0971)), (2.8604243585307083e-06, tensor(0.0968)), (2.8701697900427455e-06, tensor(0.0970)), (2.8799484241231616e-06, tensor(0.0970)), (2.8897603738927083e-06, tensor(0.0970)), (2.8996057528575407e-06, tensor(0.0975)), (2.909484674910525e-06, tensor(0.0975)), (2.9193972543325616e-06, tensor(0.0973)), (2.9293436057939025e-06, tensor(0.0973)), (2.939323844355482e-06, tensor(0.0974)), (2.949338085470244e-06, tensor(0.0977)), (2.95938644498448e-06, tensor(0.0976)), (2.969469039139168e-06, tensor(0.0974)), (2.9795859845713176e-06, tensor(0.0975)), (2.9897373983153193e-06, tensor(0.0973)), (2.999923397804299e-06, tensor(0.0975)), (3.010144100871475e-06, tensor(0.0973)), (3.0203996257515233e-06, tensor(0.0975)), (3.0306900910819418e-06, tensor(0.0975)), (3.041015615904427e-06, tensor(0.0972)), (3.0513763196662476e-06, tensor(0.0975)), (3.0617723222216285e-06, tensor(0.0975)), (3.072203743833137e-06, tensor(0.0977)), (3.082670705173073e-06, tensor(0.0973)), (3.093173327324864e-06, tensor(0.0969)), (3.10371173178447e-06, tensor(0.0971)), (3.1142860404617847e-06, tensor(0.0968)), (3.1248963756820466e-06, tensor(0.0970)), (3.1355428601872573e-06, tensor(0.0969)), (3.1462256171375964e-06, tensor(0.0967)), (3.15694477011285e-06, tensor(0.0964)), (3.167700443113839e-06, tensor(0.0963)), (3.178492760563853e-06, tensor(0.0963)), (3.189321847310091e-06, tensor(0.0962)), (3.200187828625105e-06, tensor(0.0962)), (3.211090830208248e-06, tensor(0.0964)), (3.22203097818713e-06, tensor(0.0972)), (3.233008399119077e-06, tensor(0.0976)), (3.244023219992593e-06, tensor(0.0976)), (3.2550755682288296e-06, tensor(0.0972)), (3.2661655716830638e-06, tensor(0.0970)), (3.277293358646171e-06, tensor(0.0968)), (3.288459057846113e-06, tensor(0.0967)), (3.299662798449427e-06, tensor(0.0969)), (3.310904710062718e-06, tensor(0.0968)), (3.3221849227341597e-06, tensor(0.0966)), (3.3335035669549983e-06, tensor(0.0965)), (3.3448607736610616e-06, tensor(0.0966)), (3.356256674234275e-06, tensor(0.0966)), (3.367691400504181e-06, tensor(0.0966)), (3.3791650847494617e-06, tensor(0.0964)), (3.3906778596994724e-06, tensor(0.0967)), (3.4022298585357766e-06, tensor(0.0965)), (3.4138212148936845e-06, tensor(0.0962)), (3.4254520628638004e-06, tensor(0.0961)), (3.437122536993574e-06, tensor(0.0962)), (3.4488327722888562e-06, tensor(0.0966)), (3.4605829042154617e-06, tensor(0.0967)), (3.472373068700735e-06, tensor(0.0966)), (3.4842034021351237e-06, tensor(0.0965)), (3.4960740413737567e-06, tensor(0.0965)), (3.5079851237380258e-06, tensor(0.0963)), (3.5199367870171745e-06, tensor(0.0961)), (3.5319291694698948e-06, tensor(0.0963)), (3.5439624098259225e-06, tensor(0.0962)), (3.5560366472876443e-06, tensor(0.0961)), (3.5681520215317087e-06, tensor(0.0962)), (3.5803086727106394e-06, tensor(0.0959)), (3.5925067414544595e-06, tensor(0.0958)), (3.6047463688723165e-06, tensor(0.0954)), (3.617027696554114e-06, tensor(0.0957)), (3.629350866572152e-06, tensor(0.0954)), (3.641716021482768e-06, tensor(0.0956)), (3.6541233043279887e-06, tensor(0.0955)), (3.6665728586371824e-06, tensor(0.0955)), (3.67906482842872e-06, tensor(0.0954)), (3.6915993582116417e-06, tensor(0.0952)), (3.704176592987328e-06, tensor(0.0953)), (3.7167966782511776e-06, tensor(0.0953)), (3.7294597599942908e-06, tensor(0.0949)), (3.742165984705156e-06, tensor(0.0953)), (3.754915499371348e-06, tensor(0.0952)), (3.767708451481226e-06, tensor(0.0951)), (3.7805449890256398e-06, tensor(0.0950)), (3.793425260499642e-06, tensor(0.0954)), (3.8063494149042083e-06, tensor(0.0951)), (3.819317601747955e-06, tensor(0.0950)), (3.832329971048877e-06, tensor(0.0952)), (3.8453866733360755e-06, tensor(0.0956)), (3.8584878596515035e-06, tensor(0.0956)), (3.8716336815517115e-06, tensor(0.0953)), (3.8848242911096024e-06, tensor(0.0958)), (3.898059840916189e-06, tensor(0.0962)), (3.911340484082361e-06, tensor(0.0965)), (3.924666374240654e-06, tensor(0.0963)), (3.9380376655470266e-06, tensor(0.0964)), (3.951454512682647e-06, tensor(0.0960)), (3.96491707085568e-06, tensor(0.0960)), (3.978425495803082e-06, tensor(0.0962)), (3.9919799437924025e-06, tensor(0.0959)), (4.005580571623595e-06, tensor(0.0957)), (4.019227536630829e-06, tensor(0.0961)), (4.0329209966843055e-06, tensor(0.0955)), (4.0466611101920905e-06, tensor(0.0958)), (4.060448036101943e-06, tensor(0.0956)), (4.074281933903158e-06, tensor(0.0958)), (4.088162963628405e-06, tensor(0.0959)), (4.102091285855584e-06, tensor(0.0960)), (4.116067061709683e-06, tensor(0.0960)), (4.13009045286464e-06, tensor(0.0964)), (4.144161621545216e-06, tensor(0.0964)), (4.158280730528867e-06, tensor(0.0959)), (4.17244794314763e-06, tensor(0.0957)), (4.186663423290015e-06, tensor(0.0956)), (4.200927335402896e-06, tensor(0.0954)), (4.215239844493415e-06, tensor(0.0954)), (4.229601116130895e-06, tensor(0.0954)), (4.2440113164487465e-06, tensor(0.0957)), (4.258470612146399e-06, tensor(0.0961)), (4.272979170491222e-06, tensor(0.0957)), (4.2875371593204654e-06, tensor(0.0955)), (4.302144747043196e-06, tensor(0.0954)), (4.31680210264225e-06, tensor(0.0951)), (4.331509395676187e-06, tensor(0.0948)), (4.346266796281246e-06, tensor(0.0944)), (4.361074475173324e-06, tensor(0.0940)), (4.375932603649942e-06, tensor(0.0944)), (4.390841353592229e-06, tensor(0.0944)), (4.405800897466913e-06, tensor(0.0949)), (4.4208114083283125e-06, tensor(0.0946)), (4.43587305982034e-06, tensor(0.0945)), (4.450986026178513e-06, tensor(0.0941)), (4.466150482231964e-06, tensor(0.0938)), (4.481366603405467e-06, tensor(0.0938)), (4.496634565721469e-06, tensor(0.0942)), (4.51195454580212e-06, tensor(0.0940)), (4.52732672087132e-06, tensor(0.0943)), (4.542751268756772e-06, tensor(0.0945)), (4.558228367892031e-06, tensor(0.0945)), (4.573758197318577e-06, tensor(0.0948)), (4.589340936687879e-06, tensor(0.0946)), (4.6049767662634795e-06, tensor(0.0948)), (4.620665866923075e-06, tensor(0.0948)), (4.6364084201606074e-06, tensor(0.0946)), (4.652204608088373e-06, tensor(0.0939)), (4.668054613439117e-06, tensor(0.0937)), (4.683958619568155e-06, tensor(0.0939)), (4.6999168104554906e-06, tensor(0.0941)), (4.715929370707948e-06, tensor(0.0939)), (4.7319964855612995e-06, tensor(0.0940)), (4.748118340882421e-06, tensor(0.0942)), (4.7642951231714255e-06, tensor(0.0947)), (4.780527019563837e-06, tensor(0.0947)), (4.796814217832745e-06, tensor(0.0950)), (4.81315690639098e-06, tensor(0.0951)), (4.829555274293292e-06, tensor(0.0950)), (4.8460095112385416e-06, tensor(0.0952)), (4.862519807571885e-06, tensor(0.0951)), (4.879086354286988e-06, tensor(0.0949)), (4.895709343028227e-06, tensor(0.0950)), (4.912388966092907e-06, tensor(0.0949)), (4.929125416433491e-06, tensor(0.0951)), (4.945918887659827e-06, tensor(0.0948)), (4.962769574041388e-06, tensor(0.0947)), (4.979677670509525e-06, tensor(0.0951)), (4.996643372659712e-06, tensor(0.0948)), (5.013666876753819e-06, tensor(0.0944)), (5.030748379722376e-06, tensor(0.0951)), (5.047888079166853e-06, tensor(0.0953)), (5.065086173361947e-06, tensor(0.0957)), (5.0823428612578715e-06, tensor(0.0953)), (5.099658342482666e-06, tensor(0.0952)), (5.117032817344495e-06, tensor(0.0950)), (5.134466486833974e-06, tensor(0.0949)), (5.151959552626489e-06, tensor(0.0948)), (5.169512217084534e-06, tensor(0.0947)), (5.187124683260048e-06, tensor(0.0946)), (5.204797154896766e-06, tensor(0.0945)), (5.2225298364325744e-06, tensor(0.0944)), (5.240322933001878e-06, tensor(0.0943)), (5.2581766504379725e-06, tensor(0.0949)), (5.276091195275424e-06, tensor(0.0951)), (5.294066774752461e-06, tensor(0.0949)), (5.312103596813368e-06, tensor(0.0950)), (5.330201870110895e-06, tensor(0.0951)), (5.348361804008669e-06, tensor(0.0946)), (5.366583608583615e-06, tensor(0.0947)), (5.38486749462839e-06, tensor(0.0946)), (5.403213673653818e-06, tensor(0.0946)), (5.421622357891336e-06, tensor(0.0946)), (5.440093760295454e-06, tensor(0.0944)), (5.458628094546214e-06, tensor(0.0946)), (5.477225575051661e-06, tensor(0.0944)), (5.495886416950331e-06, tensor(0.0946)), (5.51461083611373e-06, tensor(0.0949)), (5.533399049148838e-06, tensor(0.0947)), (5.55225127340061e-06, tensor(0.0948)), (5.571167726954495e-06, tensor(0.0944)), (5.590148628638957e-06, tensor(0.0946)), (5.609194198028001e-06, tensor(0.0949)), (5.628304655443725e-06, tensor(0.0951)), (5.647480221958857e-06, tensor(0.0949)), (5.666721119399318e-06, tensor(0.0953)), (5.686027570346788e-06, tensor(0.0958)), (5.705399798141281e-06, tensor(0.0960)), (5.724838026883724e-06, tensor(0.0967)), (5.7443424814385586e-06, tensor(0.0969)), (5.7639133874363325e-06, tensor(0.0968)), (5.783550971276315e-06, tensor(0.0967)), (5.803255460129116e-06, tensor(0.0968)), (5.823027081939314e-06, tensor(0.0967)), (5.842866065428089e-06, tensor(0.0964)), (5.862772640095871e-06, tensor(0.0963)), (5.882747036225e-06, tensor(0.0961)), (5.902789484882381e-06, tensor(0.0963)), (5.922900217922161e-06, tensor(0.0975)), (5.943079467988414e-06, tensor(0.0972)), (5.963327468517827e-06, tensor(0.0971)), (5.983644453742406e-06, tensor(0.0970)), (6.004030658692179e-06, tensor(0.0967)), (6.024486319197921e-06, tensor(0.0966)), (6.0450116718938775e-06, tensor(0.0961)), (6.065606954220508e-06, tensor(0.0960)), (6.086272404427223e-06, tensor(0.0960)), (6.107008261575153e-06, tensor(0.0960)), (6.1278147655399e-06, tensor(0.0960)), (6.148692157014322e-06, tensor(0.0962)), (6.169640677511318e-06, tensor(0.0959)), (6.190660569366612e-06, tensor(0.0960)), (6.21175207574157e-06, tensor(0.0961)), (6.232915440625999e-06, tensor(0.0960)), (6.254150908840982e-06, tensor(0.0964)), (6.275458726041701e-06, tensor(0.0964)), (6.2968391387202845e-06, tensor(0.0961)), (6.318292394208653e-06, tensor(0.0958)), (6.33981874068139e-06, tensor(0.0958)), (6.361418427158602e-06, tensor(0.0956)), (6.383091703508804e-06, tensor(0.0959)), (6.404838820451813e-06, tensor(0.0964)), (6.426660029561644e-06, tensor(0.0962)), (6.448555583269421e-06, tensor(0.0959)), (6.4705257348662975e-06, tensor(0.0964)), (6.492570738506389e-06, tensor(0.0962)), (6.514690849209709e-06, tensor(0.0961)), (6.5368863228651215e-06, tensor(0.0962)), (6.559157416233304e-06, tensor(0.0960)), (6.581504386949707e-06, tensor(0.0958)), (6.60392749352755e-06, tensor(0.0952)), (6.6264269953608e-06, tensor(0.0953)), (6.649003152727176e-06, tensor(0.0953)), (6.671656226791161e-06, tensor(0.0953)), (6.694386479607023e-06, tensor(0.0952)), (6.717194174121843e-06, tensor(0.0954)), (6.740079574178563e-06, tensor(0.0951)), (6.763042944519032e-06, tensor(0.0951)), (6.786084550787071e-06, tensor(0.0957)), (6.809204659531551e-06, tensor(0.0965)), (6.832403538209467e-06, tensor(0.0959)), (6.8556814551890396e-06, tensor(0.0958)), (6.879038679752813e-06, tensor(0.0954)), (6.902475482100778e-06, tensor(0.0957)), (6.92599213335349e-06, tensor(0.0955)), (6.9495889055552125e-06, tensor(0.0952)), (6.973266071677057e-06, tensor(0.0954)), (6.997023905620148e-06, tensor(0.0952)), (7.0208626822187835e-06, tensor(0.0953)), (7.044782677243622e-06, tensor(0.0951)), (7.068784167404869e-06, tensor(0.0954)), (7.092867430355477e-06, tensor(0.0958)), (7.1170327446943595e-06, tensor(0.0961)), (7.141280389969613e-06, tensor(0.0963)), (7.165610646681752e-06, tensor(0.0971)), (7.190023796286949e-06, tensor(0.0975)), (7.214520121200301e-06, tensor(0.0974)), (7.2390999047990845e-06, tensor(0.0969)), (7.2637634314260405e-06, tensor(0.0967)), (7.288510986392663e-06, tensor(0.0965)), (7.313342855982498e-06, tensor(0.0968)), (7.338259327454457e-06, tensor(0.0968)), (7.363260689046137e-06, tensor(0.0966)), (7.388347229977161e-06, tensor(0.0965)), (7.413519240452515e-06, tensor(0.0961)), (7.438777011665914e-06, tensor(0.0963)), (7.464120835803165e-06, tensor(0.0964)), (7.489551006045546e-06, tensor(0.0966)), (7.5150678165732045e-06, tensor(0.0962)), (7.540671562568554e-06, tensor(0.0962)), (7.566362540219692e-06, tensor(0.0957)), (7.5921410467238216e-06, tensor(0.0959)), (7.618007380290698e-06, tensor(0.0961)), (7.643961840146073e-06, tensor(0.0959)), (7.670004726535152e-06, tensor(0.0958)), (7.696136340726078e-06, tensor(0.0956)), (7.722356985013409e-06, tensor(0.0953)), (7.748666962721615e-06, tensor(0.0954)), (7.775066578208591e-06, tensor(0.0954)), (7.801556136869175e-06, tensor(0.0955)), (7.828135945138683e-06, tensor(0.0957)), (7.854806310496449e-06, tensor(0.0961)), (7.881567541469388e-06, tensor(0.0958)), (7.908419947635563e-06, tensor(0.0957)), (7.935363839627764e-06, tensor(0.0957)), (7.962399529137104e-06, tensor(0.0955)), (7.989527328916625e-06, tensor(0.0950)), (8.016747552784914e-06, tensor(0.0956)), (8.044060515629728e-06, tensor(0.0953)), (8.071466533411659e-06, tensor(0.0958)), (8.098965923167752e-06, tensor(0.0964)), (8.126559003015213e-06, tensor(0.0965)), (8.154246092155055e-06, tensor(0.0967)), (8.182027510875814e-06, tensor(0.0969)), (8.209903580557238e-06, tensor(0.0972)), (8.237874623674018e-06, tensor(0.0969)), (8.265940963799511e-06, tensor(0.0970)), (8.294102925609483e-06, tensor(0.0970)), (8.322360834885865e-06, tensor(0.0967)), (8.350715018520528e-06, tensor(0.0966)), (8.379165804519056e-06, tensor(0.0966)), (8.407713522004545e-06, tensor(0.0963)), (8.43635850122141e-06, tensor(0.0964)), (8.465101073539205e-06, tensor(0.0963)), (8.493941571456454e-06, tensor(0.0962)), (8.522880328604499e-06, tensor(0.0959)), (8.551917679751365e-06, tensor(0.0965)), (8.581053960805625e-06, tensor(0.0969)), (8.610289508820285e-06, tensor(0.0968)), (8.63962466199669e-06, tensor(0.0968)), (8.669059759688437e-06, tensor(0.0967)), (8.698595142405286e-06, tensor(0.0964)), (8.728231151817119e-06, tensor(0.0961)), (8.75796813075788e-06, tensor(0.0958)), (8.787806423229542e-06, tensor(0.0957)), (8.817746374406092e-06, tensor(0.0955)), (8.847788330637521e-06, tensor(0.0960)), (8.877932639453826e-06, tensor(0.0959)), (8.908179649569038e-06, tensor(0.0959)), (8.938529710885254e-06, tensor(0.0957)), (8.968983174496678e-06, tensor(0.0956)), (8.99954039269369e-06, tensor(0.0956)), (9.030201718966922e-06, tensor(0.0956)), (9.060967508011342e-06, tensor(0.0961)), (9.09183811573036e-06, tensor(0.0965)), (9.122813899239942e-06, tensor(0.0966)), (9.153895216872746e-06, tensor(0.0961)), (9.185082428182267e-06, tensor(0.0960)), (9.216375893946994e-06, tensor(0.0960)), (9.24777597617458e-06, tensor(0.0964)), (9.279283038106037e-06, tensor(0.0966)), (9.310897444219934e-06, tensor(0.0968)), (9.342619560236614e-06, tensor(0.0966)), (9.374449753122427e-06, tensor(0.0969)), (9.406388391093967e-06, tensor(0.0967)), (9.438435843622345e-06, tensor(0.0965)), (9.470592481437452e-06, tensor(0.0966)), (9.50285867653225e-06, tensor(0.0965)), (9.53523480216708e-06, tensor(0.0968)), (9.567721232873973e-06, tensor(0.0970)), (9.600318344460987e-06, tensor(0.0969)), (9.633026514016555e-06, tensor(0.0970)), (9.665846119913845e-06, tensor(0.0968)), (9.698777541815141e-06, tensor(0.0975)), (9.731821160676224e-06, tensor(0.0979)), (9.764977358750792e-06, tensor(0.0975)), (9.79824651959488e-06, tensor(0.0981)), (9.831629028071287e-06, tensor(0.0977)), (9.865125270354038e-06, tensor(0.0980)), (9.898735633932849e-06, tensor(0.0977)), (9.932460507617608e-06, tensor(0.0977)), (9.966300281542874e-06, tensor(0.0977)), (1.0000255347172391e-05, tensor(0.0973)), (1.003432609730361e-05, tensor(0.0975)), (1.0068512926072246e-05, tensor(0.0978)), (1.0102816228956822e-05, tensor(0.0984)), (1.0137236402783259e-05, tensor(0.0985)), (1.0171773845729453e-05, tensor(0.0982)), (1.020642895732989e-05, tensor(0.0982)), (1.0241202138480265e-05, tensor(0.0982)), (1.027609379144212e-05, tensor(0.0983)), (1.0311104319847497e-05, tensor(0.0986)), (1.0346234128703608e-05, tensor(0.0984)), (1.0381483624397515e-05, tensor(0.0980)), (1.0416853214700848e-05, tensor(0.0977)), (1.0452343308774498e-05, tensor(0.0980)), (1.0487954317173367e-05, tensor(0.0980)), (1.0523686651851109e-05, tensor(0.0981)), (1.0559540726164907e-05, tensor(0.0978)), (1.059551695488024e-05, tensor(0.0977)), (1.0631615754175691e-05, tensor(0.0976)), (1.0667837541647755e-05, tensor(0.0973)), (1.0704182736315679e-05, tensor(0.0977)), (1.07406517586263e-05, tensor(0.0970)), (1.0777245030458912e-05, tensor(0.0967)), (1.0813962975130148e-05, tensor(0.0963)), (1.085080601739887e-05, tensor(0.0963)), (1.0887774583471104e-05, tensor(0.0961)), (1.0924869101004936e-05, tensor(0.0966)), (1.0962089999115492e-05, tensor(0.0965)), (1.0999437708379876e-05, tensor(0.0965)), (1.1036912660842175e-05, tensor(0.0965)), (1.1074515290018435e-05, tensor(0.0972)), (1.1112246030901696e-05, tensor(0.0972)), (1.1150105319967003e-05, tensor(0.0974)), (1.1188093595176477e-05, tensor(0.0970)), (1.122621129598436e-05, tensor(0.0967)), (1.1264458863342118e-05, tensor(0.0966)), (1.130283673970353e-05, tensor(0.0963)), (1.1341345369029811e-05, tensor(0.0960)), (1.1379985196794743e-05, tensor(0.0961)), (1.1418756669989835e-05, tensor(0.0958)), (1.1457660237129492e-05, tensor(0.0959)), (1.1496696348256197e-05, tensor(0.0955)), (1.1535865454945728e-05, tensor(0.0953)), (1.1575168010312372e-05, tensor(0.0953)), (1.1614604469014174e-05, tensor(0.0957)), (1.1654175287258194e-05, tensor(0.0957)), (1.1693880922805777e-05, tensor(0.0960)), (1.1733721834977868e-05, tensor(0.0961)), (1.1773698484660299e-05, tensor(0.0959)), (1.1813811334309143e-05, tensor(0.0957)), (1.1854060847956055e-05, tensor(0.0960)), (1.1894447491213638e-05, tensor(0.0960)), (1.1934971731280832e-05, tensor(0.0961)), (1.1975634036948318e-05, tensor(0.0961)), (1.2016434878603944e-05, tensor(0.0961)), (1.2057374728238158e-05, tensor(0.0964)), (1.2098454059449482e-05, tensor(0.0963)), (1.2139673347449972e-05, tensor(0.0962)), (1.2181033069070735e-05, tensor(0.0965)), (1.2222533702767431e-05, tensor(0.0969)), (1.2264175728625817e-05, tensor(0.0966)), (1.230595962836729e-05, tensor(0.0967)), (1.2347885885354471e-05, tensor(0.0966)), (1.238995498459679e-05, tensor(0.0962)), (1.2432167412756098e-05, tensor(0.0964)), (1.2474523658152301e-05, tensor(0.0963)), (1.2517024210768997e-05, tensor(0.0962)), (1.2559669562259159e-05, tensor(0.0965)), (1.2602460205950814e-05, tensor(0.0960)), (1.2645396636852751e-05, tensor(0.0957)), (1.2688479351660248e-05, tensor(0.0951)), (1.2731708848760819e-05, tensor(0.0949)), (1.2775085628239978e-05, tensor(0.0942)), (1.2818610191887022e-05, tensor(0.0944)), (1.2862283043200843e-05, tensor(0.0942)), (1.290610468739574e-05, tensor(0.0944)), (1.2950075631407282e-05, tensor(0.0950)), (1.299419638389815e-05, tensor(0.0953)), (1.303846745526404e-05, tensor(0.0954)), (1.3082889357639558e-05, tensor(0.0954)), (1.3127462604904146e-05, tensor(0.0957)), (1.3172187712688028e-05, tensor(0.0958)), (1.3217065198378174e-05, tensor(0.0955)), (1.3262095581124281e-05, tensor(0.0952)), (1.3307279381844788e-05, tensor(0.0952)), (1.3352617123232899e-05, tensor(0.0951)), (1.3398109329762621e-05, tensor(0.0952)), (1.3443756527694841e-05, tensor(0.0955)), (1.3489559245083406e-05, tensor(0.0957)), (1.3535518011781248e-05, tensor(0.0961)), (1.3581633359446487e-05, tensor(0.0954)), (1.3627905821548607e-05, tensor(0.0959)), (1.3674335933374607e-05, tensor(0.0959)), (1.372092423203521e-05, tensor(0.0958)), (1.3767671256471067e-05, tensor(0.0958)), (1.3814577547458992e-05, tensor(0.0958)), (1.3861643647618215e-05, tensor(0.0955)), (1.3908870101416672e-05, tensor(0.0955)), (1.3956257455177289e-05, tensor(0.0958)), (1.400380625708431e-05, tensor(0.0959)), (1.4051517057189634e-05, tensor(0.0962)), (1.409939040741918e-05, tensor(0.0960)), (1.4147426861579277e-05, tensor(0.0962)), (1.4195626975363058e-05, tensor(0.0961)), (1.42439913063569e-05, tensor(0.0963)), (1.4292520414046874e-05, tensor(0.0961)), (1.4341214859825206e-05, tensor(0.0960)), (1.439007520699678e-05, tensor(0.0962)), (1.4439102020785657e-05, tensor(0.0963)), (1.4488295868341609e-05, tensor(0.0958)), (1.4537657318746676e-05, tensor(0.0956)), (1.4587186943021757e-05, tensor(0.0955)), (1.4636885314133213e-05, tensor(0.0954)), (1.468675300699949e-05, tensor(0.0956)), (1.4736790598497784e-05, tensor(0.0953)), (1.478699866747069e-05, tensor(0.0955)), (1.483737779473293e-05, tensor(0.0955)), (1.4887928563078039e-05, tensor(0.0950)), (1.4938651557285133e-05, tensor(0.0948)), (1.4989547364125659e-05, tensor(0.0952)), (1.5040616572370188e-05, tensor(0.0950)), (1.5091859772795226e-05, tensor(0.0950)), (1.5143277558190045e-05, tensor(0.0947)), (1.5194870523363549e-05, tensor(0.0947)), (1.524663926515114e-05, tensor(0.0943)), (1.529858438242164e-05, tensor(0.0948)), (1.5350706476084204e-05, tensor(0.0955)), (1.540300614909528e-05, tensor(0.0959)), (1.5455484006465576e-05, tensor(0.0959)), (1.5508140655267074e-05, tensor(0.0955)), (1.5560976704640034e-05, tensor(0.0952)), (1.5613992765800056e-05, tensor(0.0953)), (1.566718945204514e-05, tensor(0.0956)), (1.5720567378762786e-05, tensor(0.0956)), (1.577412716343711e-05, tensor(0.0955)), (1.5827869425655997e-05, tensor(0.0952)), (1.5881794787118246e-05, tensor(0.0955)), (1.5935903871640795e-05, tensor(0.0958)), (1.5990197305165903e-05, tensor(0.0953)), (1.604467571576841e-05, tensor(0.0957)), (1.6099339733663015e-05, tensor(0.0961)), (1.6154189991211523e-05, tensor(0.0960)), (1.6209227122930208e-05, tensor(0.0964)), (1.626445176549713e-05, tensor(0.0964)), (1.63198645577595e-05, tensor(0.0963)), (1.6375466140741076e-05, tensor(0.0958)), (1.643125715764958e-05, tensor(0.0954)), (1.6487238253884127e-05, tensor(0.0957)), (1.6543410077042707e-05, tensor(0.0956)), (1.6599773276929656e-05, tensor(0.0954)), (1.66563285055632e-05, tensor(0.0955)), (1.6713076417182983e-05, tensor(0.0953)), (1.6770017668257618e-05, tensor(0.0951)), (1.6827152917492318e-05, tensor(0.0949)), (1.688448282583649e-05, tensor(0.0950)), (1.694200805649139e-05, tensor(0.0951)), (1.699972927491778e-05, tensor(0.0948)), (1.7057647148843654e-05, tensor(0.0946)), (1.711576234827195e-05, tensor(0.0943)), (1.7174075545488277e-05, tensor(0.0945)), (1.7232587415068736e-05, tensor(0.0947)), (1.7291298633887683e-05, tensor(0.0946)), (1.7350209881125596e-05, tensor(0.0942)), (1.7409321838276887e-05, tensor(0.0944)), (1.7468635189157836e-05, tensor(0.0943)), (1.7528150619914465e-05, tensor(0.0946)), (1.7587868819030486e-05, tensor(0.0947)), (1.764779047733527e-05, tensor(0.0947)), (1.7707916288011837e-05, tensor(0.0947)), (1.776824694660487e-05, tensor(0.0945)), (1.7828783151028764e-05, tensor(0.0948)), (1.788952560157571e-05, tensor(0.0951)), (1.7950475000923766e-05, tensor(0.0953)), (1.8011632054145022e-05, tensor(0.0951)), (1.8072997468713735e-05, tensor(0.0954)), (1.8134571954514525e-05, tensor(0.0954)), (1.8196356223850568e-05, tensor(0.0956)), (1.8258350991451856e-05, tensor(0.0955)), (1.8320556974483455e-05, tensor(0.0952)), (1.8382974892553808e-05, tensor(0.0951)), (1.8445605467723047e-05, tensor(0.0953)), (1.8508449424511366e-05, tensor(0.0954)), (1.8571507489907383e-05, tensor(0.0952)), (1.8634780393376553e-05, tensor(0.0954)), (1.8698268866869625e-05, tensor(0.0957)), (1.876197364483108e-05, tensor(0.0958)), (1.8825895464207654e-05, tensor(0.0962)), (1.8890035064456845e-05, tensor(0.0960)), (1.895439318755548e-05, tensor(0.0962)), (1.9018970578008287e-05, tensor(0.0961)), (1.908376798285651e-05, tensor(0.0961)), (1.914878615168656e-05, tensor(0.0959)), (1.921402583663868e-05, tensor(0.0960)), (1.9279487792415645e-05, tensor(0.0957)), (1.934517277629148e-05, tensor(0.0955)), (1.941108154812026e-05, tensor(0.0952)), (1.947721487034485e-05, tensor(0.0952)), (1.954357350800576e-05, tensor(0.0951)), (1.9610158228749985e-05, tensor(0.0947)), (1.9676969802839874e-05, tensor(0.0948)), (1.9744009003162063e-05, tensor(0.0948)), (1.9811276605236393e-05, tensor(0.0946)), (1.98787733872249e-05, tensor(0.0947)), (1.9946500129940803e-05, tensor(0.0945)), (2.0014457616857546e-05, tensor(0.0941)), (2.0082646634117856e-05, tensor(0.0943)), (2.015106797054284e-05, tensor(0.0944)), (2.0219722417641103e-05, tensor(0.0940)), (2.0288610769617925e-05, tensor(0.0944)), (2.0357733823384414e-05, tensor(0.0948)), (2.042709237856676e-05, tensor(0.0945)), (2.0496687237515466e-05, tensor(0.0946)), (2.056651920531463e-05, tensor(0.0944)), (2.063658908979126e-05, tensor(0.0941)), (2.0706897701524635e-05, tensor(0.0940)), (2.0777445853855654e-05, tensor(0.0940)), (2.0848234362896255e-05, tensor(0.0943)), (2.091926404753888e-05, tensor(0.0943)), (2.0990535729465903e-05, tensor(0.0943)), (2.1062050233159184e-05, tensor(0.0938)), (2.113380838590956e-05, tensor(0.0936)), (2.1205811017826455e-05, tensor(0.0933)), (2.1278058961847454e-05, tensor(0.0933)), (2.1350553053747964e-05, tensor(0.0932)), (2.1423294132150857e-05, tensor(0.0935)), (2.1496283038536184e-05, tensor(0.0934)), (2.1569520617250915e-05, tensor(0.0938)), (2.1643007715518694e-05, tensor(0.0942)), (2.1716745183449652e-05, tensor(0.0946)), (2.1790733874050227e-05, tensor(0.0945)), (2.1864974643233046e-05, tensor(0.0948)), (2.1939468349826818e-05, tensor(0.0949)), (2.2014215855586267e-05, tensor(0.0949)), (2.2089218025202118e-05, tensor(0.0950)), (2.216447572631107e-05, tensor(0.0954)), (2.223998982950586e-05, tensor(0.0956)), (2.2315761208345325e-05, tensor(0.0957)), (2.23917907393645e-05, tensor(0.0955)), (2.2468079302084765e-05, tensor(0.0955)), (2.254462777902403e-05, tensor(0.0954)), (2.2621437055706915e-05, tensor(0.0958)), (2.269850802067503e-05, tensor(0.0959)), (2.277584156549722e-05, tensor(0.0958)), (2.2853438584779903e-05, tensor(0.0959)), (2.2931299976177414e-05, tensor(0.0965)), (2.300942664040237e-05, tensor(0.0963)), (2.3087819481236126e-05, tensor(0.0962)), (2.316647940553919e-05, tensor(0.0964)), (2.3245407323261747e-05, tensor(0.0962)), (2.3324604147454163e-05, tensor(0.0957)), (2.340407079427756e-05, tensor(0.0953)), (2.3483808183014406e-05, tensor(0.0950)), (2.3563817236079158e-05, tensor(0.0946)), (2.3644098879028923e-05, tensor(0.0953)), (2.372465404057418e-05, tensor(0.0951)), (2.380548365258949e-05, tensor(0.0951)), (2.3886588650124336e-05, tensor(0.0951)), (2.396796997141387e-05, tensor(0.0947)), (2.404962855788982e-05, tensor(0.0956)), (2.4131565354191345e-05, tensor(0.0956)), (2.421378130817599e-05, tensor(0.0959)), (2.4296277370930636e-05, tensor(0.0961)), (2.4379054496782512e-05, tensor(0.0962)), (2.4462113643310217e-05, tensor(0.0963)), (2.4545455771354817e-05, tensor(0.0960)), (2.4629081845030943e-05, tensor(0.0965)), (2.471299283173797e-05, tensor(0.0964)), (2.4797189702171167e-05, tensor(0.0961)), (2.488167343033297e-05, tensor(0.0966)), (2.496644499354422e-05, tensor(0.0968)), (2.5051505372455487e-05, tensor(0.0965)), (2.5136855551058395e-05, tensor(0.0966)), (2.5222496516697023e-05, tensor(0.0965)), (2.5308429260079314e-05, tensor(0.0971)), (2.5394654775288545e-05, tensor(0.0973)), (2.5481174059794822e-05, tensor(0.0970)), (2.5567988114466623e-05, tensor(0.0972)), (2.5655097943582367e-05, tensor(0.0975)), (2.574250455484204e-05, tensor(0.0971)), (2.5830208959378855e-05, tensor(0.0971)), (2.5918212171770928e-05, tensor(0.0972)), (2.600651521005305e-05, tensor(0.0974)), (2.609511909572843e-05, tensor(0.0973)), (2.6184024853780538e-05, tensor(0.0976)), (2.6273233512684938e-05, tensor(0.0974)), (2.636274610442121e-05, tensor(0.0977)), (2.6452563664484862e-05, tensor(0.0976)), (2.6542687231899335e-05, tensor(0.0974)), (2.663311784922801e-05, tensor(0.0972)), (2.672385656258626e-05, tensor(0.0973)), (2.6814904421653564e-05, tensor(0.0971)), (2.6906262479685657e-05, tensor(0.0964)), (2.699793179352669e-05, tensor(0.0962)), (2.7089913423621467e-05, tensor(0.0962)), (2.7182208434027733e-05, tensor(0.0962)), (2.727481789242845e-05, tensor(0.0963)), (2.7367742870144164e-05, tensor(0.0970)), (2.7460984442145404e-05, tensor(0.0973)), (2.7554543687065106e-05, tensor(0.0973)), (2.7648421687211093e-05, tensor(0.0969)), (2.7742619528578608e-05, tensor(0.0968)), (2.7837138300862852e-05, tensor(0.0970)), (2.793197909747162e-05, tensor(0.0970)), (2.8027143015537924e-05, tensor(0.0969)), (2.8122631155932693e-05, tensor(0.0971)), (2.8218444623277523e-05, tensor(0.0974)), (2.831458452595743e-05, tensor(0.0974)), (2.8411051976133683e-05, tensor(0.0978)), (2.8507848089756686e-05, tensor(0.0979)), (2.8604973986578865e-05, tensor(0.0978)), (2.870243079016762e-05, tensor(0.0977)), (2.880021962791834e-05, tensor(0.0981)), (2.889834163106744e-05, tensor(0.0977)), (2.8996797934705443e-05, tensor(0.0976)), (2.9095589677790096e-05, tensor(0.0973)), (2.9194718003159588e-05, tensor(0.0974)), (2.9294184057545722e-05, tensor(0.0976)), (2.9393988991587215e-05, tensor(0.0976)), (2.9494133959842987e-05, tensor(0.0975)), (2.959462012080553e-05, tensor(0.0973)), (2.969544863691432e-05, tensor(0.0977)), (2.9796620674569226e-05, tensor(0.0977)), (2.9898137404144036e-05, tensor(0.0976))]
******

*** 2018-12-28 16:03:25,381 - code.resnet_fastai - DEBUG ***
1e-06
******

*** 2018-12-28 16:03:25,432 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2018-12-28 16:03:25,435 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,435 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 16:03:25,444 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,444 - matplotlib.ticker - DEBUG ***
ticklocs [2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 16:03:25,536 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
******

*** 2018-12-28 16:03:25,567 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,567 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 16:03:25,568 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,569 - matplotlib.ticker - DEBUG ***
ticklocs [2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 16:03:25,730 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2018-12-28 16:03:25,733 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,733 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 16:03:25,734 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,735 - matplotlib.ticker - DEBUG ***
ticklocs [2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 16:03:25,801 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,801 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 16:03:25,802 - matplotlib.ticker - DEBUG ***
vmin 8.751789166450485e-07 vmax 3.4748246438981526e-05
******

*** 2018-12-28 16:03:25,803 - matplotlib.ticker - DEBUG ***
ticklocs [2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 16:03:25,870 - code.resnet_fastai - INFO ***
Start model fitting: Stage 2
******

*** 2018-12-28 16:03:25,870 - code.resnet_fastai - DEBUG ***
Use best LR: 7e-07
******

2         0.097566                
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
epoch     train_loss  valid_loss  fbeta   
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/atlas/code/resnet_fastai.py", line 485, in <module>
    learn = fit_model(learn, stage=2, fold=index)
  File "/home/ubuntu/atlas/code/resnet_fastai.py", line 421, in fit_model
    learn.fit_one_cycle(cyc_len, max_lr)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/train.py", line 21, in fit_one_cycle
    learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/basic_train.py", line 166, in fit
    callbacks=self.callbacks+callbacks)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/basic_train.py", line 94, in fit
    raise e
  File "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/basic_train.py", line 84, in fit
    loss = loss_batch(model, xb, yb, loss_func, opt, cb_handler)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/fastai/basic_train.py", line 22, in loss_batch
    loss = loss_func(out, *yb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 1662, in binary_cross_entropy_with_logits
    return loss.mean()
  File "/home/ubuntu/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 227, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 12043) is killed by signal: Terminated. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
