*** 2018-12-28 11:42:09,992 - code.resnet_fastai - DEBUG ***
Start a new training task
******

*** 2018-12-28 11:42:09,992 - code.resnet_fastai - INFO ***
Device ID: 0
Image size: 512
Network architecture: resnet
Loss function: bce
Sampler: random
Encoder depth: 50
Dropout: 0.5
Threshold: 0.1
Stage 1 #epoch: 3
Stage 2 #epoch: 25
Learning rate #1: 0
Batch size: 32
Dataset: official
Dataset directory: data/official
Output directory: output
******

*** 2018-12-28 11:42:09,992 - code.resnet_fastai - INFO ***
Offical stats: ([0.07986162506177984, 0.05217604947235713, 0.054227752481757215, 0.08201468927464939], [0.1403192215484648, 0.1041239635111223, 0.1532386688507187, 0.14099509309392533])
******

*** 2018-12-28 11:42:10,052 - code.resnet_fastai - DEBUG ***
# Test ids: 11702
******

*** 2018-12-28 11:42:10,821 - code.resnet_fastai - DEBUG ***
Start of fold 0
******

*** 2018-12-28 11:42:10,821 - code.resnet_fastai - DEBUG ***
Size of valid set: 6209
******

*** 2018-12-28 11:42:11,013 - code.resnet_fastai - DEBUG ***
LabelList
y: MultiCategoryList (24863 items)
[MultiCategory 16;0, MultiCategory 1, MultiCategory 18, MultiCategory 0, MultiCategory 25;2]...
Path: data/official
x: ImageItemList (24863 items)
[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...
Path: data/official
******

*** 2018-12-28 11:42:11,160 - code.resnet_fastai - DEBUG ***
LabelList
y: MultiCategoryList (6209 items)
[MultiCategory 7;1;2;0, MultiCategory 5, MultiCategory 21, MultiCategory 0, MultiCategory 25;4]...
Path: data/official
x: ImageItemList (6209 items)
[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...
Path: data/official
******

*** 2018-12-28 11:42:13,391 - code.resnet_fastai - DEBUG ***
Databunch created
******

*** 2018-12-28 11:42:13,391 - code.resnet_fastai - INFO ***
Initialising model.
******

*** 2018-12-28 11:42:17,769 - code.resnet_fastai - INFO ***
Complete initialising model.
******

*** 2018-12-28 11:42:17,769 - code.resnet_fastai - INFO ***
No pretrained model.
******

*** 2018-12-28 11:42:17,770 - code.resnet_fastai - DEBUG ***
Start finding LR
******

epoch     train_loss  valid_loss  fbeta   
1         0.159679                
*** 2018-12-28 11:50:47,327 - code.resnet_fastai - DEBUG ***
[(0.01, tensor(0.8629)), (0.010013872557113347, tensor(0.8612)), (0.010027764359010777, tensor(0.8384)), (0.010041675432389732, tensor(0.8105)), (0.010055605803984681, tensor(0.7821)), (0.01006955550056719, tensor(0.7537)), (0.010083524548945951, tensor(0.7284)), (0.010097512975966859, tensor(0.7020)), (0.010111520808513042, tensor(0.6668)), (0.01012554807350493, tensor(0.6362)), (0.010139594797900291, tensor(0.6019)), (0.010153661008694297, tensor(0.5720)), (0.010167746732919562, tensor(0.5439)), (0.010181851997646207, tensor(0.5174)), (0.010195976829981905, tensor(0.4925)), (0.010210121257071934, tensor(0.4719)), (0.010224285306099224, tensor(0.4529)), (0.010238469004284424, tensor(0.4360)), (0.010252672378885939, tensor(0.4219)), (0.01026689545719999, tensor(0.4096)), (0.010281138266560666, tensor(0.3978)), (0.010295400834339972, tensor(0.3874)), (0.010309683187947886, tensor(0.3777)), (0.01032398535483242, tensor(0.3672)), (0.010338307362479645, tensor(0.3587)), (0.010352649238413777, tensor(0.3508)), (0.010367011010197207, tensor(0.3436)), (0.010381392705430573, tensor(0.3368)), (0.010395794351752788, tensor(0.3304)), (0.010410215976841115, tensor(0.3236)), (0.010424657608411214, tensor(0.3175)), (0.01043911927421719, tensor(0.3124)), (0.010453601002051649, tensor(0.3080)), (0.010468102819745757, tensor(0.3022)), (0.010482624755169288, tensor(0.2986)), (0.010497166836230674, tensor(0.2931)), (0.010511729090877065, tensor(0.2887)), (0.010526311547094385, tensor(0.2856)), (0.01054091423290738, tensor(0.2818)), (0.010555537176379668, tensor(0.2786)), (0.010570180405613803, tensor(0.2751)), (0.010584843948751328, tensor(0.2713)), (0.010599527833972817, tensor(0.2679)), (0.010614232089497947, tensor(0.2643)), (0.010628956743585532, tensor(0.2609)), (0.010643701824533598, tensor(0.2585)), (0.010658467360679425, tensor(0.2558)), (0.010673253380399601, tensor(0.2531)), (0.01068805991211008, tensor(0.2513)), (0.01070288698426624, tensor(0.2495)), (0.010717734625362931, tensor(0.2475)), (0.010732602863934536, tensor(0.2443)), (0.010747491728555013, tensor(0.2425)), (0.010762401247837972, tensor(0.2404)), (0.01077733145043671, tensor(0.2383)), (0.010792282365044273, tensor(0.2364)), (0.010807254020393516, tensor(0.2341)), (0.01082224644525715, tensor(0.2323)), (0.0108372596684478, tensor(0.2300)), (0.010852293718818072, tensor(0.2296)), (0.01086734862526058, tensor(0.2282)), (0.010882424416708036, tensor(0.2270)), (0.010897521122133283, tensor(0.2265)), (0.01091263877054935, tensor(0.2247)), (0.010927777391009526, tensor(0.2231)), (0.010942937012607394, tensor(0.2216)), (0.010958117664476909, tensor(0.2202)), (0.01097331937579243, tensor(0.2186)), (0.010988542175768796, tensor(0.2175)), (0.011003786093661372, tensor(0.2157)), (0.011019051158766106, tensor(0.2146)), (0.011034337400419592, tensor(0.2138)), (0.011049644847999116, tensor(0.2129)), (0.011064973530922721, tensor(0.2123)), (0.011080323478649259, tensor(0.2117)), (0.01109569472067845, tensor(0.2102)), (0.011111087286550936, tensor(0.2093)), (0.01112650120584834, tensor(0.2082)), (0.011141936508193324, tensor(0.2078)), (0.01115739322324964, tensor(0.2068)), (0.011172871380722201, tensor(0.2058)), (0.011188371010357112, tensor(0.2052)), (0.01120389214194176, tensor(0.2042)), (0.011219434805304844, tensor(0.2034)), (0.011234999030316451, tensor(0.2022)), (0.011250584846888094, tensor(0.2016)), (0.011266192284972793, tensor(0.2002)), (0.011281821374565116, tensor(0.1998)), (0.011297472145701235, tensor(0.1993)), (0.011313144628459003, tensor(0.1988)), (0.011328838852957986, tensor(0.1985)), (0.01134455484935954, tensor(0.1971)), (0.011360292647866864, tensor(0.1963)), (0.01137605227872505, tensor(0.1949)), (0.01139183377222115, tensor(0.1946)), (0.011407637158684236, tensor(0.1946)), (0.011423462468485452, tensor(0.1937)), (0.011439309732038074, tensor(0.1932)), (0.01145517897979757, tensor(0.1922)), (0.011471070242261653, tensor(0.1912)), (0.011486983549970351, tensor(0.1912)), (0.011502918933506053, tensor(0.1909)), (0.011518876423493576, tensor(0.1902)), (0.011534856050600225, tensor(0.1899)), (0.011550857845535842, tensor(0.1893)), (0.011566881839052873, tensor(0.1885)), (0.011582928061946432, tensor(0.1878)), (0.011598996545054346, tensor(0.1874)), (0.011615087319257221, tensor(0.1866)), (0.011631200415478509, tensor(0.1866)), (0.011647335864684558, tensor(0.1862)), (0.011663493697884672, tensor(0.1859)), (0.01167967394613118, tensor(0.1851)), (0.011695876640519473, tensor(0.1846)), (0.011712101812188099, tensor(0.1838)), (0.011728349492318789, tensor(0.1835)), (0.011744619712136535, tensor(0.1828)), (0.011760912502909648, tensor(0.1823)), (0.011777227895949816, tensor(0.1821)), (0.01179356592261216, tensor(0.1815)), (0.011809926614295304, tensor(0.1811)), (0.011826310002441427, tensor(0.1811)), (0.011842716118536328, tensor(0.1809)), (0.011859144994109479, tensor(0.1809)), (0.011875596660734103, tensor(0.1802)), (0.01189207115002721, tensor(0.1797)), (0.011908568493649683, tensor(0.1795)), (0.011925088723306316, tensor(0.1791)), (0.011941631870745895, tensor(0.1782)), (0.011958197967761241, tensor(0.1769)), (0.011974787046189286, tensor(0.1766)), (0.011991399137911127, tensor(0.1761)), (0.012008034274852086, tensor(0.1759)), (0.012024692488981777, tensor(0.1754)), (0.012041373812314158, tensor(0.1748)), (0.012058078276907604, tensor(0.1744)), (0.012074805914864964, tensor(0.1740)), (0.012091556758333614, tensor(0.1741)), (0.012108330839505538, tensor(0.1733)), (0.012125128190617371, tensor(0.1730)), (0.01214194884395047, tensor(0.1726)), (0.012158792831830972, tensor(0.1720)), (0.012175660186629862, tensor(0.1711)), (0.012192550940763032, tensor(0.1710)), (0.012209465126691344, tensor(0.1703)), (0.012226402776920685, tensor(0.1703)), (0.012243363924002045, tensor(0.1697)), (0.012260348600531563, tensor(0.1689)), (0.012277356839150605, tensor(0.1683)), (0.012294388672545807, tensor(0.1678)), (0.012311444133449163, tensor(0.1677)), (0.012328523254638067, tensor(0.1675)), (0.012345626068935384, tensor(0.1674)), (0.012362752609209516, tensor(0.1670)), (0.012379902908374457, tensor(0.1663)), (0.012397076999389868, tensor(0.1665)), (0.012414274915261123, tensor(0.1662)), (0.012431496689039397, tensor(0.1652)), (0.012448742353821703, tensor(0.1650)), (0.012466011942750974, tensor(0.1645)), (0.01248330548901612, tensor(0.1642)), (0.012500623025852092, tensor(0.1639)), (0.012517964586539945, tensor(0.1635)), (0.012535330204406905, tensor(0.1631)), (0.012552719912826433, tensor(0.1629)), (0.012570133745218284, tensor(0.1621)), (0.012587571735048578, tensor(0.1620)), (0.012605033915829856, tensor(0.1619)), (0.012622520321121156, tensor(0.1618)), (0.012640030984528068, tensor(0.1612)), (0.012657565939702799, tensor(0.1608)), (0.012675125220344245, tensor(0.1611)), (0.012692708860198049, tensor(0.1608)), (0.012710316893056664, tensor(0.1608)), (0.01272794935275943, tensor(0.1602)), (0.012745606273192623, tensor(0.1599)), (0.01276328768828953, tensor(0.1602)), (0.012780993632030516, tensor(0.1601)), (0.012798724138443079, tensor(0.1599)), (0.01281647924160193, tensor(0.1598)), (0.012834258975629042, tensor(0.1595)), (0.01285206337469373, tensor(0.1594)), (0.012869892473012708, tensor(0.1594)), (0.012887746304850156, tensor(0.1598)), (0.01290562490451779, tensor(0.1602)), (0.012923528306374924, tensor(0.1596)), (0.012941456544828533, tensor(0.1592)), (0.012959409654333336, tensor(0.1591)), (0.012977387669391834, tensor(0.1589)), (0.0129953906245544, tensor(0.1589)), (0.013013418554419336, tensor(0.1595)), (0.013031471493632941, tensor(0.1596)), (0.013049549476889577, tensor(0.1596)), (0.013067652538931733, tensor(0.1600)), (0.013085780714550101, tensor(0.1595)), (0.013103934038583634, tensor(0.1593)), (0.013122112545919608, tensor(0.1591)), (0.01314031627149371, tensor(0.1584)), (0.013158545250290081, tensor(0.1579)), (0.0131767995173414, tensor(0.1576)), (0.013195079107728942, tensor(0.1581)), (0.013213384056582652, tensor(0.1577)), (0.013231714399081202, tensor(0.1573)), (0.013250070170452075, tensor(0.1570)), (0.013268451405971618, tensor(0.1570)), (0.013286858140965117, tensor(0.1569)), (0.01330529041080686, tensor(0.1570)), (0.013323748250920218, tensor(0.1563)), (0.01334223169677769, tensor(0.1557)), (0.013360740783900994, tensor(0.1555)), (0.01337927554786112, tensor(0.1555)), (0.013397836024278409, tensor(0.1555)), (0.013416422248822613, tensor(0.1555)), (0.013435034257212968, tensor(0.1553)), (0.013453672085218263, tensor(0.1551)), (0.013472335768656902, tensor(0.1545)), (0.013491025343396988, tensor(0.1542)), (0.013509740845356374, tensor(0.1538)), (0.013528482310502745, tensor(0.1534)), (0.013547249774853679, tensor(0.1535)), (0.013566043274476719, tensor(0.1532)), (0.013584862845489447, tensor(0.1533)), (0.01360370852405955, tensor(0.1537)), (0.013622580346404883, tensor(0.1539)), (0.013641478348793546, tensor(0.1539)), (0.013660402567543955, tensor(0.1540)), (0.013679353039024908, tensor(0.1539)), (0.013698329799655658, tensor(0.1531)), (0.013717332885905976, tensor(0.1533)), (0.013736362334296225, tensor(0.1534)), (0.013755418181397439, tensor(0.1537)), (0.013774500463831376, tensor(0.1533)), (0.013793609218270607, tensor(0.1528)), (0.013812744481438568, tensor(0.1525)), (0.013831906290109648, tensor(0.1528)), (0.013851094681109247, tensor(0.1529)), (0.01387030969131385, tensor(0.1531)), (0.013889551357651105, tensor(0.1531)), (0.01390881971709988, tensor(0.1530)), (0.01392811480669035, tensor(0.1528)), (0.013947436663504054, tensor(0.1529)), (0.013966785324673976, tensor(0.1522)), (0.013986160827384615, tensor(0.1522)), (0.014005563208872047, tensor(0.1522)), (0.01402499250642401, tensor(0.1521)), (0.014044448757379972, tensor(0.1521)), (0.014063931999131193, tensor(0.1524)), (0.014083442269120807, tensor(0.1524)), (0.014102979604843895, tensor(0.1523)), (0.01412254404384755, tensor(0.1521)), (0.014142135623730952, tensor(0.1522)), (0.014161754382145439, tensor(0.1517)), (0.014181400356794587, tensor(0.1510)), (0.014201073585434272, tensor(0.1506)), (0.014220774105872747, tensor(0.1503)), (0.014240501955970717, tensor(0.1509)), (0.014260257173641409, tensor(0.1508)), (0.01428003979685064, tensor(0.1512)), (0.014299849863616907, tensor(0.1516)), (0.014319687412011436, tensor(0.1514)), (0.014339552480158273, tensor(0.1510)), (0.014359445106234355, tensor(0.1506)), (0.014379365328469574, tensor(0.1506)), (0.014399313185146858, tensor(0.1504)), (0.014419288714602248, tensor(0.1504)), (0.014439291955224962, tensor(0.1506)), (0.014459322945457473, tensor(0.1507)), (0.01447938172379559, tensor(0.1504)), (0.014499468328788519, tensor(0.1503)), (0.014519582799038944, tensor(0.1509)), (0.014539725173203106, tensor(0.1516)), (0.014559895489990867, tensor(0.1520)), (0.014580093788165792, tensor(0.1517)), (0.014600320106545217, tensor(0.1516)), (0.014620574484000334, tensor(0.1514)), (0.014640856959456255, tensor(0.1510)), (0.014661167571892094, tensor(0.1507)), (0.014681506360341032, tensor(0.1508)), (0.01470187336389041, tensor(0.1510)), (0.014722268621681784, tensor(0.1509)), (0.014742692172911012, tensor(0.1506)), (0.01476314405682833, tensor(0.1504)), (0.014783624312738419, tensor(0.1502)), (0.014804132980000488, tensor(0.1502)), (0.01482467009802835, tensor(0.1500)), (0.014845235706290491, tensor(0.1494)), (0.01486582984431015, tensor(0.1488)), (0.014886452551665397, tensor(0.1487)), (0.014907103867989204, tensor(0.1484)), (0.01492778383296953, tensor(0.1485)), (0.014948492486349383, tensor(0.1482)), (0.014969229867926915, tensor(0.1483)), (0.014989996017555475, tensor(0.1483)), (0.015010790975143712, tensor(0.1482)), (0.015031614780655627, tensor(0.1481)), (0.01505246747411067, tensor(0.1486)), (0.01507334909558381, tensor(0.1485)), (0.015094259685205598, tensor(0.1486)), (0.015115199283162267, tensor(0.1482)), (0.015136167929695792, tensor(0.1484)), (0.01515716566510398, tensor(0.1482)), (0.01517819252974054, tensor(0.1479)), (0.015199248564015158, tensor(0.1476)), (0.01522033380839358, tensor(0.1479)), (0.015241448303397694, tensor(0.1478)), (0.015262592089605592, tensor(0.1484)), (0.015283765207651666, tensor(0.1483)), (0.015304967698226677, tensor(0.1479)), (0.015326199602077832, tensor(0.1478)), (0.015347460960008868, tensor(0.1473)), (0.015368751812880124, tensor(0.1470)), (0.015390072201608625, tensor(0.1468)), (0.015411422167168157, tensor(0.1468)), (0.015432801750589349, tensor(0.1477)), (0.015454210992959747, tensor(0.1472)), (0.015475649935423899, tensor(0.1473)), (0.015497118619183431, tensor(0.1470)), (0.015518617085497122, tensor(0.1471)), (0.01554014537568099, tensor(0.1468)), (0.015561703531108374, tensor(0.1468)), (0.015583291593209998, tensor(0.1463)), (0.01560490960347407, tensor(0.1463)), (0.015626557603446348, tensor(0.1461)), (0.015648235634730227, tensor(0.1467)), (0.015669943738986815, tensor(0.1467)), (0.015691681957935015, tensor(0.1466)), (0.015713450333351607, tensor(0.1462)), (0.01573524890707132, tensor(0.1462)), (0.015757077720986924, tensor(0.1459)), (0.015778936817049304, tensor(0.1453)), (0.015800826237267546, tensor(0.1449)), (0.015822746023709, tensor(0.1445)), (0.015844696218499384, tensor(0.1446)), (0.015866676863822857, tensor(0.1445)), (0.015888688001922096, tensor(0.1439)), (0.015910729675098375, tensor(0.1435)), (0.015932801925711657, tensor(0.1438)), (0.015954904796180662, tensor(0.1440)), (0.01597703832898296, tensor(0.1444)), (0.01599920256665505, tensor(0.1446)), (0.01602139755179244, tensor(0.1447)), (0.016043623327049727, tensor(0.1440)), (0.01606587993514068, tensor(0.1436)), (0.016088167418838315, tensor(0.1437)), (0.016110485820975004, tensor(0.1433)), (0.016132835184442525, tensor(0.1429)), (0.01615521555219216, tensor(0.1427)), (0.016177626967234782, tensor(0.1426)), (0.016200069472640917, tensor(0.1431)), (0.016222543111540855, tensor(0.1428)), (0.01624504792712471, tensor(0.1426)), (0.016267583962642516, tensor(0.1432)), (0.016290151261404307, tensor(0.1432)), (0.016312749866780194, tensor(0.1436)), (0.016335379822200454, tensor(0.1435)), (0.01635804117115562, tensor(0.1435)), (0.016380733957196553, tensor(0.1432)), (0.016403458223934526, tensor(0.1433)), (0.016426214015041317, tensor(0.1435)), (0.016449001374249286, tensor(0.1434)), (0.01647182034535146, tensor(0.1433)), (0.016494670972201628, tensor(0.1433)), (0.016517553298714398, tensor(0.1428)), (0.016540467368865313, tensor(0.1439)), (0.01656341322669091, tensor(0.1430)), (0.016586390916288832, tensor(0.1428)), (0.01660940048181788, tensor(0.1421)), (0.016632441967498128, tensor(0.1420)), (0.01665551541761098, tensor(0.1422)), (0.01667862087649928, tensor(0.1422)), (0.016701758388567387, tensor(0.1427)), (0.016724927998281257, tensor(0.1424)), (0.016748129750168532, tensor(0.1430)), (0.016771363688818625, tensor(0.1427)), (0.016794629858882807, tensor(0.1427)), (0.01681792830507429, tensor(0.1428)), (0.01684125907216832, tensor(0.1424)), (0.01686462220500225, tensor(0.1424)), (0.01688801774847564, tensor(0.1427)), (0.01691144574755033, tensor(0.1428)), (0.016934906247250543, tensor(0.1424)), (0.016958399292662955, tensor(0.1424)), (0.016981924928936794, tensor(0.1422)), (0.01700548320128392, tensor(0.1427)), (0.0170290741549789, tensor(0.1428)), (0.017052697835359135, tensor(0.1424)), (0.017076354287824898, tensor(0.1424)), (0.017100043557839454, tensor(0.1426)), (0.01712376569092914, tensor(0.1429)), (0.017147520732683434, tensor(0.1430)), (0.017171308728755077, tensor(0.1432)), (0.01719512972486013, tensor(0.1423)), (0.01721898376677808, tensor(0.1424)), (0.01724287090035192, tensor(0.1422)), (0.017266791171488237, tensor(0.1422)), (0.017290744626157303, tensor(0.1421)), (0.01731473131039317, tensor(0.1424)), (0.017338751270293735, tensor(0.1425)), (0.01736280455202086, tensor(0.1431)), (0.017386891201800436, tensor(0.1432)), (0.017411011265922482, tensor(0.1437)), (0.017435164790741246, tensor(0.1446)), (0.01745935182267526, tensor(0.1444)), (0.017483572408207464, tensor(0.1442)), (0.017507826593885282, tensor(0.1444)), (0.017532114426320702, tensor(0.1440)), (0.017556435952190388, tensor(0.1438)), (0.01758079121823574, tensor(0.1439)), (0.017605180271263017, tensor(0.1441)), (0.017629603158143402, tensor(0.1444)), (0.017654059925813096, tensor(0.1441)), (0.017678550621273423, tensor(0.1438)), (0.017703075291590903, tensor(0.1438)), (0.017727633983897345, tensor(0.1441)), (0.017752226745389958, tensor(0.1447)), (0.017776853623331403, tensor(0.1448)), (0.017801514665049926, tensor(0.1446)), (0.017826209917939425, tensor(0.1453)), (0.017850939429459534, tensor(0.1452)), (0.01787570324713574, tensor(0.1448)), (0.01790050141855945, tensor(0.1447)), (0.017925333991388098, tensor(0.1445)), (0.01795020101334523, tensor(0.1447)), (0.017975102532220594, tensor(0.1451)), (0.01800003859587024, tensor(0.1457)), (0.018025009252216603, tensor(0.1452)), (0.0180500145492486, tensor(0.1450)), (0.018075054535021718, tensor(0.1453)), (0.01810012925765811, tensor(0.1458)), (0.018125238765346687, tensor(0.1458)), (0.018150383106343218, tensor(0.1457)), (0.018175562328970402, tensor(0.1457)), (0.018200776481617983, tensor(0.1462)), (0.018226025612742832, tensor(0.1458)), (0.01825130977086904, tensor(0.1457)), (0.01827662900458801, tensor(0.1460)), (0.018301983362558567, tensor(0.1457)), (0.018327372893507027, tensor(0.1459)), (0.0183527976462273, tensor(0.1460)), (0.018378257669580997, tensor(0.1463)), (0.0184037530124975, tensor(0.1464)), (0.01842928372397408, tensor(0.1465)), (0.018454849853075966, tensor(0.1462)), (0.01848045144893647, tensor(0.1463)), (0.018506088560757045, tensor(0.1464)), (0.018531761237807417, tensor(0.1463)), (0.018557469529425656, tensor(0.1462)), (0.018583213485018266, tensor(0.1466)), (0.018608993154060307, tensor(0.1464)), (0.018634808586095463, tensor(0.1465)), (0.01866065983073615, tensor(0.1467)), (0.01868654693766361, tensor(0.1473)), (0.018712469956628, tensor(0.1475)), (0.01873842893744851, tensor(0.1475)), (0.018764423930013423, tensor(0.1474)), (0.018790454984280235, tensor(0.1471)), (0.018816522150275756, tensor(0.1466)), (0.018842625478096175, tensor(0.1462)), (0.018868765017907203, tensor(0.1465)), (0.018894940819944125, tensor(0.1461)), (0.01892115293451192, tensor(0.1463)), (0.018947401411985355, tensor(0.1463)), (0.01897368630280908, tensor(0.1459)), (0.019000007657497722, tensor(0.1453)), (0.019026365526635985, tensor(0.1452)), (0.01905275996087875, tensor(0.1449)), (0.019079191010951166, tensor(0.1445)), (0.019105658727648748, tensor(0.1441)), (0.01913216316183749, tensor(0.1446)), (0.01915870436445393, tensor(0.1443)), (0.019185282386505288, tensor(0.1449)), (0.019211897279069533, tensor(0.1451)), (0.019238549093295493, tensor(0.1451)), (0.019265237880402956, tensor(0.1449)), (0.019291963691682765, tensor(0.1446)), (0.01931872657849691, tensor(0.1449)), (0.01934552659227864, tensor(0.1448)), (0.019372363784532554, tensor(0.1446)), (0.019399238206834698, tensor(0.1443)), (0.019426149910832666, tensor(0.1443)), (0.01945309894824571, tensor(0.1441)), (0.01948008537086482, tensor(0.1442)), (0.019507109230552835, tensor(0.1441)), (0.019534170579244548, tensor(0.1437)), (0.019561269468946787, tensor(0.1438)), (0.01958840595173854, tensor(0.1436)), (0.019615580079771027, tensor(0.1435)), (0.019642791905267826, tensor(0.1435)), (0.019670041480524966, tensor(0.1434)), (0.019697328857911013, tensor(0.1435)), (0.019724654089867184, tensor(0.1434)), (0.019752017228907452, tensor(0.1435)), (0.01977941832761863, tensor(0.1433)), (0.019806857438660494, tensor(0.1434)), (0.019834334614765862, tensor(0.1435)), (0.01986184990874072, tensor(0.1430)), (0.019889403373464287, tensor(0.1432)), (0.019916995061889164, tensor(0.1435)), (0.01994462502704139, tensor(0.1438)), (0.01997229332202058, tensor(0.1437)), (0.02, tensor(0.1440)), (0.020027745114226694, tensor(0.1439)), (0.020055528718021555, tensor(0.1439)), (0.020083350864779463, tensor(0.1440)), (0.020111211607969363, tensor(0.1438)), (0.02013911100113438, tensor(0.1437)), (0.020167049097891902, tensor(0.1437)), (0.020195025951933718, tensor(0.1436)), (0.020223041617026084, tensor(0.1440)), (0.02025109614700986, tensor(0.1439)), (0.020279189595800582, tensor(0.1442)), (0.020307322017388593, tensor(0.1435)), (0.020335493465839124, tensor(0.1434)), (0.020363703995292415, tensor(0.1440)), (0.02039195365996381, tensor(0.1444)), (0.020420242514143868, tensor(0.1448)), (0.020448570612198447, tensor(0.1445)), (0.020476938008568847, tensor(0.1445)), (0.020505344757771878, tensor(0.1443)), (0.02053379091439998, tensor(0.1447)), (0.020562276533121333, tensor(0.1451)), (0.020590801668679944, tensor(0.1449)), (0.02061936637589578, tensor(0.1448)), (0.02064797070966484, tensor(0.1455)), (0.02067661472495929, tensor(0.1453)), (0.020705298476827554, tensor(0.1454)), (0.02073402202039442, tensor(0.1453)), (0.020762785410861146, tensor(0.1451)), (0.020791588703505576, tensor(0.1454)), (0.02082043195368223, tensor(0.1456)), (0.02084931521682243, tensor(0.1458)), (0.02087823854843438, tensor(0.1463)), (0.020907202004103297, tensor(0.1461)), (0.020936205639491518, tensor(0.1458)), (0.020965249510338575, tensor(0.1449)), (0.020994333672461347, tensor(0.1447)), (0.021023458181754134, tensor(0.1450)), (0.021052623094188774, tensor(0.1448)), (0.02108182846581476, tensor(0.1448)), (0.021111074352759336, tensor(0.1452)), (0.02114036081122761, tensor(0.1449)), (0.021169687897502655, tensor(0.1451)), (0.021199055667945638, tensor(0.1448)), (0.021228464178995893, tensor(0.1448)), (0.021257913487171067, tensor(0.1449)), (0.0212874036490672, tensor(0.1450)), (0.02131693472135885, tensor(0.1448)), (0.021346506760799203, tensor(0.1452)), (0.021376119824220163, tensor(0.1454)), (0.02140577396853248, tensor(0.1460)), (0.021435469250725862, tensor(0.1463)), (0.02146520572786907, tensor(0.1465)), (0.02149498345711003, tensor(0.1470)), (0.021524802495675944, tensor(0.1467)), (0.02155466290087342, tensor(0.1471)), (0.021584564730088546, tensor(0.1471)), (0.02161450804078703, tensor(0.1471)), (0.0216444928905143, tensor(0.1470)), (0.021674519336895605, tensor(0.1471)), (0.021704587437636143, tensor(0.1470)), (0.021734697250521164, tensor(0.1474)), (0.02176484883341608, tensor(0.1478)), (0.021795042244266566, tensor(0.1476)), (0.0218252775410987, tensor(0.1478)), (0.021855554782019046, tensor(0.1480)), (0.021885874025214788, tensor(0.1478)), (0.021916235328953815, tensor(0.1483)), (0.02194663875158486, tensor(0.1487)), (0.02197708435153759, tensor(0.1483)), (0.022007572187322744, tensor(0.1483)), (0.022038102317532213, tensor(0.1483)), (0.022068674800839183, tensor(0.1486)), (0.022099289695998232, tensor(0.1482)), (0.022129947061845442, tensor(0.1475)), (0.022160646957298517, tensor(0.1472)), (0.022191389441356898, tensor(0.1471)), (0.022222174573101872, tensor(0.1475)), (0.02225300241169668, tensor(0.1475)), (0.022283873016386645, tensor(0.1479)), (0.02231478644649928, tensor(0.1478)), (0.022345742761444395, tensor(0.1476)), (0.022376742020714224, tensor(0.1477)), (0.02240778428388352, tensor(0.1479)), (0.022438869610609688, tensor(0.1485)), (0.022469998060632896, tensor(0.1486)), (0.022501169693776187, tensor(0.1487)), (0.022532384569945586, tensor(0.1486)), (0.022563642749130225, tensor(0.1494)), (0.02259494429140247, tensor(0.1493)), (0.022626289256918005, tensor(0.1490)), (0.022657677705915973, tensor(0.1487)), (0.02268910969871908, tensor(0.1489)), (0.022720585295733727, tensor(0.1493)), (0.02275210455745009, tensor(0.1493)), (0.0227836675444423, tensor(0.1493)), (0.022815274317368472, tensor(0.1498)), (0.022846924936970905, tensor(0.1496)), (0.02287861946407615, tensor(0.1501)), (0.02291035795959514, tensor(0.1505)), (0.022942140484523303, tensor(0.1507)), (0.0229739670999407, tensor(0.1509)), (0.023005837867012106, tensor(0.1513)), (0.023037752846987152, tensor(0.1512)), (0.02306971210120045, tensor(0.1515)), (0.02310171569107168, tensor(0.1513)), (0.023133763678105747, tensor(0.1513)), (0.023165856123892863, tensor(0.1512)), (0.023197993090108688, tensor(0.1515)), (0.023230174638514442, tensor(0.1514)), (0.023262400830957018, tensor(0.1512)), (0.023294671729369117, tensor(0.1509)), (0.023326987395769345, tensor(0.1507)), (0.023359347892262353, tensor(0.1503)), (0.023391753281038947, tensor(0.1505)), (0.023424203624376198, tensor(0.1506)), (0.023456698984637578, tensor(0.1513)), (0.02348923942427307, tensor(0.1513)), (0.023521825005819296, tensor(0.1513)), (0.02355445579189963, tensor(0.1505)), (0.02358713184522432, tensor(0.1505)), (0.023619853228590608, tensor(0.1507)), (0.023652620004882854, tensor(0.1507)), (0.023685432237072656, tensor(0.1503)), (0.023718289988218958, tensor(0.1499)), (0.023751193321468207, tensor(0.1499)), (0.02378414230005442, tensor(0.1507)), (0.023817136987299366, tensor(0.1509)), (0.023850177446612632, tensor(0.1513)), (0.02388326374149179, tensor(0.1518)), (0.023916395935522482, tensor(0.1522)), (0.02394957409237857, tensor(0.1524)), (0.023982798275822254, tensor(0.1531)), (0.024016068549704173, tensor(0.1536)), (0.024049384977963554, tensor(0.1539)), (0.024082747624628316, tensor(0.1543)), (0.02411615655381521, tensor(0.1540)), (0.02414961182972993, tensor(0.1539)), (0.02418311351666723, tensor(0.1542)), (0.024216661679011077, tensor(0.1542)), (0.024250256381234743, tensor(0.1544)), (0.02428389768790094, tensor(0.1545)), (0.024317585663661944, tensor(0.1548)), (0.024351320373259724, tensor(0.1545)), (0.024385101881526063, tensor(0.1549)), (0.024418930253382688, tensor(0.1549)), (0.024452805553841373, tensor(0.1548)), (0.02448672784800409, tensor(0.1550)), (0.024520697201063126, tensor(0.1553)), (0.02455471367830121, tensor(0.1553)), (0.024588777345091618, tensor(0.1550)), (0.024622888266898325, tensor(0.1545)), (0.024657046509276134, tensor(0.1545)), (0.02469125213787077, tensor(0.1546)), (0.02472550521841903, tensor(0.1543)), (0.024759805816748914, tensor(0.1543)), (0.024794153998779735, tensor(0.1542)), (0.024828549830522247, tensor(0.1543)), (0.024862993378078794, tensor(0.1540)), (0.024897484707643407, tensor(0.1540)), (0.024932023885501947, tensor(0.1543)), (0.02496661097803224, tensor(0.1543)), (0.025001246051704184, tensor(0.1542)), (0.02503592917307989, tensor(0.1548)), (0.02507066040881381, tensor(0.1544)), (0.025105439825652866, tensor(0.1545)), (0.025140267490436567, tensor(0.1546)), (0.025175143470097156, tensor(0.1548)), (0.025210067831659716, tensor(0.1545)), (0.025245040642242315, tensor(0.1543)), (0.025280061969056137, tensor(0.1542)), (0.025315131879405598, tensor(0.1542)), (0.02535025044068849, tensor(0.1541)), (0.0253854177203961, tensor(0.1540)), (0.025420633786113332, tensor(0.1543)), (0.02545589870551886, tensor(0.1544)), (0.025491212546385245, tensor(0.1542)), (0.025526575376579062, tensor(0.1541)), (0.02556198726406103, tensor(0.1542)), (0.02559744827688616, tensor(0.1542)), (0.02563295848320386, tensor(0.1543)), (0.025668517951258085, tensor(0.1538)), (0.02570412674938746, tensor(0.1531)), (0.025739784946025416, tensor(0.1525)), (0.02577549260970031, tensor(0.1527)), (0.02581124980903558, tensor(0.1525)), (0.025847056612749848, tensor(0.1524)), (0.02588291308965707, tensor(0.1526)), (0.02591881930866667, tensor(0.1530)), (0.025954775338783667, tensor(0.1529)), (0.0259907812491088, tensor(0.1528)), (0.026026837108838668, tensor(0.1527)), (0.026062942987265882, tensor(0.1523)), (0.02609909895377915, tensor(0.1521)), (0.026135305077863467, tensor(0.1516)), (0.026171561429100203, tensor(0.1517)), (0.026207868077167264, tensor(0.1523)), (0.026244225091839216, tensor(0.1521)), (0.026280632542987417, tensor(0.1513)), (0.026317090500580162, tensor(0.1514)), (0.0263535990346828, tensor(0.1512)), (0.026390158215457885, tensor(0.1517)), (0.0264267681131653, tensor(0.1512)), (0.0264634287981624, tensor(0.1514)), (0.026500140340904147, tensor(0.1515)), (0.026536902811943232, tensor(0.1519)), (0.02657371628193023, tensor(0.1525)), (0.02661058082161372, tensor(0.1528)), (0.026647496501840437, tensor(0.1529)), (0.026684463393555378, tensor(0.1528)), (0.026721481567801988, tensor(0.1530)), (0.02675855109572224, tensor(0.1527)), (0.026795672048556818, tensor(0.1525)), (0.026832844497645225, tensor(0.1526)), (0.026870068514425936, tensor(0.1533)), (0.026907344170436522, tensor(0.1532)), (0.026944671537313804, tensor(0.1532)), (0.026982050686793976, tensor(0.1540)), (0.02701948169071275, tensor(0.1536)), (0.027056964621005486, tensor(0.1539)), (0.027094499549707357, tensor(0.1538)), (0.027132086548953438, tensor(0.1541)), (0.027169725690978894, tensor(0.1544)), (0.0272074170481191, tensor(0.1541)), (0.027245160692809762, tensor(0.1540)), (0.027282956697587093, tensor(0.1536)), (0.02732080513508791, tensor(0.1536)), (0.027358706078049817, tensor(0.1538)), (0.027396659599311316, tensor(0.1535)), (0.027434665771811945, tensor(0.1538)), (0.02747272466859245, tensor(0.1543)), (0.027510836362794874, tensor(0.1543)), (0.027549000927662753, tensor(0.1545)), (0.027587218436541213, tensor(0.1544)), (0.027625488962877136, tensor(0.1544)), (0.027663812580219296, tensor(0.1544)), (0.027702189362218493, tensor(0.1544)), (0.0277406193826277, tensor(0.1547)), (0.02777910271530221, tensor(0.1556)), (0.02781763943419976, tensor(0.1561)), (0.0278562296133807, tensor(0.1557)), (0.02789487332700811, tensor(0.1558)), (0.02793357064934795, tensor(0.1558)), (0.02797232165476923, tensor(0.1558)), (0.028011126417744094, tensor(0.1558)), (0.02804998501284802, tensor(0.1557)), (0.028088897514759945, tensor(0.1558)), (0.028127863998262385, tensor(0.1561)), (0.028166884538241614, tensor(0.1570)), (0.02820595920968779, tensor(0.1571)), (0.0282450880876951, tensor(0.1572)), (0.028284271247461905, tensor(0.1576)), (0.028323508764290878, tensor(0.1578)), (0.028362800713589174, tensor(0.1581)), (0.028402147170868544, tensor(0.1586)), (0.028441548211745493, tensor(0.1589)), (0.028481003911941433, tensor(0.1591)), (0.028520514347282817, tensor(0.1588)), (0.02856007959370128, tensor(0.1593)), (0.028599699727233814, tensor(0.1591)), (0.028639374824022873, tensor(0.1592)), (0.028679104960316545, tensor(0.1593)), (0.02871889021246871, tensor(0.1589)), (0.02875873065693915, tensor(0.1589)), (0.028798626370293717, tensor(0.1591)), (0.028838577429204496, tensor(0.1594)), (0.028878583910449923, tensor(0.1595)), (0.028918645890914946, tensor(0.1596)), (0.02895876344759118, tensor(0.1595)), (0.028998936657577037, tensor(0.1599)), (0.029039165598077888, tensor(0.1599)), (0.029079450346406212, tensor(0.1598)), (0.029119790979981734, tensor(0.1604)), (0.029160187576331584, tensor(0.1604)), (0.029200640213090434, tensor(0.1603)), (0.029241148968000667, tensor(0.1599)), (0.02928171391891251, tensor(0.1597)), (0.029322335143784187, tensor(0.1605)), (0.029363012720682063, tensor(0.1604)), (0.02940374672778082, tensor(0.1603)), (0.02944453724336357, tensor(0.1606)), (0.029485384345822024, tensor(0.1610)), (0.02952628811365666, tensor(0.1610)), (0.029567248625476838, tensor(0.1609)), (0.029608265960000983, tensor(0.1608)), (0.029649340196056705, tensor(0.1608)), (0.029690471412580983, tensor(0.1610)), (0.0297316596886203, tensor(0.1613)), (0.029772905103330794, tensor(0.1616)), (0.029814207735978412, tensor(0.1615)), (0.02985556766593906, tensor(0.1620)), (0.02989698497269877, tensor(0.1623)), (0.02993845973585383, tensor(0.1634)), (0.029979992035110953, tensor(0.1638)), (0.030021581950287424, tensor(0.1640)), (0.030063229561311258, tensor(0.1640)), (0.03010493494822135, tensor(0.1641)), (0.03014669819116762, tensor(0.1645)), (0.030188519370411195, tensor(0.1648)), (0.030230398566324534, tensor(0.1648)), (0.030272335859391583, tensor(0.1649)), (0.030314331330207965, tensor(0.1647)), (0.030356385059481083, tensor(0.1645)), (0.030398497128030316, tensor(0.1647)), (0.030440667616787164, tensor(0.1644)), (0.030482896606795387, tensor(0.1644)), (0.030525184179211188, tensor(0.1653)), (0.030567530415303336, tensor(0.1656)), (0.030609935396453354, tensor(0.1660)), (0.030652399204155665, tensor(0.1663)), (0.03069492192001774, tensor(0.1664)), (0.03073750362576025, tensor(0.1672)), (0.03078014440321725, tensor(0.1674)), (0.030822844334336318, tensor(0.1676)), (0.030865603501178694, tensor(0.1677)), (0.03090842198591949, tensor(0.1678)), (0.030951299870847798, tensor(0.1675)), (0.030994237238366855, tensor(0.1675)), (0.03103723417099424, tensor(0.1680)), (0.03108029075136198, tensor(0.1690)), (0.03112340706221674, tensor(0.1694)), (0.03116658318641999, tensor(0.1694)), (0.03120981920694814, tensor(0.1695)), (0.031253115206892695, tensor(0.1698)), (0.03129647126946045, tensor(0.1703)), (0.03133988747797363, tensor(0.1707)), (0.03138336391587003, tensor(0.1709)), (0.03142690066670321, tensor(0.1709)), (0.031470497814142635, tensor(0.1710)), (0.03151415544197385, tensor(0.1714)), (0.03155787363409861, tensor(0.1714)), (0.031601652474535086, tensor(0.1711)), (0.03164549204741799, tensor(0.1705)), (0.03168939243699876, tensor(0.1700)), (0.03173335372764571, tensor(0.1706)), (0.031777376003844185, tensor(0.1707)), (0.03182145935019674, tensor(0.1703)), (0.031865603851423306, tensor(0.1703)), (0.03190980959236132, tensor(0.1701)), (0.031954076657965916, tensor(0.1699)), (0.0319984051333101, tensor(0.1693)), (0.03204279510358488, tensor(0.1689)), (0.03208724665409945, tensor(0.1686)), (0.03213175987028136, tensor(0.1691)), (0.03217633483767663, tensor(0.1690)), (0.03222097164195001, tensor(0.1687)), (0.03226567036888505, tensor(0.1695)), (0.03231043110438432, tensor(0.1697)), (0.032355253934469565, tensor(0.1698)), (0.032400138945281834, tensor(0.1712)), (0.03244508622308171, tensor(0.1713)), (0.03249009585424942, tensor(0.1712)), (0.03253516792528503, tensor(0.1720)), (0.032580302522808614, tensor(0.1719)), (0.03262549973356039, tensor(0.1717)), (0.03267075964440091, tensor(0.1714)), (0.03271608234231124, tensor(0.1715)), (0.032761467914393105, tensor(0.1717)), (0.03280691644786905, tensor(0.1720)), (0.032852428030082634, tensor(0.1728)), (0.03289800274849857, tensor(0.1728)), (0.03294364069070292, tensor(0.1725)), (0.032989341944403255, tensor(0.1728)), (0.033035106597428796, tensor(0.1722)), (0.033080934737730626, tensor(0.1725)), (0.03312682645338182, tensor(0.1726)), (0.033172781832577665, tensor(0.1724)), (0.03321880096363576, tensor(0.1728)), (0.033264883934996256, tensor(0.1725)), (0.03331103083522196, tensor(0.1725)), (0.03335724175299856, tensor(0.1719)), (0.033403516777134774, tensor(0.1716)), (0.033449855996562514, tensor(0.1714)), (0.033496259500337064, tensor(0.1717)), (0.03354272737763725, tensor(0.1717)), (0.033589259717765614, tensor(0.1716)), (0.03363585661014858, tensor(0.1717)), (0.03368251814433664, tensor(0.1718)), (0.0337292444100045, tensor(0.1719)), (0.03377603549695128, tensor(0.1715)), (0.03382289149510066, tensor(0.1723)), (0.033869812494501085, tensor(0.1729)), (0.03391679858532591, tensor(0.1728)), (0.03396384985787359, tensor(0.1731)), (0.03401096640256784, tensor(0.1730)), (0.0340581483099578, tensor(0.1727)), (0.03410539567071827, tensor(0.1725)), (0.034152708575649796, tensor(0.1735)), (0.03420008711567891, tensor(0.1736)), (0.03424753138185828, tensor(0.1735)), (0.03429504146536687, tensor(0.1730)), (0.034342617457510154, tensor(0.1730)), (0.03439025944972026, tensor(0.1738)), (0.03443796753355616, tensor(0.1739)), (0.03448574180070384, tensor(0.1740)), (0.034533582342976474, tensor(0.1737)), (0.03458148925231461, tensor(0.1737)), (0.03462946262078634, tensor(0.1736)), (0.03467750254058747, tensor(0.1736)), (0.03472560910404172, tensor(0.1733)), (0.03477378240360087, tensor(0.1741)), (0.034822022531844965, tensor(0.1741)), (0.03487032958148249, tensor(0.1737)), (0.03491870364535052, tensor(0.1745)), (0.03496714481641493, tensor(0.1747)), (0.035015653187770564, tensor(0.1752)), (0.035064228852641405, tensor(0.1749)), (0.035112871904380775, tensor(0.1750)), (0.03516158243647148, tensor(0.1757)), (0.03521036054252604, tensor(0.1755)), (0.03525920631628681, tensor(0.1764)), (0.03530811985162619, tensor(0.1761)), (0.035357101242546846, tensor(0.1761)), (0.035406150583181806, tensor(0.1759)), (0.03545526796779469, tensor(0.1753)), (0.035504453490779915, tensor(0.1750)), (0.03555370724666281, tensor(0.1751)), (0.03560302933009986, tensor(0.1748)), (0.03565241983587885, tensor(0.1745)), (0.035701878858919074, tensor(0.1745)), (0.03575140649427148, tensor(0.1747)), (0.0358010028371189, tensor(0.1749)), (0.035850667982776196, tensor(0.1747)), (0.03590040202669046, tensor(0.1753)), (0.035950205064441194, tensor(0.1754)), (0.03600007719174048, tensor(0.1755)), (0.036050018504433214, tensor(0.1755)), (0.0361000290984972, tensor(0.1753)), (0.036150109070043436, tensor(0.1751)), (0.03620025851531622, tensor(0.1751)), (0.03625047753069338, tensor(0.1749)), (0.036300766212686436, tensor(0.1752)), (0.036351124657940805, tensor(0.1751)), (0.03640155296323597, tensor(0.1749)), (0.036452051225485664, tensor(0.1747)), (0.03650261954173808, tensor(0.1744)), (0.036553258009176026, tensor(0.1742)), (0.03660396672511714, tensor(0.1744)), (0.036654745787014054, tensor(0.1742)), (0.0367055952924546, tensor(0.1746)), (0.036756515339161994, tensor(0.1740)), (0.036807506024995, tensor(0.1738)), (0.03685856744794815, tensor(0.1741)), (0.03690969970615193, tensor(0.1737)), (0.03696090289787293, tensor(0.1737)), (0.03701217712151409, tensor(0.1734)), (0.037063522475614834, tensor(0.1733)), (0.037114939058851305, tensor(0.1733)), (0.037166426970036526, tensor(0.1730)), (0.037217986308120614, tensor(0.1727)), (0.037269617172190926, tensor(0.1729)), (0.0373213196614723, tensor(0.1730)), (0.03737309387532722, tensor(0.1732)), (0.037424939913256, tensor(0.1730)), (0.03747685787489702, tensor(0.1728)), (0.037528847860026845, tensor(0.1730)), (0.03758090996856047, tensor(0.1730)), (0.037633044300551505, tensor(0.1733)), (0.037685250956192344, tensor(0.1732)), (0.037737530035814405, tensor(0.1730)), (0.037789881639888244, tensor(0.1731)), (0.03784230586902384, tensor(0.1729)), (0.03789480282397071, tensor(0.1727)), (0.03794737260561816, tensor(0.1731)), (0.03800001531499544, tensor(0.1734)), (0.03805273105327196, tensor(0.1731)), (0.038105519921757494, tensor(0.1733)), (0.038158382021902325, tensor(0.1739)), (0.038211317455297496, tensor(0.1739)), (0.03826432632367497, tensor(0.1740)), (0.03831740872890786, tensor(0.1741)), (0.038370564773010575, tensor(0.1741)), (0.03842379455813907, tensor(0.1745)), (0.03847709818659099, tensor(0.1749)), (0.03853047576080591, tensor(0.1749)), (0.03858392738336553, tensor(0.1752)), (0.03863745315699382, tensor(0.1751)), (0.03869105318455728, tensor(0.1749)), (0.03874472756906511, tensor(0.1752)), (0.038798476413669396, tensor(0.1744)), (0.03885229982166533, tensor(0.1740)), (0.03890619789649142, tensor(0.1740)), (0.03896017074172964, tensor(0.1737)), (0.03901421846110567, tensor(0.1734)), (0.039068341158489096, tensor(0.1732)), (0.039122538937893574, tensor(0.1732)), (0.03917681190347708, tensor(0.1729)), (0.039231160159542054, tensor(0.1727)), (0.03928558381053565, tensor(0.1730)), (0.03934008296104993, tensor(0.1730)), (0.039394657715822026, tensor(0.1737)), (0.03944930817973437, tensor(0.1741)), (0.039504034457814904, tensor(0.1744)), (0.03955883665523726, tensor(0.1742)), (0.03961371487732099, tensor(0.1747)), (0.039668669229531724, tensor(0.1745)), (0.03972369981748144, tensor(0.1747)), (0.039778806746928574, tensor(0.1748)), (0.03983399012377833, tensor(0.1746)), (0.03988925005408278, tensor(0.1739)), (0.03994458664404116, tensor(0.1735))]
******

*** 2018-12-28 11:50:47,684 - code.resnet_fastai - DEBUG ***
0.016632441967498128
******

*** 2018-12-28 11:50:47,719 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2018-12-28 11:50:47,722 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:47,722 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2018-12-28 11:50:47,728 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:47,729 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2018-12-28 11:50:47,804 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,821 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXGeneral:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXGeneral ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,835 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXGeneral:style=italic:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXGeneral ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,836 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXGeneral:style=normal:variant=normal:weight=bold:stretch=normal:size=10.0 to STIXGeneral ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf') with score of 0.000000.
******

*** 2018-12-28 11:50:47,845 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXNonUnicode:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXNonUnicode ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,850 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXNonUnicode:style=italic:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXNonUnicode ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,859 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXNonUnicode:style=normal:variant=normal:weight=bold:stretch=normal:size=10.0 to STIXNonUnicode ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf') with score of 0.000000.
******

*** 2018-12-28 11:50:47,865 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeOneSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeOneSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,878 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeTwoSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeTwoSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,884 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeThreeSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeThreeSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,901 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeFourSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeFourSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,906 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=STIXSizeFiveSym:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to STIXSizeFiveSym ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,911 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmsy10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmsy10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,916 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmr10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmr10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,921 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmtt10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmtt10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,925 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmmi10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmmi10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,930 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmb10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmb10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,935 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmss10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmss10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,940 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=cmex10:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to cmex10 ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,945 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,950 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans:style=italic:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf') with score of 0.150000.
******

*** 2018-12-28 11:50:47,952 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans:style=normal:variant=normal:weight=bold:stretch=normal:size=10.0 to DejaVu Sans ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf') with score of 0.000000.
******

*** 2018-12-28 11:50:47,957 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans Mono:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans Mono ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:47,962 - matplotlib.font_manager - DEBUG ***
findfont: Matching :family=DejaVu Sans Display:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans Display ('/home/ubuntu/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf') with score of 0.050000.
******

*** 2018-12-28 11:50:48,160 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:48,160 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2018-12-28 11:50:48,161 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:48,162 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2018-12-28 11:50:48,253 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2018-12-28 11:50:48,256 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:48,256 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2018-12-28 11:50:48,257 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:48,257 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2018-12-28 11:50:48,266 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:48,266 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00])
******

*** 2018-12-28 11:50:48,267 - matplotlib.ticker - DEBUG ***
vmin 0.009471074402518941 vmax 0.042468701550101975
******

*** 2018-12-28 11:50:48,268 - matplotlib.ticker - DEBUG ***
ticklocs [0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
******

*** 2018-12-28 11:50:48,289 - code.resnet_fastai - INFO ***
Start model fitting: Stage 1
******

*** 2018-12-28 11:50:48,289 - code.resnet_fastai - DEBUG ***
Use best LR: 0.011642709377248688
******

2         0.173459                
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
epoch     train_loss  valid_loss  fbeta   
1         0.124279    0.112465    0.612686  
2         0.106300    0.097166    0.663123  
*** 2018-12-28 12:14:26,522 - code.resnet_fastai - INFO ***
Complete model fitting: Stage 1
******

*** 2018-12-28 12:14:26,652 - code.resnet_fastai - INFO ***
Stage 1 model saved.
******

*** 2018-12-28 12:14:26,654 - code.resnet_fastai - DEBUG ***
Unfreezing model
******

*** 2018-12-28 12:14:26,654 - code.resnet_fastai - DEBUG ***
Start finding LR
******

3         0.099800    0.120659    0.693216  
epoch     train_loss  valid_loss  fbeta   
1         0.094767                
*** 2018-12-28 12:23:09,988 - code.resnet_fastai - DEBUG ***
[(1e-08, tensor(0.0956)), (1.0069316688518042e-08, tensor(0.0923)), (1.0139113857366796e-08, tensor(0.0987)), (1.02093948370768e-08, tensor(0.0983)), (1.0280162981264735e-08, tensor(0.0968)), (1.035142166679344e-08, tensor(0.0946)), (1.0423174293933042e-08, tensor(0.0981)), (1.0495424286523223e-08, tensor(0.0984)), (1.0568175092136585e-08, tensor(0.0959)), (1.0641430182243161e-08, tensor(0.0952)), (1.0715193052376065e-08, tensor(0.0964)), (1.0789467222298288e-08, tensor(0.0944)), (1.0864256236170656e-08, tensor(0.0939)), (1.0939563662720939e-08, tensor(0.0932)), (1.101539309541415e-08, tensor(0.0949)), (1.109174815262401e-08, tensor(0.0967)), (1.1168632477805612e-08, tensor(0.0969)), (1.1246049739669264e-08, tensor(0.0964)), (1.132400363235557e-08, tensor(0.0975)), (1.1402497875611686e-08, tensor(0.0963)), (1.1481536214968828e-08, tensor(0.0961)), (1.1561122421920989e-08, tensor(0.0971)), (1.1641260294104914e-08, tensor(0.0977)), (1.1721953655481306e-08, tensor(0.0972)), (1.1803206356517297e-08, tensor(0.0969)), (1.1885022274370185e-08, tensor(0.0967)), (1.1967405313072436e-08, tensor(0.0974)), (1.2050359403717974e-08, tensor(0.0972)), (1.2133888504649773e-08, tensor(0.0978)), (1.2217996601648718e-08, tensor(0.0978)), (1.2302687708123816e-08, tensor(0.0979)), (1.2387965865303691e-08, tensor(0.0974)), (1.247383514242943e-08, tensor(0.0968)), (1.256029963694875e-08, tensor(0.0964)), (1.2647363474711513e-08, tensor(0.0963)), (1.2735030810166617e-08, tensor(0.0963)), (1.2823305826560214e-08, tensor(0.0966)), (1.2912192736135342e-08, tensor(0.0967)), (1.3001695780332903e-08, tensor(0.0972)), (1.3091819229994071e-08, tensor(0.0967)), (1.3182567385564071e-08, tensor(0.0962)), (1.3273944577297397e-08, tensor(0.0964)), (1.3365955165464423e-08, tensor(0.0966)), (1.3458603540559482e-08, tensor(0.0968)), (1.355189412351036e-08, tensor(0.0974)), (1.3645831365889245e-08, tensor(0.0971)), (1.3740419750125152e-08, tensor(0.0971)), (1.383566378971781e-08, tensor(0.0971)), (1.3931568029453033e-08, tensor(0.0962)), (1.4028137045619582e-08, tensor(0.0965)), (1.4125375446227544e-08, tensor(0.0961)), (1.4223287871228198e-08, tensor(0.0960)), (1.4321878992735435e-08, tensor(0.0957)), (1.4421153515248689e-08, tensor(0.0951)), (1.4521116175877422e-08, tensor(0.0959)), (1.4621771744567183e-08, tensor(0.0965)), (1.4723125024327189e-08, tensor(0.0969)), (1.4825180851459536e-08, tensor(0.0964)), (1.4927944095789962e-08, tensor(0.0964)), (1.5031419660900222e-08, tensor(0.0960)), (1.5135612484362082e-08, tensor(0.0960)), (1.524052753797291e-08, tensor(0.0957)), (1.5346169827992945e-08, tensor(0.0956)), (1.5452544395384137e-08, tensor(0.0964)), (1.5559656316050745e-08, tensor(0.0962)), (1.5667510701081492e-08, tensor(0.0962)), (1.5776112696993486e-08, tensor(0.0957)), (1.5885467485977788e-08, tensor(0.0954)), (1.599558028614669e-08, tensor(0.0948)), (1.6106456351782704e-08, tensor(0.0949)), (1.62181009735893e-08, tensor(0.0949)), (1.6330519478943343e-08, tensor(0.0948)), (1.6443717232149315e-08, tensor(0.0943)), (1.655769963469528e-08, tensor(0.0944)), (1.6672472125510626e-08, tensor(0.0953)), (1.6788040181225605e-08, tensor(0.0966)), (1.690440931643264e-08, tensor(0.0962)), (1.7021585083949507e-08, tensor(0.0965)), (1.7139573075084252e-08, tensor(0.0966)), (1.7258378919902036e-08, tensor(0.0966)), (1.7378008287493757e-08, tensor(0.0961)), (1.749846688624657e-08, tensor(0.0960)), (1.7619760464116293e-08, tensor(0.0959)), (1.774189480890166e-08, tensor(0.0959)), (1.786487574852051e-08, tensor(0.0955)), (1.798870915128788e-08, tensor(0.0952)), (1.8113400926196024e-08, tensor(0.0954)), (1.823895702319638e-08, tensor(0.0954)), (1.8365383433483463e-08, tensor(0.0956)), (1.8492686189780784e-08, tensor(0.0958)), (1.8620871366628676e-08, tensor(0.0957)), (1.8749945080674185e-08, tensor(0.0955)), (1.8879913490962934e-08, tensor(0.0961)), (1.9010782799233e-08, tensor(0.0957)), (1.914255925021086e-08, tensor(0.0962)), (1.927524913190936e-08, tensor(0.0963)), (1.9408858775927783e-08, tensor(0.0965)), (1.9543394557753946e-08, tensor(0.0964)), (1.967886289706845e-08, tensor(0.0960)), (1.9815270258050982e-08, tensor(0.0962)), (1.9952623149688796e-08, tensor(0.0962)), (2.009092812608728e-08, tensor(0.0956)), (2.0230191786782714e-08, tensor(0.0956)), (2.0370420777057184e-08, tensor(0.0954)), (2.0511621788255654e-08, tensor(0.0956)), (2.065380155810529e-08, tensor(0.0958)), (2.0796966871036954e-08, tensor(0.0955)), (2.0941124558508927e-08, tensor(0.0953)), (2.1086281499332892e-08, tensor(0.0956)), (2.1232444620002197e-08, tensor(0.0956)), (2.1379620895022322e-08, tensor(0.0956)), (2.152781734724373e-08, tensor(0.0952)), (2.1677041048196948e-08, tensor(0.0949)), (2.1827299118430016e-08, tensor(0.0948)), (2.197859872784825e-08, tensor(0.0951)), (2.2130947096056376e-08, tensor(0.0952)), (2.228435149270304e-08, tensor(0.0954)), (2.2438819237827663e-08, tensor(0.0955)), (2.2594357702209777e-08, tensor(0.0955)), (2.2750974307720705e-08, tensor(0.0954)), (2.2908676527677733e-08, tensor(0.0956)), (2.306747188720069e-08, tensor(0.0956)), (2.322736796357107e-08, tensor(0.0955)), (2.3388372386593547e-08, tensor(0.0952)), (2.3550492838960095e-08, tensor(0.0950)), (2.3713737056616554e-08, tensor(0.0955)), (2.3878112829131776e-08, tensor(0.0955)), (2.4043628000069335e-08, tensor(0.0953)), (2.4210290467361784e-08, tensor(0.0955)), (2.4378108183687525e-08, tensor(0.0956)), (2.4547089156850305e-08, tensor(0.0954)), (2.4717241450161304e-08, tensor(0.0952)), (2.488857318282391e-08, tensor(0.0948)), (2.506109253032114e-08, tensor(0.0948)), (2.5234807724805748e-08, tensor(0.0948)), (2.5409727055493052e-08, tensor(0.0948)), (2.558585886905646e-08, tensor(0.0946)), (2.5763211570025756e-08, tensor(0.0943)), (2.5941793621188144e-08, tensor(0.0943)), (2.612161354399207e-08, tensor(0.0938)), (2.630267991895382e-08, tensor(0.0934)), (2.648500138606701e-08, tensor(0.0938)), (2.6668586645214797e-08, tensor(0.0934)), (2.685344445658507e-08, tensor(0.0933)), (2.7039583641088436e-08, tensor(0.0939)), (2.7227013080779124e-08, tensor(0.0943)), (2.7415741719278825e-08, tensor(0.0954)), (2.760577856220346e-08, tensor(0.0957)), (2.7797132677592887e-08, tensor(0.0951)), (2.7989813196343625e-08, tensor(0.0950)), (2.8183829312644537e-08, tensor(0.0946)), (2.837919028441556e-08, tensor(0.0943)), (2.857590543374947e-08, tensor(0.0942)), (2.8773984147356692e-08, tensor(0.0944)), (2.897343587701323e-08, tensor(0.0943)), (2.9174270140011668e-08, tensor(0.0939)), (2.937649651961531e-08, tensor(0.0936)), (2.958012466551546e-08, tensor(0.0932)), (2.97851642942919e-08, tensor(0.0932)), (2.9991625189876515e-08, tensor(0.0937)), (3.019951720402017e-08, tensor(0.0938)), (3.0408850256762794e-08, tensor(0.0935)), (3.0619634336906774e-08, tensor(0.0938)), (3.0831879502493547e-08, tensor(0.0933)), (3.104559588128356e-08, tensor(0.0932)), (3.126079367123955e-08, tensor(0.0937)), (3.147748314101316e-08, tensor(0.0942)), (3.169567463043491e-08, tensor(0.0943)), (3.191537855100762e-08, tensor(0.0942)), (3.213660538640318e-08, tensor(0.0943)), (3.2359365692962835e-08, tensor(0.0940)), (3.2583670100200884e-08, tensor(0.0938)), (3.28095293113119e-08, tensor(0.0938)), (3.303695410368148e-08, tensor(0.0935)), (3.326595532940045e-08, tensor(0.0937)), (3.349654391578277e-08, tensor(0.0934)), (3.3728730865886885e-08, tensor(0.0932)), (3.396252725904084e-08, tensor(0.0931)), (3.4197944251370886e-08, tensor(0.0933)), (3.4434993076333846e-08, tensor(0.0931)), (3.4673685045253164e-08, tensor(0.0929)), (3.491403154785861e-08, tensor(0.0933)), (3.515604405282981e-08, tensor(0.0931)), (3.539973410834347e-08, tensor(0.0928)), (3.564511334262442e-08, tensor(0.0930)), (3.589219346450052e-08, tensor(0.0925)), (3.614098626396133e-08, tensor(0.0923)), (3.6391503612720714e-08, tensor(0.0927)), (3.664375746478333e-08, tensor(0.0929)), (3.6897759857015035e-08, tensor(0.0930)), (3.715352290971726e-08, tensor(0.0932)), (3.741105882720534e-08, tensor(0.0936)), (3.767037989839089e-08, tensor(0.0938)), (3.7931498497368195e-08, tensor(0.0939)), (3.8194427084004656e-08, tensor(0.0940)), (3.845917820453536e-08, tensor(0.0945)), (3.872576449216172e-08, tensor(0.0944)), (3.8994198667654347e-08, tensor(0.0942)), (3.9264493539959994e-08, tensor(0.0940)), (3.9536662006812795e-08, tensor(0.0946)), (3.981071705534973e-08, tensor(0.0950)), (4.008667176273029e-08, tensor(0.0950)), (4.03645392967605e-08, tensor(0.0954)), (4.0644332916521283e-08, tensor(0.0955)), (4.092606597300108e-08, tensor(0.0953)), (4.120975190973302e-08, tensor(0.0954)), (4.149540426343629e-08, tensor(0.0951)), (4.178303666466218e-08, tensor(0.0951)), (4.207266283844441e-08, tensor(0.0952)), (4.236429660495412e-08, tensor(0.0956)), (4.2657951880159266e-08, tensor(0.0953)), (4.2953642676488733e-08, tensor(0.0949)), (4.325138310350087e-08, tensor(0.0950)), (4.355118736855686e-08, tensor(0.0953)), (4.385306977749857e-08, tensor(0.0955)), (4.4157044735331255e-08, tensor(0.0957)), (4.4463126746910867e-08, tensor(0.0959)), (4.4771330417636255e-08, tensor(0.0956)), (4.508167045414601e-08, tensor(0.0952)), (4.539416166502032e-08, tensor(0.0951)), (4.570881896148751e-08, tensor(0.0950)), (4.6025657358135606e-08, tensor(0.0953)), (4.6344691973628804e-08, tensor(0.0957)), (4.666593803142886e-08, tensor(0.0956)), (4.6989410860521546e-08, tensor(0.0960)), (4.7315125896148054e-08, tensor(0.0958)), (4.764309868054158e-08, tensor(0.0954)), (4.797334486366892e-08, tensor(0.0956)), (4.830588020397727e-08, tensor(0.0955)), (4.864072056914616e-08, tensor(0.0955)), (4.897788193684463e-08, tensor(0.0957)), (4.93173803954936e-08, tensor(0.0956)), (4.965923214503361e-08, tensor(0.0953)), (5.000345349769786e-08, tensor(0.0947)), (5.035006087879049e-08, tensor(0.0946)), (5.0699070827470436e-08, tensor(0.0948)), (5.105049999754062e-08, tensor(0.0945)), (5.140436515824261e-08, tensor(0.0945)), (5.176068319505676e-08, tensor(0.0942)), (5.211947111050805e-08, tensor(0.0938)), (5.248074602497726e-08, tensor(0.0932)), (5.284452517751804e-08, tensor(0.0934)), (5.321082592667942e-08, tensor(0.0935)), (5.357966575133416e-08, tensor(0.0938)), (5.3951062251512766e-08, tensor(0.0937)), (5.4325033149243326e-08, tensor(0.0936)), (5.4701596289397164e-08, tensor(0.0942)), (5.508076964054034e-08, tensor(0.0944)), (5.5462571295791076e-08, tensor(0.0942)), (5.5847019473683085e-08, tensor(0.0945)), (5.623413251903491e-08, tensor(0.0947)), (5.6623928903825337e-08, tensor(0.0946)), (5.701642722807475e-08, tensor(0.0951)), (5.741164622073276e-08, tensor(0.0950)), (5.780960474057182e-08, tensor(0.0954)), (5.821032177708714e-08, tensor(0.0958)), (5.8613816451402875e-08, tensor(0.0957)), (5.9020108017184435e-08, tensor(0.0956)), (5.942921586155727e-08, tensor(0.0957)), (5.984115950603197e-08, tensor(0.0957)), (6.025595860743578e-08, tensor(0.0960)), (6.067363295885054e-08, tensor(0.0960)), (6.109420249055721e-08, tensor(0.0959)), (6.151768727098683e-08, tensor(0.0957)), (6.194410750767815e-08, tensor(0.0961)), (6.237348354824193e-08, tensor(0.0963)), (6.280583588133181e-08, tensor(0.0963)), (6.324118513762196e-08, tensor(0.0963)), (6.367955209079158e-08, tensor(0.0964)), (6.412095765851617e-08, tensor(0.0965)), (6.456542290346557e-08, tensor(0.0962)), (6.501296903430908e-08, tensor(0.0965)), (6.546361740672751e-08, tensor(0.0968)), (6.591738952443214e-08, tensor(0.0968)), (6.637430704019089e-08, tensor(0.0972)), (6.683439175686148e-08, tensor(0.0973)), (6.72976656284318e-08, tensor(0.0975)), (6.776415076106752e-08, tensor(0.0973)), (6.823386941416698e-08, tensor(0.0974)), (6.870684400142322e-08, tensor(0.0975)), (6.918309709189366e-08, tensor(0.0972)), (6.966265141107689e-08, tensor(0.0976)), (7.014552984199711e-08, tensor(0.0978)), (7.063175542629619e-08, tensor(0.0976)), (7.112135136533289e-08, tensor(0.0980)), (7.161434102129019e-08, tensor(0.0981)), (7.211074791828995e-08, tensor(0.0980)), (7.261059574351546e-08, tensor(0.0978)), (7.311390834834174e-08, tensor(0.0974)), (7.362070974947361e-08, tensor(0.0976)), (7.413102413009175e-08, tensor(0.0975)), (7.464487584100665e-08, tensor(0.0974)), (7.516228940182054e-08, tensor(0.0975)), (7.568328950209743e-08, tensor(0.0970)), (7.62079010025412e-08, tensor(0.0971)), (7.67361489361819e-08, tensor(0.0970)), (7.726805850957023e-08, tensor(0.0974)), (7.780365510398041e-08, tensor(0.0972)), (7.834296427662118e-08, tensor(0.0970)), (7.888601176185544e-08, tensor(0.0966)), (7.943282347242815e-08, tensor(0.0970)), (7.998342550070284e-08, tensor(0.0968)), (8.053784411990667e-08, tensor(0.0963)), (8.109610578538409e-08, tensor(0.0965)), (8.165823713585924e-08, tensor(0.0965)), (8.222426499470711e-08, tensor(0.0966)), (8.279421637123341e-08, tensor(0.0961)), (8.336811846196342e-08, tensor(0.0962)), (8.394599865193975e-08, tensor(0.0965)), (8.452788451602899e-08, tensor(0.0966)), (8.511380382023765e-08, tensor(0.0960)), (8.570378452303696e-08, tensor(0.0955)), (8.629785477669703e-08, tensor(0.0958)), (8.689604292863019e-08, tensor(0.0955)), (8.749837752274362e-08, tensor(0.0958)), (8.810488730080142e-08, tensor(0.0955)), (8.87156012037961e-08, tensor(0.0957)), (8.933054837332954e-08, tensor(0.0951)), (8.994975815300352e-08, tensor(0.0949)), (9.057326008982003e-08, tensor(0.0950)), (9.120108393559099e-08, tensor(0.0950)), (9.18332596483581e-08, tensor(0.0951)), (9.246981739382227e-08, tensor(0.0959)), (9.311078754678305e-08, tensor(0.0959)), (9.375620069258802e-08, tensor(0.0962)), (9.440608762859235e-08, tensor(0.0962)), (9.506047936562816e-08, tensor(0.0958)), (9.571940712948445e-08, tensor(0.0958)), (9.638290236239706e-08, tensor(0.0961)), (9.705099672454898e-08, tensor(0.0964)), (9.772372209558108e-08, tensor(0.0964)), (9.840111057611339e-08, tensor(0.0967)), (9.908319448927678e-08, tensor(0.0969)), (9.977000638225535e-08, tensor(0.0971)), (1.0046157902783954e-07, tensor(0.0970)), (1.0115794542598987e-07, tensor(0.0967)), (1.0185913880541172e-07, tensor(0.0964)), (1.025651926251408e-07, tensor(0.0964)), (1.0327614057613976e-07, tensor(0.0967)), (1.0399201658290595e-07, tensor(0.0969)), (1.0471285480508999e-07, tensor(0.0971)), (1.0543868963912591e-07, tensor(0.0968)), (1.061695557198725e-07, tensor(0.0972)), (1.0690548792226581e-07, tensor(0.0971)), (1.0764652136298347e-07, tensor(0.0968)), (1.0839269140212034e-07, tensor(0.0970)), (1.0914403364487565e-07, tensor(0.0969)), (1.0990058394325209e-07, tensor(0.0970)), (1.1066237839776662e-07, tensor(0.0966)), (1.1142945335917299e-07, tensor(0.0967)), (1.1220184543019633e-07, tensor(0.0968)), (1.1297959146727976e-07, tensor(0.0971)), (1.1376272858234307e-07, tensor(0.0974)), (1.1455129414455356e-07, tensor(0.0970)), (1.1534532578210921e-07, tensor(0.0969)), (1.1614486138403427e-07, tensor(0.0973)), (1.169499391019871e-07, tensor(0.0971)), (1.1776059735208073e-07, tensor(0.0970)), (1.1857687481671601e-07, tensor(0.0967)), (1.1939881044642733e-07, tensor(0.0971)), (1.202264434617413e-07, tensor(0.0968)), (1.2105981335504824e-07, tensor(0.0966)), (1.2189895989248665e-07, tensor(0.0973)), (1.2274392311584074e-07, tensor(0.0978)), (1.2359474334445104e-07, tensor(0.0984)), (1.244514611771385e-07, tensor(0.0983)), (1.2531411749414159e-07, tensor(0.0980)), (1.2618275345906707e-07, tensor(0.0979)), (1.2705741052085417e-07, tensor(0.0981)), (1.2793813041575248e-07, tensor(0.0988)), (1.288249551693134e-07, tensor(0.0984)), (1.297179270983956e-07, tensor(0.0986)), (1.3061708881318415e-07, tensor(0.0983)), (1.3152248321922384e-07, tensor(0.0980)), (1.3243415351946647e-07, tensor(0.0978)), (1.3335214321633243e-07, tensor(0.0980)), (1.3427649611378639e-07, tensor(0.0980)), (1.3520725631942772e-07, tensor(0.0981)), (1.3614446824659502e-07, tensor(0.0982)), (1.3708817661648537e-07, tensor(0.0984)), (1.380384264602885e-07, tensor(0.0986)), (1.3899526312133533e-07, tensor(0.0987)), (1.3995873225726182e-07, tensor(0.0984)), (1.4092887984218748e-07, tensor(0.0984)), (1.4190575216890925e-07, tensor(0.0981)), (1.428893958511103e-07, tensor(0.0981)), (1.4387985782558456e-07, tensor(0.0982)), (1.4487718535447618e-07, tensor(0.0982)), (1.4588142602753486e-07, tensor(0.0982)), (1.4689262776438669e-07, tensor(0.0984)), (1.4791083881682077e-07, tensor(0.0983)), (1.4893610777109154e-07, tensor(0.0974)), (1.4996848355023738e-07, tensor(0.0977)), (1.5100801541641487e-07, tensor(0.0977)), (1.5205475297324959e-07, tensor(0.0980)), (1.5310874616820304e-07, tensor(0.0977)), (1.5417004529495597e-07, tensor(0.0977)), (1.5523870099580825e-07, tensor(0.0977)), (1.5631476426409545e-07, tensor(0.0974)), (1.57398286446622e-07, tensor(0.0975)), (1.5848931924611138e-07, tensor(0.0978)), (1.5958791472367328e-07, tensor(0.0976)), (1.6069412530128777e-07, tensor(0.0975)), (1.618080037643066e-07, tensor(0.0977)), (1.629296032639723e-07, tensor(0.0979)), (1.6405897731995396e-07, tensor(0.0982)), (1.6519617982290154e-07, tensor(0.0976)), (1.6634126503701693e-07, tensor(0.0978)), (1.6749428760264373e-07, tensor(0.0977)), (1.686553025388741e-07, tensor(0.0980)), (1.698243652461744e-07, tensor(0.0984)), (1.7100153150902874e-07, tensor(0.0983)), (1.721868574986007e-07, tensor(0.0983)), (1.7338039977541377e-07, tensor(0.0989)), (1.7458221529205038e-07, tensor(0.0989)), (1.7579236139586924e-07, tensor(0.0986)), (1.7701089583174208e-07, tensor(0.0985)), (1.7823787674480895e-07, tensor(0.0985)), (1.7947336268325264e-07, tensor(0.0986)), (1.807174126010927e-07, tensor(0.0984)), (1.8197008586099835e-07, tensor(0.0981)), (1.8323144223712113e-07, tensor(0.0985)), (1.8450154191794734e-07, tensor(0.0985)), (1.8578044550916986e-07, tensor(0.0985)), (1.8706821403658004e-07, tensor(0.0987)), (1.8836490894898008e-07, tensor(0.0985)), (1.8967059212111463e-07, tensor(0.0984)), (1.909853258566238e-07, tensor(0.0981)), (1.9230917289101584e-07, tensor(0.0979)), (1.936421963946607e-07, tensor(0.0980)), (1.9498445997580455e-07, tensor(0.0982)), (1.963360276836047e-07, tensor(0.0978)), (1.9769696401118608e-07, tensor(0.0981)), (1.9906733389871867e-07, tensor(0.0979)), (2.0044720273651612e-07, tensor(0.0976)), (2.018366363681561e-07, tensor(0.0976)), (2.032357010936222e-07, tensor(0.0972)), (2.0464446367246745e-07, tensor(0.0975)), (2.06062991327e-07, tensor(0.0972)), (2.07491351745491e-07, tensor(0.0972)), (2.0892961308540398e-07, tensor(0.0970)), (2.1037784397664756e-07, tensor(0.0969)), (2.118361135248502e-07, tensor(0.0969)), (2.1330449131465768e-07, tensor(0.0970)), (2.147830474130534e-07, tensor(0.0971)), (2.1627185237270205e-07, tensor(0.0970)), (2.177709772353159e-07, tensor(0.0968)), (2.1928049353504488e-07, tensor(0.0966)), (2.2080047330189e-07, tensor(0.0966)), (2.2233098906514035e-07, tensor(0.0964)), (2.23872113856834e-07, tensor(0.0963)), (2.2542392121524298e-07, tensor(0.0960)), (2.2698648518838222e-07, tensor(0.0964)), (2.2855988033754304e-07, tensor(0.0966)), (2.3014418174085088e-07, tensor(0.0967)), (2.317394649968479e-07, tensor(0.0968)), (2.333458062281003e-07, tensor(0.0969)), (2.3496328208483077e-07, tensor(0.0969)), (2.3659196974857587e-07, tensor(0.0969)), (2.3823194693586908e-07, tensor(0.0965)), (2.398832919019491e-07, tensor(0.0965)), (2.4154608344449406e-07, tensor(0.0962)), (2.4322040090738156e-07, tensor(0.0962)), (2.4490632418447456e-07, tensor(0.0966)), (2.46603933723434e-07, tensor(0.0966)), (2.483133105295571e-07, tensor(0.0963)), (2.500345361696432e-07, tensor(0.0962)), (2.5176769277588565e-07, tensor(0.0960)), (2.5351286304979083e-07, tensor(0.0956)), (2.5527013026612465e-07, tensor(0.0956)), (2.570395782768863e-07, tensor(0.0957)), (2.588212915153091e-07, tensor(0.0956)), (2.606153549998895e-07, tensor(0.0959)), (2.624218543384442e-07, tensor(0.0962)), (2.6424087573219464e-07, tensor(0.0962)), (2.6607250597988094e-07, tensor(0.0965)), (2.6791683248190317e-07, tensor(0.0963)), (2.69773943244492e-07, tensor(0.0959)), (2.716439268839082e-07, tensor(0.0965)), (2.7352687263067116e-07, tensor(0.0965)), (2.7542287033381663e-07, tensor(0.0968)), (2.7733201046518403e-07, tensor(0.0970)), (2.7925438412373376e-07, tensor(0.0968)), (2.8119008303989406e-07, tensor(0.0967)), (2.831391995799379e-07, tensor(0.0967)), (2.851018267503909e-07, tensor(0.0966)), (2.870780582024691e-07, tensor(0.0973)), (2.890679882365476e-07, tensor(0.0974)), (2.9107171180666054e-07, tensor(0.0973)), (2.9308932452503207e-07, tensor(0.0972)), (2.9512092266663856e-07, tensor(0.0969)), (2.971666031738026e-07, tensor(0.0965)), (2.9922646366081894e-07, tensor(0.0964)), (3.0130060241861214e-07, tensor(0.0962)), (3.033891184194271e-07, tensor(0.0965)), (3.0549211132155133e-07, tensor(0.0968)), (3.0760968147407083e-07, tensor(0.0974)), (3.0974192992165806e-07, tensor(0.0973)), (3.118889584093937e-07, tensor(0.0973)), (3.1405086938762177e-07, tensor(0.0976)), (3.1622776601683797e-07, tensor(0.0971)), (3.1841975217261247e-07, tensor(0.0969)), (3.206269324505466e-07, tensor(0.0970)), (3.228494121712636e-07, tensor(0.0967)), (3.250872973854344e-07, tensor(0.0966)), (3.2734069487883823e-07, tensor(0.0967)), (3.296097121774578e-07, tensor(0.0968)), (3.318944575526104e-07, tensor(0.0967)), (3.3419504002611426e-07, tensor(0.0972)), (3.365115693754908e-07, tensor(0.0974)), (3.3884415613920264e-07, tensor(0.0976)), (3.411929116219286e-07, tensor(0.0976)), (3.435579478998746e-07, tensor(0.0975)), (3.4593937782612204e-07, tensor(0.0977)), (3.483373150360119e-07, tensor(0.0973)), (3.5075187395256807e-07, tensor(0.0974)), (3.53183169791957e-07, tensor(0.0974)), (3.5563131856898536e-07, tensor(0.0977)), (3.580964371026361e-07, tensor(0.0976)), (3.605786430216425e-07, tensor(0.0975)), (3.630780547701014e-07, tensor(0.0975)), (3.6559479161312495e-07, tensor(0.0979)), (3.6812897364253154e-07, tensor(0.0977)), (3.7068072178257607e-07, tensor(0.0976)), (3.732501577957206e-07, tensor(0.0976)), (3.758374042884442e-07, tensor(0.0976)), (3.784425847170934e-07, tensor(0.0975)), (3.810658233937731e-07, tensor(0.0984)), (3.8370724549227887e-07, tensor(0.0982)), (3.8636697705406927e-07, tensor(0.0981)), (3.890451449942807e-07, tensor(0.0980)), (3.917418771077832e-07, tensor(0.0985)), (3.944573020752785e-07, tensor(0.0986)), (3.9719154946944046e-07, tensor(0.0990)), (3.999447497610976e-07, tensor(0.0990)), (4.027170343254592e-07, tensor(0.0983)), (4.05508535448384e-07, tensor(0.0984)), (4.0831938633269224e-07, tensor(0.0981)), (4.1114972110452235e-07, tensor(0.0982)), (4.139996748197306e-07, tensor(0.0979)), (4.1686938347033557e-07, tensor(0.0978)), (4.1975898399100765e-07, tensor(0.0976)), (4.2266861426560313e-07, tensor(0.0978)), (4.2559841313374323e-07, tensor(0.0978)), (4.285485203974397e-07, tensor(0.0977)), (4.315190768277654e-07, tensor(0.0973)), (4.345102241715717e-07, tensor(0.0972)), (4.375221051582522e-07, tensor(0.0971)), (4.4055486350655347e-07, tensor(0.0969)), (4.436086439314327e-07, tensor(0.0969)), (4.4668359215096333e-07, tensor(0.0966)), (4.497798548932881e-07, tensor(0.0965)), (4.5289757990362093e-07, tensor(0.0962)), (4.5603691595129633e-07, tensor(0.0965)), (4.591980128368688e-07, tensor(0.0966)), (4.623810213992605e-07, tensor(0.0965)), (4.6558609352295914e-07, tensor(0.0967)), (4.688133821452654e-07, tensor(0.0973)), (4.7206304126359075e-07, tensor(0.0968)), (4.753352259428055e-07, tensor(0.0968)), (4.786300923226386e-07, tensor(0.0969)), (4.819477976251275e-07, tensor(0.0969)), (4.852885001621213e-07, tensor(0.0978)), (4.886523593428335e-07, tensor(0.0983)), (4.920395356814508e-07, tensor(0.0984)), (4.9545019080479e-07, tensor(0.0986)), (4.988844874600121e-07, tensor(0.0983)), (5.023425895223869e-07, tensor(0.0984)), (5.058246620031139e-07, tensor(0.0986)), (5.093308710571953e-07, tensor(0.0982)), (5.128613839913647e-07, tensor(0.0980)), (5.164163692720708e-07, tensor(0.0979)), (5.199959965335159e-07, tensor(0.0977)), (5.236004365857501e-07, tensor(0.0975)), (5.272298614228226e-07, tensor(0.0974)), (5.308844442309882e-07, tensor(0.0973)), (5.345643593969715e-07, tensor(0.0976)), (5.382697825162881e-07, tensor(0.0974)), (5.420008904016238e-07, tensor(0.0975)), (5.457578610912708e-07, tensor(0.0973)), (5.495408738576244e-07, tensor(0.0978)), (5.533501092157366e-07, tensor(0.0974)), (5.571857489319297e-07, tensor(0.0973)), (5.610479760324703e-07, tensor(0.0969)), (5.649369748123024e-07, tensor(0.0972)), (5.688529308438414e-07, tensor(0.0970)), (5.727960309858291e-07, tensor(0.0968)), (5.767664633922507e-07, tensor(0.0965)), (5.807644175213119e-07, tensor(0.0965)), (5.847900841444807e-07, tensor(0.0969)), (5.888436553555888e-07, tensor(0.0973)), (5.929253245799998e-07, tensor(0.0977)), (5.970352865838368e-07, tensor(0.0980)), (6.011737374832779e-07, tensor(0.0981)), (6.053408747539135e-07, tensor(0.0977)), (6.095368972401692e-07, tensor(0.0981)), (6.137620051647942e-07, tensor(0.0984)), (6.180164001384158e-07, tensor(0.0979)), (6.223002851691595e-07, tensor(0.0984)), (6.266138646723353e-07, tensor(0.0982)), (6.309573444801932e-07, tensor(0.0978)), (6.353309318517437e-07, tensor(0.0974)), (6.397348354826481e-07, tensor(0.0970)), (6.441692655151772e-07, tensor(0.0966)), (6.486344335482383e-07, tensor(0.0967)), (6.531305526474723e-07, tensor(0.0968)), (6.576578373554204e-07, tensor(0.0968)), (6.62216503701762e-07, tensor(0.0965)), (6.66806769213622e-07, tensor(0.0963)), (6.714288529259524e-07, tensor(0.0958)), (6.760829753919818e-07, tensor(0.0957)), (6.807693586937414e-07, tensor(0.0959)), (6.854882264526616e-07, tensor(0.0959)), (6.90239803840242e-07, tensor(0.0959)), (6.950243175887968e-07, tensor(0.0958)), (6.998419960022736e-07, tensor(0.0960)), (7.04693068967147e-07, tensor(0.0963)), (7.095777679633888e-07, tensor(0.0960)), (7.144963260755134e-07, tensor(0.0959)), (7.194489780036995e-07, tensor(0.0958)), (7.244359600749902e-07, tensor(0.0955)), (7.294575102545688e-07, tensor(0.0958)), (7.34513868157115e-07, tensor(0.0962)), (7.396052750582379e-07, tensor(0.0961)), (7.447319739059892e-07, tensor(0.0959)), (7.498942093324558e-07, tensor(0.0959)), (7.55092227665434e-07, tensor(0.0960)), (7.603262769401819e-07, tensor(0.0957)), (7.655966069112565e-07, tensor(0.0960)), (7.709034690644302e-07, tensor(0.0961)), (7.762471166286918e-07, tensor(0.0957)), (7.816278045883297e-07, tensor(0.0953)), (7.870457896950987e-07, tensor(0.0951)), (7.925013304804719e-07, tensor(0.0955)), (7.979946872679767e-07, tensor(0.0955)), (8.035261221856173e-07, tensor(0.0953)), (8.090958991783825e-07, tensor(0.0951)), (8.147042840208397e-07, tensor(0.0952)), (8.203515443298184e-07, tensor(0.0950)), (8.260379495771789e-07, tensor(0.0955)), (8.317637711026711e-07, tensor(0.0957)), (8.375292821268827e-07, tensor(0.0958)), (8.433347577642755e-07, tensor(0.0955)), (8.491804750363141e-07, tensor(0.0960)), (8.550667128846836e-07, tensor(0.0955)), (8.609937521846009e-07, tensor(0.0959)), (8.669618757582169e-07, tensor(0.0960)), (8.729713683881118e-07, tensor(0.0959)), (8.790225168308845e-07, tensor(0.0956)), (8.851156098308358e-07, tensor(0.0959)), (8.912509381337458e-07, tensor(0.0963)), (8.974287945007486e-07, tensor(0.0963)), (9.036494737223016e-07, tensor(0.0966)), (9.099132726322518e-07, tensor(0.0967)), (9.16220490122e-07, tensor(0.0971)), (9.225714271547634e-07, tensor(0.0972)), (9.289663867799367e-07, tensor(0.0979)), (9.354056741475522e-07, tensor(0.0979)), (9.418895965228417e-07, tensor(0.0979)), (9.484184633008974e-07, tensor(0.0975)), (9.549925860214362e-07, tensor(0.0970)), (9.61612278383665e-07, tensor(0.0967)), (9.682778562612496e-07, tensor(0.0976)), (9.749896377173873e-07, tensor(0.0971)), (9.817479430199847e-07, tensor(0.0968)), (9.885530946569393e-07, tensor(0.0966)), (9.954054173515272e-07, tensor(0.0967)), (1.0023052380779e-06, tensor(0.0965)), (1.0092528860766849e-06, tensor(0.0969)), (1.016248692870696e-06, tensor(0.0969)), (1.0232929922807546e-06, tensor(0.0972)), (1.0303861204416165e-06, tensor(0.0974)), (1.037528415818013e-06, tensor(0.0977)), (1.0447202192208004e-06, tensor(0.0974)), (1.0519618738232234e-06, tensor(0.0975)), (1.0592537251772894e-06, tensor(0.0976)), (1.0665961212302582e-06, tensor(0.0975)), (1.0739894123412452e-06, tensor(0.0975)), (1.0814339512979385e-06, tensor(0.0979)), (1.088930093333434e-06, tensor(0.0980)), (1.0964781961431855e-06, tensor(0.0974)), (1.1040786199020738e-06, tensor(0.0974)), (1.1117317272815917e-06, tensor(0.0973)), (1.1194378834671521e-06, tensor(0.0977)), (1.1271974561755108e-06, tensor(0.0974)), (1.1350108156723156e-06, tensor(0.0972)), (1.1428783347897723e-06, tensor(0.0969)), (1.1508003889444364e-06, tensor(0.0973)), (1.1587773561551257e-06, tensor(0.0971)), (1.166809617060962e-06, tensor(0.0975)), (1.1748975549395294e-06, tensor(0.0974)), (1.1830415557251644e-06, tensor(0.0980)), (1.1912420080273745e-06, tensor(0.0980)), (1.1994993031493785e-06, tensor(0.0978)), (1.20781383510678e-06, tensor(0.0977)), (1.2161860006463676e-06, tensor(0.0979)), (1.2246161992650484e-06, tensor(0.0980)), (1.2331048332289087e-06, tensor(0.0975)), (1.2416523075924108e-06, tensor(0.0976)), (1.2502590302177198e-06, tensor(0.0976)), (1.258925411794167e-06, tensor(0.0978)), (1.2676518658578453e-06, tensor(0.0979)), (1.2764388088113436e-06, tensor(0.0979)), (1.2852866599436152e-06, tensor(0.0979)), (1.2941958414499857e-06, tensor(0.0974)), (1.3031667784522991e-06, tensor(0.0969)), (1.312199899019203e-06, tensor(0.0972)), (1.3212956341865749e-06, tensor(0.0974)), (1.3304544179780907e-06, tensor(0.0978)), (1.3396766874259348e-06, tensor(0.0975)), (1.3489628825916535e-06, tensor(0.0975)), (1.3583134465871538e-06, tensor(0.0977)), (1.367728825595849e-06, tensor(0.0976)), (1.3772094688939465e-06, tensor(0.0978)), (1.3867558288718884e-06, tensor(0.0977)), (1.3963683610559374e-06, tensor(0.0981)), (1.4060475241299137e-06, tensor(0.0983)), (1.4157937799570814e-06, tensor(0.0983)), (1.4256075936021882e-06, tensor(0.0985)), (1.435489433353656e-06, tensor(0.0982)), (1.4454397707459273e-06, tensor(0.0984)), (1.4554590805819657e-06, tensor(0.0986)), (1.4655478409559115e-06, tensor(0.0983)), (1.4757065332758945e-06, tensor(0.0986)), (1.4859356422870067e-06, tensor(0.0984)), (1.4962356560944333e-06, tensor(0.0987)), (1.506607066186742e-06, tensor(0.0986)), (1.5170503674593365e-06, tensor(0.0984)), (1.5275660582380727e-06, tensor(0.0986)), (1.5381546403030349e-06, tensor(0.0985)), (1.548816618912481e-06, tensor(0.0981)), (1.5595525028269535e-06, tensor(0.0981)), (1.5703628043335525e-06, tensor(0.0979)), (1.5812480392703834e-06, tensor(0.0983)), (1.5922087270511703e-06, tensor(0.0985)), (1.6032453906900414e-06, tensor(0.0982)), (1.6143585568264862e-06, tensor(0.0982)), (1.625548755750484e-06, tensor(0.0983)), (1.6368165214278084e-06, tensor(0.0981)), (1.6481623915255083e-06, tensor(0.0979)), (1.659586907437561e-06, tensor(0.0977)), (1.6710906143107076e-06, tensor(0.0975)), (1.6826740610704677e-06, tensor(0.0973)), (1.6943378004473286e-06, tensor(0.0971)), (1.7060823890031237e-06, tensor(0.0972)), (1.717908387157588e-06, tensor(0.0974)), (1.7298163592151016e-06, tensor(0.0971)), (1.7418068733916145e-06, tensor(0.0979)), (1.7538805018417614e-06, tensor(0.0975)), (1.7660378206861645e-06, tensor(0.0975)), (1.7782794100389231e-06, tensor(0.0970)), (1.7906058540352945e-06, tensor(0.0967)), (1.8030177408595692e-06, tensor(0.0963)), (1.8155156627731358e-06, tensor(0.0969)), (1.828100216142743e-06, tensor(0.0968)), (1.840772001468956e-06, tensor(0.0966)), (1.8535316234148115e-06, tensor(0.0960)), (1.86637969083467e-06, tensor(0.0960)), (1.8793168168032688e-06, tensor(0.0963)), (1.8923436186449757e-06, tensor(0.0967)), (1.9054607179632475e-06, tensor(0.0967)), (1.91866874067029e-06, tensor(0.0966)), (1.9319683170169246e-06, tensor(0.0962)), (1.945360081622663e-06, tensor(0.0967)), (1.9588446735059903e-06, tensor(0.0963)), (1.972422736114854e-06, tensor(0.0962)), (1.9860949173573717e-06, tensor(0.0963)), (1.999861869632745e-06, tensor(0.0957)), (2.0137242498623885e-06, tensor(0.0957)), (2.0276827195212825e-06, tensor(0.0954)), (2.04173794466953e-06, tensor(0.0949)), (2.055890595984142e-06, tensor(0.0950)), (2.0701413487910427e-06, tensor(0.0950)), (2.0844908830972895e-06, tensor(0.0949)), (2.098939883623525e-06, tensor(0.0951)), (2.1134890398366474e-06, tensor(0.0948)), (2.1281390459827125e-06, tensor(0.0949)), (2.1428906011200592e-06, tensor(0.0947)), (2.157744409152667e-06, tensor(0.0946)), (2.172701178863745e-06, tensor(0.0948)), (2.1877616239495534e-06, tensor(0.0951)), (2.2029264630534568e-06, tensor(0.0952)), (2.2181964198002196e-06, tensor(0.0955)), (2.2335722228305322e-06, tensor(0.0953)), (2.2490546058357816e-06, tensor(0.0954)), (2.2646443075930605e-06, tensor(0.0954)), (2.280342072000419e-06, tensor(0.0949)), (2.2961486481123625e-06, tensor(0.0948)), (2.3120647901755953e-06, tensor(0.0952)), (2.3280912576650087e-06, tensor(0.0953)), (2.344228815319923e-06, tensor(0.0952)), (2.360478233180578e-06, tensor(0.0954)), (2.3768402866248775e-06, tensor(0.0953)), (2.3933157564053883e-06, tensor(0.0960)), (2.409905428686596e-06, tensor(0.0962)), (2.4266100950824164e-06, tensor(0.0966)), (2.443430552693973e-06, tensor(0.0966)), (2.460367604147628e-06, tensor(0.0966)), (2.4774220576332868e-06, tensor(0.0967)), (2.4945947269429556e-06, tensor(0.0967)), (2.511886431509581e-06, tensor(0.0965)), (2.529297996446146e-06, tensor(0.0959)), (2.5468302525850422e-06, tensor(0.0963)), (2.5644840365177187e-06, tensor(0.0965)), (2.582260190634597e-06, tensor(0.0962)), (2.600159563165273e-06, tensor(0.0959)), (2.6181830082189868e-06, tensor(0.0957)), (2.636331385825381e-06, tensor(0.0959)), (2.6546055619755407e-06, tensor(0.0956)), (2.673006408663313e-06, tensor(0.0954)), (2.6915348039269168e-06, tensor(0.0955)), (2.710191631890844e-06, tensor(0.0953)), (2.7289777828080425e-06, tensor(0.0953)), (2.7478941531023964e-06, tensor(0.0954)), (2.766941645411511e-06, tensor(0.0952)), (2.78612116862977e-06, tensor(0.0948)), (2.805433637951713e-06, tensor(0.0948)), (2.8248799749157064e-06, tensor(0.0948)), (2.844461107447915e-06, tensor(0.0947)), (2.8641779699065803e-06, tensor(0.0947)), (2.884031503126605e-06, tensor(0.0946)), (2.9040226544644496e-06, tensor(0.0944)), (2.924152377843335e-06, tensor(0.0946)), (2.9444216337987603e-06, tensor(0.0943)), (2.9648313895243416e-06, tensor(0.0938)), (2.9853826189179593e-06, tensor(0.0942)), (3.0060763026282305e-06, tensor(0.0939)), (3.026913428101305e-06, tensor(0.0939)), (3.0478949896279826e-06, tensor(0.0940)), (3.0690219883911567e-06, tensor(0.0940)), (3.0902954325135898e-06, tensor(0.0936)), (3.1117163371060173e-06, tensor(0.0936)), (3.133285724315585e-06, tensor(0.0934)), (3.1550046233746264e-06, tensor(0.0933)), (3.1768740706497706e-06, tensor(0.0933)), (3.1988951096913973e-06, tensor(0.0935)), (3.221068791283434e-06, tensor(0.0938)), (3.243396173493492e-06, tensor(0.0940)), (3.2658783217233576e-06, tensor(0.0939)), (3.2885163087598303e-06, tensor(0.0935)), (3.3113112148259103e-06, tensor(0.0938)), (3.334264127632349e-06, tensor(0.0936)), (3.3573761424295464e-06, tensor(0.0937)), (3.380648362059816e-06, tensor(0.0933)), (3.404081897010009e-06, tensor(0.0933)), (3.4276778654645034e-06, tensor(0.0932)), (3.451437393358562e-06, tensor(0.0937)), (3.475361614432058e-06, tensor(0.0940)), (3.499451670283573e-06, tensor(0.0945)), (3.523708710424871e-06, tensor(0.0945)), (3.5481338923357546e-06, tensor(0.0943)), (3.5727283815192893e-06, tensor(0.0942)), (3.597493351557423e-06, tensor(0.0946)), (3.622429984166986e-06, tensor(0.0942)), (3.647539469256078e-06, tensor(0.0943)), (3.672823004980847e-06, tensor(0.0945)), (3.698281797802662e-06, tensor(0.0945)), (3.723917062545685e-06, tensor(0.0947)), (3.7497300224548357e-06, tensor(0.0946)), (3.77572190925416e-06, tensor(0.0947)), (3.801893963205612e-06, tensor(0.0953)), (3.828247433168226e-06, tensor(0.0950)), (3.854783576657718e-06, tensor(0.0947)), (3.881503659906483e-06, tensor(0.0946)), (3.9084089579240205e-06, tensor(0.0945)), (3.935500754557774e-06, tensor(0.0948)), (3.9627803425543945e-06, tensor(0.0951)), (3.990249023621421e-06, tensor(0.0951)), (4.0179081084894e-06, tensor(0.0954)), (4.045758916974427e-06, tensor(0.0952)), (4.073802778041128e-06, tensor(0.0957)), (4.102041029866069e-06, tensor(0.0955)), (4.130475019901614e-06, tensor(0.0955)), (4.159106104940222e-06, tensor(0.0957)), (4.187935651179184e-06, tensor(0.0961)), (4.216965034285823e-06, tensor(0.0965)), (4.24619563946313e-06, tensor(0.0961)), (4.275628861515863e-06, tensor(0.0965)), (4.305266104917107e-06, tensor(0.0966)), (4.3351087838752895e-06, tensor(0.0967)), (4.365158322401661e-06, tensor(0.0969)), (4.395416154378245e-06, tensor(0.0967)), (4.425883723626266e-06, tensor(0.0968)), (4.456562483975033e-06, tensor(0.0970)), (4.487453899331322e-06, tensor(0.0973)), (4.518559443749224e-06, tensor(0.0974)), (4.549880601500486e-06, tensor(0.0979)), (4.581418867145335e-06, tensor(0.0977)), (4.6131757456037945e-06, tensor(0.0973)), (4.645152752227495e-06, tensor(0.0969)), (4.677351412871983e-06, tensor(0.0971)), (4.70977326396953e-06, tensor(0.0969)), (4.742419852602447e-06, tensor(0.0968)), (4.77529273657691e-06, tensor(0.0971)), (4.808393484497287e-06, tensor(0.0971)), (4.841723675840995e-06, tensor(0.0966)), (4.875284901033864e-06, tensor(0.0969)), (4.909078761526032e-06, tensor(0.0978)), (4.943106869868356e-06, tensor(0.0973)), (4.9773708497893614e-06, tensor(0.0977)), (5.011872336272724e-06, tensor(0.0970)), (5.046612975635285e-06, tensor(0.0967)), (5.081594425605607e-06, tensor(0.0963)), (5.116818355403079e-06, tensor(0.0959)), (5.152286445817566e-06, tensor(0.0958)), (5.188000389289613e-06, tensor(0.0959)), (5.223961889991199e-06, tensor(0.0963)), (5.2601726639070635e-06, tensor(0.0963)), (5.2966344389165795e-06, tensor(0.0967)), (5.333348954876211e-06, tensor(0.0970)), (5.370317963702529e-06, tensor(0.0972)), (5.407543229455811e-06, tensor(0.0969)), (5.4450265284242145e-06, tensor(0.0969)), (5.48276964920854e-06, tensor(0.0967)), (5.520774392807576e-06, tensor(0.0966)), (5.559042572704037e-06, tensor(0.0968)), (5.5975760149511045e-06, tensor(0.0968)), (5.636376558259547e-06, tensor(0.0962)), (5.6754460540854736e-06, tensor(0.0961)), (5.7147863667186725e-06, tensor(0.0964)), (5.754399373371572e-06, tensor(0.0962)), (5.794286964268813e-06, tensor(0.0965)), (5.83445104273745e-06, tensor(0.0966)), (5.87489352529777e-06, tensor(0.0966)), (5.9156163417547416e-06, tensor(0.0964)), (5.956621435290107e-06, tensor(0.0967)), (5.997910762555097e-06, tensor(0.0963)), (6.039486293763801e-06, tensor(0.0965)), (6.081350012787182e-06, tensor(0.0968)), (6.123503917247738e-06, tensor(0.0963)), (6.165950018614824e-06, tensor(0.0962)), (6.208690342300638e-06, tensor(0.0966)), (6.251726927756861e-06, tensor(0.0964)), (6.295061828571979e-06, tensor(0.0965)), (6.338697112569272e-06, tensor(0.0963)), (6.38263486190549e-06, tensor(0.0966)), (6.4268771731702e-06, tensor(0.0966)), (6.471426157485835e-06, tensor(0.0962)), (6.516283940608426e-06, tensor(0.0959)), (6.561452663029053e-06, tensor(0.0959)), (6.6069344800759585e-06, tensor(0.0959)), (6.652731562017412e-06, tensor(0.0963)), (6.698846094165263e-06, tensor(0.0962)), (6.745280276979217e-06, tensor(0.0960)), (6.792036326171844e-06, tensor(0.0961)), (6.839116472814292e-06, tensor(0.0962)), (6.886522963442759e-06, tensor(0.0964)), (6.9342580601656895e-06, tensor(0.0964)), (6.982324040771713e-06, tensor(0.0961)), (7.030723198838333e-06, tensor(0.0964)), (7.079457843841378e-06, tensor(0.0963)), (7.1285303012651935e-06, tensor(0.0966)), (7.177942912713615e-06, tensor(0.0965)), (7.227698036021701e-06, tensor(0.0964)), (7.2777980453682395e-06, tensor(0.0967)), (7.3282453313890395e-06, tensor(0.0965)), (7.379042301291008e-06, tensor(0.0964)), (7.430191378967013e-06, tensor(0.0962)), (7.481695005111542e-06, tensor(0.0962)), (7.533555637337173e-06, tensor(0.0965)), (7.5857757502918365e-06, tensor(0.0960)), (7.638357835776906e-06, tensor(0.0955)), (7.691304402866096e-06, tensor(0.0954)), (7.744617978025187e-06, tensor(0.0956)), (7.798301105232587e-06, tensor(0.0958)), (7.852356346100718e-06, tensor(0.0956)), (7.90678627999825e-06, tensor(0.0960)), (7.961593504173188e-06, tensor(0.0964)), (8.01678063387679e-06, tensor(0.0962)), (8.072350302488382e-06, tensor(0.0959)), (8.128305161640991e-06, tensor(0.0961)), (8.184647881347897e-06, tensor(0.0959)), (8.241381150130022e-06, tensor(0.0962)), (8.298507675144225e-06, tensor(0.0970)), (8.35603018231248e-06, tensor(0.0968)), (8.41395141645195e-06, tensor(0.0968)), (8.472274141405965e-06, tensor(0.0966)), (8.531001140175894e-06, tensor(0.0963)), (8.590135215053957e-06, tensor(0.0966)), (8.649679187756934e-06, tensor(0.0967)), (8.709635899560807e-06, tensor(0.0965)), (8.770008211436348e-06, tensor(0.0960)), (8.830799004185628e-06, tensor(0.0959)), (8.892011178579484e-06, tensor(0.0956)), (8.953647655495939e-06, tensor(0.0956)), (9.01571137605957e-06, tensor(0.0958)), (9.078205301781858e-06, tensor(0.0956)), (9.141132414702503e-06, tensor(0.0957)), (9.204495717531714e-06, tensor(0.0954)), (9.268298233793493e-06, tensor(0.0952)), (9.332543007969911e-06, tensor(0.0955)), (9.39723310564638e-06, tensor(0.0955)), (9.462371613657932e-06, tensor(0.0950)), (9.52796164023652e-06, tensor(0.0946)), (9.594006315159333e-06, tensor(0.0948)), (9.660508789898134e-06, tensor(0.0945)), (9.727472237769651e-06, tensor(0.0946)), (9.79489985408699e-06, tensor(0.0946)), (9.862794856312107e-06, tensor(0.0945)), (9.93116048420934e-06, tensor(0.0948))]
******

*** 2018-12-28 12:23:10,360 - code.resnet_fastai - DEBUG ***
3.614098626396133e-08
******

*** 2018-12-28 12:23:10,393 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2018-12-28 12:23:10,396 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,396 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 12:23:10,406 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,407 - matplotlib.ticker - DEBUG ***
ticklocs [2e-10, 3e-10, 4e-10, 5e-10, 6e-10, 7.000000000000001e-10, 8e-10, 9e-10, 2e-09, 3.0000000000000004e-09, 4e-09, 5e-09, 6.000000000000001e-09, 7.000000000000001e-09, 8e-09, 9.000000000000001e-09, 2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 12:23:10,551 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,552 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 12:23:10,553 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,553 - matplotlib.ticker - DEBUG ***
ticklocs [2e-10, 3e-10, 4e-10, 5e-10, 6e-10, 7.000000000000001e-10, 8e-10, 9e-10, 2e-09, 3.0000000000000004e-09, 4e-09, 5e-09, 6.000000000000001e-09, 7.000000000000001e-09, 8e-09, 9.000000000000001e-09, 2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 12:23:10,708 - matplotlib.axes._base - DEBUG ***
update_title_pos
******

*** 2018-12-28 12:23:10,711 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,711 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 12:23:10,713 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,713 - matplotlib.ticker - DEBUG ***
ticklocs [2e-10, 3e-10, 4e-10, 5e-10, 6e-10, 7.000000000000001e-10, 8e-10, 9e-10, 2e-09, 3.0000000000000004e-09, 4e-09, 5e-09, 6.000000000000001e-09, 7.000000000000001e-09, 8e-09, 9.000000000000001e-09, 2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 12:23:10,739 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,739 - matplotlib.ticker - DEBUG ***
ticklocs array([1.e-10, 1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03])
******

*** 2018-12-28 12:23:10,740 - matplotlib.ticker - DEBUG ***
vmin 7.627812340691617e-09 vmax 1.3477210138513501e-05
******

*** 2018-12-28 12:23:10,741 - matplotlib.ticker - DEBUG ***
ticklocs [2e-10, 3e-10, 4e-10, 5e-10, 6e-10, 7.000000000000001e-10, 8e-10, 9e-10, 2e-09, 3.0000000000000004e-09, 4e-09, 5e-09, 6.000000000000001e-09, 7.000000000000001e-09, 8e-09, 9.000000000000001e-09, 2e-08, 3.0000000000000004e-08, 4e-08, 5e-08, 6.000000000000001e-08, 7e-08, 8e-08, 9e-08, 2e-07, 3e-07, 4e-07, 5e-07, 6e-07, 7e-07, 8e-07, 9e-07, 2e-06, 3e-06, 4e-06, 4.9999999999999996e-06, 6e-06, 7e-06, 8e-06, 9e-06, 2e-05, 3.0000000000000004e-05, 4e-05, 5e-05, 6.000000000000001e-05, 7.000000000000001e-05, 8e-05, 9e-05, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001]
******

*** 2018-12-28 12:23:10,779 - code.resnet_fastai - INFO ***
Start model fitting: Stage 2
******

*** 2018-12-28 12:23:10,779 - code.resnet_fastai - DEBUG ***
Use best LR: 2.529869038477293e-08
******

2         0.094830                
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
epoch     train_loss  valid_loss  fbeta   
1         0.097174    0.117030    0.696700  
2         0.096843    0.119400    0.694600  
3         0.095207    0.089638    0.695563  
4         0.096006    0.122987    0.693719  
5         0.096262    0.120324    0.695622  
6         0.094717    0.120206    0.697993  
7         0.096851    0.121371    0.696245  
8         0.096981    0.117816    0.695482  
9         0.095266    0.123892    0.697683  
Epoch 9: reducing lr to 9.937138397341406e-07
10        0.093370    0.108341    0.696168  
11        0.094650    0.099615    0.700536  
12        0.093954    0.092108    0.697862  
13        0.092970    0.121700    0.700261  
14        0.095481    0.088721    0.700374  
15        0.093764    0.113556    0.702365  
Epoch 15: reducing lr to 6.185651454774584e-07
16        0.093926    0.119356    0.695768  
17        0.093651    0.102011    0.697168  
18        0.092960    0.116726    0.700070  
19        0.095151    0.108088    0.696555  
20        0.094245    0.104709    0.698371  
21        0.094533    0.115051    0.701758  
Epoch 21: reducing lr to 1.2494291860778976e-07
22        0.093089    0.098857    0.702614  
23        0.094548    0.108577    0.699190  
24        0.092613    0.087962    0.701059  
*** 2018-12-28 15:44:19,431 - code.resnet_fastai - INFO ***
Complete model fitting: Stage 2
******

*** 2018-12-28 15:44:19,562 - code.resnet_fastai - INFO ***
Stage 2 model saved.
******

*** 2018-12-28 15:44:19,564 - code.resnet_fastai - INFO ***
Start predicting test set
******

25        0.094269    0.108506    0.702895  
*** 2018-12-28 15:46:46,411 - code.resnet_fastai - INFO ***
Complete test prediction.
******

*** 2018-12-28 15:46:46,414 - code.resnet_fastai - INFO ***
Prediction saved.
******

*** 2018-12-28 15:46:46,527 - code.resnet_fastai - INFO ***
Results written to output/resnet50-512-official-bce-random-drop0.5-th0.1-bs32-lr0-ep3_25-0.csv. Finished! :)
******

*** 2018-12-28 15:46:46,529 - code.resnet_fastai - DEBUG ***
torch.Size([11702, 28])
******

